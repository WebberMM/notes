#+TITLE: Introduction To Commutative Algebra
#+AUTHOR: Atiyah & Macdonald

#+LATEX_HEADER: \input{../preamble.tex}
#+EXPORT_FILE_NAME: ../latex/IntroductionToCommutativeAlgebra/IntroductionToCommutativeAlgebra.tex
#+options: num:1
* Rings and Ideals
  A *unit* is an element \(u\) with a *reciprocal* \(1/u\) or the
  *multiplicative inverse*. The units form a multiplicative group, denoted
  \(R^\times\)

  A ring *homomorphism*, or simply a *ring map*, \(\varphi:R\to R'\) is a map
  preserving sum, products and 1

  If there is an unspecified isomorphism between rings \(R\) and \(R'\), then we
  write \(R=R'\) when it is *canonical*; that is, it does not depend on any
  artificial choices.

  A subset \(R''\subset R\) is a *subring* if \(R''\) is a ring and the
  inclusion \(R''\hookrightarrow R\) is a ring map. In this case, we call \(R\)
  a *(ring) extension*.

  An *\(R\)-algebra* is a ring \(R'\) that comes equipped with a ring map
  \(\varphi:R\to R'\), called the *structure map*, denoted by \(R'/R\). For
  example, every ring is canonically a \(\Z\)-algebra. An
  *\(R\)-algebra homomorphism*, or *\(R\)-map*, \(R'\to R''\) is a ring map
  between \(R\)-algebras.

  A group \(G\) is said to *act* on \(R\) if there is a homomorphism given from
  \(G\) into the group of automorphism of \(R\). The *ring of invariants*
  \(R^G\) is the subring defined by
  \begin{equation*}
  R^G:=\{x\in R\mid gx=g\text{ for all }g\in G\}
  \end{equation*}

  Similarly a group \(G\) is said to *act* on \(R'/R\) if \(G\) acts on \(R'\)
  and each \(g\in G\) is an \(R\)-map. Note that \(R'^G\) is an \(R\)-subalgebra

** Boolean rings label:sec1.2
  The simplest nonzero ring has two elements, 0 and 1. It's denoted \(\F_2\)


  Given any ring \(R\) and any set \(X\), let \(R^X\) denote the set of
  functions \(f:X\to R\). Then \(R^X\) is a ring.

  For example, take \(R:=\F_2\). Given \(f:X\to R\), put \(S:=f^{-1}\{1\}\).
  Then \(f(x)=1\) if \(x\in S\). In other words, \(f\) is the *characteristic
  function* \(\chi_S\). Thus /the characteristic functions form a ring, namely/, \(\F_2^X\)

  Given \(T\subset X\), clearly \(\chi_S\cdot\chi_T=\chi_{S\cap T}\).
  \(\chi_S+\chi_T=\chi_{S\triangle T}\), where \(S\triangle T\) is the
  *symmetric difference*:
  \begin{equation*}
  S\triangle T:=(S\cup T)-(S\cap T)
  \end{equation*}
  Thus /the subsets of \(X\) form a ring: sum is symmetric difference, and/
  /product is intersection. This ring is canonically isomorphic to \(\F_2^X\)/

  A ring \(B\) is called *Boolean* if \(f^2=f\) for all \(f\in B\). If so, then
  \(2f=0\) as \(2f=(f+f)^2=f^2+2f+f^2=4f\)

  Suppose \(X\) is a topological space, and give \(\F_2\) the *discrete*
  topology; that is, every subset is both open and closed. Consider the
  continuous functions \(f:X\to\F_2\). Clearly, they are just the \(\chi_S\)
  where \(S\) is both open and closed.

** Polynomial rings
   Let \(R\) be a ring, \(P:=R[X_1,\dots,X_n]\). \(P\) has this *Universal
   Mapping Property* (UMP): /given a ring map \(\varphi:R\to R'\) and given an/
   /element \(x_i\) of \(R'\) for each \(i\), there is a unique ring map/
   /\(\pi:P\to R'\) with \(\pi|R=\varphi\) and \(\pi(X_i)=x_i\)./ In fact, since
   \pi is a ring map, necessarily \pi is given by the formula:
   \begin{equation}
   \pi(\sum a_{(i_1,\dots,i_n)}X_1^{i_1}\dots X_n^{i_n})=\sum
   \varphi(a_{(i_1,\dots,i_n)})x_1^{i_1}\dots x_n^{i_n}\label{eq1.3.1}
   \end{equation}
   In other words, \(P\) is universal among \(R\)-algebras equipped with a list
   of \(n\) elements

   Similarly let \(\calx:=\{X_\lambda\}_{\lambda\in\Lambda}\) be any set of
   variables. Set \(P':=R[\calx]\); the elements of \(P'\) are the polynomials
   in any finitely many of the \(X_\lambda\). \(P'\) has essentially the same
   UMP as \(P\)

** Ideals
   Let \(R\) be a ring. A subset \(\fa\) is called an *ideal* if
   1. \(0\in\fa\)
   2. whenever \(a,b\in\fa\), also \(a+b\in\fa\)
   3. whenever \(x\in R\) and \(a\in\fa\) also \(xa\in\fa\)


   Given a subset \(\fa\subset R\), by the ideal \(\la\fa\ra\) that \(\fa\)
   *generates*, we mean the smallest ideal containing \(\fa\)

   All ideal containing all the \(a_\lambda\) contains any (finite) *linear
   combination* \(\sum x_\lambda a_\lambda\) with \(x_\lambda\in R\) and almost
   all 0.

   Given a single element \(a\), we say that the ideal \(\la a\ra\) is
   *principal*

   Given a number of ideals \(\fa_\lambda\), by their *sum* \(\sum\fa_\lambda\)
   we mean the set of all finite linear combinations \(\sum x_\lambda
   a_\lambda\) with \(x_\lambda\in R\) and \(a_\lambda\in\fa_\lambda\)

   Given two ideals \(\fa\) and \(\fb\), by the *transporter* of \(\fb\) into
   \(\fa\) we mean the set
   \begin{equation*}
   (\fa:\fb):=\{x\in R\mid x\fb\subset\fa\}
   \end{equation*}
   \((\fa:\fb)\)  is an ideal. Plainly,
   \begin{equation*}
   \fa\fb\subset\fa\cap\fb\subset\fa+\fb,\quad\fa,\fb\subset\fa+\fb,\quad
   \fa\subset(\fa:\fb)
   \end{equation*}
   Further, for any ideal \(\fc\), the distributive law holds:
   \(\fa(\fb+\fc)=\fa\fb+\fa\fc\)

   Given an ideal \(fa\), notice \(\fa=R\) /if and only if/ \(1\in\fa\). It
   follows that \(\fa=R\) iff \(\fa\) contains a unit.

   Given a ring map \(\varphi:R\to R'\), denote by \(\fa R'\) or \(\fa^e\) the
   ideal of \(R'\) generated by the set \(\varphi(\fa)\). We call it the
   *extension* of \(\fa\)

   Given an ideal \(\fa'\) of \(R'\), its preimage \(\varphi^{-1}(\fa')\) is an
   ideal of \(R\). We call \(\varphi^{-1}(\fa')\) the *contraction* of \(\fa'\)
   and sometimes denote it by \(\fa'^c\)

** Residue rings
   *kernel* \(\ker(\varphi)\) is defined to be the ideal \(\varphi^{-1}(0)\) of
   \(R\)

   Let \(\fa\) be an ideal of \(R\). Form the set of cosets of \(\fa\)
   \begin{equation*}
   R/\fa:=\{x+\fa\mid x\in R\}
   \end{equation*}
   \(R/\fa\) is called the *residure ring* or *quotient ring* or *factor ring* of
   \(R\) *modulo* \(\fa\). From the *quotient map*
   \begin{equation*}
   \kappa:R\to R/\fa\quad\text{ by }\kappa x:=x+\fa
   \end{equation*}
   The element \(\kappa x\in R/\fa\) is called the *residue* of \(x\).

   If \(\ker(\varphi)\supset\fa\), /then there is a ring map/ \(\psi:R/\fa\to R'\)
   /with/ \(\psi\kappa=\varphi\); that is, the following diagram is commutative

   #+BEGIN_center
   \begin{tikzcd}
   R\arrow[r,"\kappa"]\arrow[dr,"\varphi"]&R/\fa\arrow[d,"\psi"]\\
   &R'
   \end{tikzcd}
   #+END_center
   by \(\psi(x\fa)=\varphi(x)\). Then we only need to verify that \(\psi\) is a map
   
   Conversely, /if \psi exists, then/ \(\ker(\varphi)\supset\fa\), /or/
   \(\varphi\fa=0\), /or/ \(\fa R'=0\), since \(\kappa\fa=0\)

   Further, /if \psi exists, then \psi is unique/ as \(\kappa\) is surjective

   Finally, as \kappa is surjective, /if \psi exists, then \psi is surjective/
   /iff \psi is so/. In addition, \psi /is injective iff \(\fa=\ker(\varphi)\)/.
   Hence \psi /is an isomorphism iff \varphi is surjective and/
   \(\fa=\ker(\varphi)\). Therefore,
   \begin{equation*}
   R/\ker(\varphi)\xrightarrow{\sim}\im(\varphi)
   \end{equation*}

   \(R/\fa\) has UMP: \(\kappa(\fa)=0\), and given \(\varphi:R\to R'\) s.t.
   \(\varphi:R\to R'\) s.t. \(\varphi(\fa)=0\), there is a unique ring map
   \(\psi:R/\fa\to R'\) s.t. \(\psi\kappa=\varphi\). In other words, \(R/\fa\)
   is universal among \(R\)-algebras \(R'\) s.t. \(\fa R'=0\)

   If \(\fa\) is the ideal generated by elements \(a_\lambda\),then the UMP can
   be usefully rephrased as follows: \(\kappa(a_\lambda)=0\) for all \lambda,
   and given \(\varphi:R\to R'\) s.t. \(\varphi(a_\lambda)=0\) for all \lambda,
   there is a unique ring map \(\psi:R/\fa\to R'\) s.t. \(\psi\kappa=\varphi\)

   /The UMP serves to determine/ \(R/\fa\) /up to unique isomorphism/.
   Say \(R'\), equipped with \(\varphi:R\to R'\) has the UMP too.
   \(\kappa(\fa)=0\) so there is a unique \(\psi':R'\to R/\fa\) with
   \(\psi'\varphi=\kappa\). Then \(\psi'\psi\kappa=\kappa\). Hence
   \(\psi'\psi=1\) by uniqueness. Thus \(\psi\) and \(\psi'\) are inverse isomorphism
   #+BEGIN_center
   \begin{tikzcd}
   &&R/\fa\arrow[dd,"1"]\arrow[dl,"\psi"]\\
   R\arrow[urr,"\kappa"]\arrow[r,"\varphi"]\arrow[drr,"\kappa"]&
   R'\arrow[dr,"\psi'"]&\\
   &&R/\fa
   \end{tikzcd}
   #+END_center

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   Let \(R\) be a ring, \(P:=R[X]\), \(a\in R\) and \(\pi:P\to R\) the
   \(R\)-algebra map defined by \(\pi(X):=a\). Then
   1. \(\ker(\pi)=\{F(X)\in P\mid F(a)=0\}=\la X-a\ra\)
   2. \(R/\la X-a\ra\simeq R\)
   #+END_proposition

   #+BEGIN_proof
   Set \(G:=X-a\). Given \(F\in P\), let's show \(F=GH+r\) with \(H\in P\) and
   \(r\in R\). By linearity, we may assume \(F:=X^n\). If \(n\ge1\), then
   \(F=(G+a)X^{n-1}\), so \(F=GH+aX^{n-1}\) with \(H:=X^{n-1}\).

   Then \(\pi(F)=\pi(G)\pi(H)+\pi(r)=r\). Hence \(F\in\ker(\pi)\) iff \(F=GH\). But
   \(\pi(F)=F(a)\) by ref:eq1.3.1
   #+END_proof


** Degree of a polynomial
   Let \(R\) be a ring, \(P\) the polynomial ring in any number of variables.
   If \(F\) is a monomial \(\bM\), then its degree \(\deg(\bM)\) is the sum of
   its exponents; in general, \(\deg(F)\) is the largest \(\deg(\bM)\) of all
   monomials \(\bM\) in \(F\)

   Given any \(G\in P\) with \(FG\) nonzero, notice that
   \begin{equation*}
   \deg(FG)\le\deg(F)+\deg(G)
   \end{equation*}

** Order of a polynomial
   Let \(R\) be a ring, \(P\) the polynomial ring in variable \(X_\lambda\) for
   \(\lambda\in\Lambda\), and \((x_\lambda)\in R^\Lambda\) a vector. Let
   \(\varphi_{(x_\lambda)}:P\to P\) denote the \(R\)-algebra map defined by
   \(\varphi_{(x_\lambda)}X_\mu:=X_\mu+x_\mu\) for all \(\mu\in\Lambda\). Fix a
   nonzero \(F\in P\)

   The *order* of \(F\) at the zero vector \((0)\), denoted \(\ord_{(0)}F\), is
   defined as the smallest \(\deg(\bM)\) of all the monomials \(\bM\) in \(F\).
   In general, the *order* of \(F\) at the vector \((x_\lambda)\), denoted
   \(\ord_{(x_\lambda)}F\) is defined by the formula: \(\ord_{(x_\lambda)}F:=\ord_{(0)}(\varphi_{(x_\lambda)}F)\)

   Notice that \(\ord_{(x_\lambda)}F=0\) iff \(F(x_\lambda)\neq0\) as \((\varphi_{x_\lambda}F)(0)=F(x_\lambda)\)

   Given \mu and \(x\in R\), form \(F_{\mu,x}\) by substituting \(x\) for \(X_\mu\)
   in \(F\). If \(F_{\mu,x_\mu}\neq0\) , then
   \begin{equation*}
   \ord_{(x_\lambda)}F\le\ord_{(x_\lambda)}F_{\mu,x_\mu}\label{eq1.8.1}
   \end{equation*}
   If \(x_\mu=0\), then \(F_{\mu,x_\mu}\) is the sum of the terms without
   \(x_\mu\) in \(F\). Hence if \((x_\lambda)=(0)\), then ref:eq1.8.1 holds. But
   substituting 0 for \(X_\mu\) in \(\varphi_{(x_\lambda)}F\) is the same as
   substituting \(x_\mu\) for \(X_\mu\) in \(F\) and then applying
   \(\varphi_{(x_\lambda)}\) to the result; that is,
   \((\varphi_{(x_\mu)}F)_{\mu,0}=\varphi_{(x_\lambda)}F_{\mu,x_\mu}\)

   Given any \(G\in P\) with \(FG\) nonzero,
   \begin{equation*}
   \ord_{(x_\lambda)}FG\ge\ord_{(x_\lambda)}F+\ord_{(x_\lambda)}G
   \end{equation*}

** Nested ideals label:1.9
   Let \(R\) be a ring, \(\fa\) an ideal, and \(\kappa:R\to R/\fa\) the quotient map.
   Given an ideal \(\fb\supset\fa\), form the corresponding set of cosets of
   \(\fa\)
   \begin{equation*}
   \fb/\fa:=\{b+\fa\mid b\in\fb\}=\kappa(\fb)
   \end{equation*}
   Clearly, \(\fb/\fa\) is an ideal of \(R/\fa\). Also \(\fb/\fa=\fb(R/\fa)\)

   /The operation/ \(\fb\mapsto\fb/\fa\) /and/ \(\fb'\mapsto\kappa^{-1}(\fb')\) /are/
   /inverse to each other, and establish a bijective correspondence between the/
   /set of ideals \(\fb\) of \(R\) containing \(\fa\) and the set of all ideals/
   \(\fb'\) /of/ \(R/\fa\). /Moreover, this correspondence preserves inclusions/

   Given an ideal \(\fb\supset\fa\), form the composition of the quotient maps
   \begin{equation*}
   \varphi:R\to R/\fa\to (R/\fa)/(\fb/\fa)
   \end{equation*}
   \varphi is surjective and \(\ker(\varphi)=\fb\). Hence \varphi factors
   #+BEGIN_center
   \begin{tikzcd}
   R\arrow[r]\arrow[d]&R/\fb\arrow[d,"\psi","\simeq"']\\
   R/\fa\arrow[r]&(R/\fa)/(\fb/\fa)
   \end{tikzcd}
   #+END_center

** Idempotents
   Let \(R\) be a ring. Let \(e\in R\) be an *idempotent*; that is, \(e^2=e\).
   Then \(Re\) is a ring with \(e\) as 1.

   Set \(e':=1-e\). Then \(e'\) is idempotent and \(e\cdot e'=0\). We call \(e\)
   and \(e'\)  *complementary idempotents*. Conversely, if two elements
   \(e_1,e_2\in R\) satisfy \(e_1+e_2=1\) and \(e_1e_2=0\), then they are
   complementary idempotents, as for each \(i\),
   \begin{equation*}
   e_i=e_i\cdot 1=e_i(e_1+e_2)=e_i^2
   \end{equation*}
   We denote the set of all idempotents by \(\Idem(R)\). Let \(\varphi:R\to R'\)
   be a ring map. Then \(\varphi(e)\) is idempotent. So the restriction of
   \varphi to \(\Idem(R)\) is a map
   \begin{equation*}
   \Idem(\varphi):\Idem(R)\to\Idem(R')
   \end{equation*}
   #+ATTR_LATEX: :options []
   #+BEGIN_examplle
   Let \(R:=R'\times R''\) be a *product* of two rings. Set \(e':=(1,0)\) and
   \(e'':=(0,1)\). Then \(e'\) and \(e''\) are complementary idempotents.
   #+END_examplle

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   Let \(R\) be a ring, and \(e',e''\) complementary idempotents. Set
   \(R':=Re'\) and \(R'':=Re''\). Define \(\varphi:R\to R'\times R''\) by
   \(\varphi(x):=(xe',xe'')\). Then \varphi is a ring isomorphism. Moreover, \(R'=R/Re''\)
   and \(R''=R/Re'\)
   #+END_proposition

   #+BEGIN_proof
   Define a surjection \(\varphi':R\to R'\) by \(\varphi'(x):=xe'\). Then
   \(\varphi'\) is a ring map, since \(xye'=xye'^2=(xe')(ye')\). Moreover,
   \(\ker(\varphi')=Re''\) since \(x=x\cdot 1=xe'+xe''=xe''\). Thus
   \(R'=R/Re''\)

   Since \varphi is a ring map. It's surjective since \((xe',x'e'')=\varphi(xe'+x'e'')\)
   #+END_proof

** Exercise
   #+BEGIN_exercise
   label:ex1.13
   Let \(\varphi:R\to R'\) be a map of rings, \(\fa_1,\fa_2,\fa\) ideals of \(R\),
   \(\fb_1,\fb_2,\fb\) ideals of \(R'\). Prove
   1. \((\fa_1+\fa_2)^e=\fa_1^e+\fa_2^e\)
   2. \((\fb_1+\fb_2)^c\supset\fb_1^c+\fb_2^c\)
   3. \((\fa_1\cap\fa_2)^e\subset\fa_1^e\cap\fa_2^e\)
   4. \((\fb_1\cap\fb_2)^c=\fb_1^c\cap\fb_2^c\)
   5. \((\fa_1\fa_2)^e=\fa_1^e\fa_2^e\)
   6. \((\fb_1\fb_2)^c\supset\fb_1^c\fb_2^c\)
   7. \((\fa_1:\fa_2)^e\subset(\fa_1^e:\fa_2^e)\)
   8. \((\fb_1:\fb_2)^c\subset(\fb_1^c:\fb_2^c)\)
   #+END_exercise

   #+BEGIN_exercise
   label:ex1.14
   Let \(\varphi:R\to R'\) be a map of rings, \(\fa\) an ideal of \(R\), and \(\fb\)
   an ideal of \(R'\). Prove the following statements:
   1. \(\fa^{ec}\supset\fa\) and \(\fb^{ce}\subset\fb\)
   2. \(\fa^{ece}=\fa^e\) and \(\fb^{cec}=\fb^c\)
   3. If \(\fb\) is an extension, then \(\fb^c\) is the largest ideal of \(R\)
      with extension \(\fb\)
   4. If two extensions have the same contraction, then they are equal
   #+END_exercise

   #+BEGIN_exercise
   label:1.15
   Let \(R\) be a ring, \(\fa\) an ideal, \(\calx\) a set of variables. Prove:
   1. The extension \(\fa(R[\calx])\) is the set \(\fa[\calx]\)
   2. \(\fa(R[\calx])\cap R=\fa\)
   #+END_exercise

   #+BEGIN_exercise
   label:1.16
   Let \(R\) be a ring, \(\fa\) an ideal, and \(\calx\) a set of variables. Set
   \(P:=R[\calx]\). Prove \(P/\fa P=(R/\fa)[\calx]\)
   #+END_exercise

   #+BEGIN_exercise
   label:1.17
   Let \(R\) be a ring, \(P:=R[\{X_\lambda\}]\) the polynomial ring in variables
   \(X_\lambda\) for \(\lambda\in\Lambda\) a vector. Let
   \(\pi_{(x_\lambda)}:P\to R\) denote the \(R\)-algebra map defined by
   \(\pi_{(x_\lambda)}X_\mu:=x_\mu\) for all \(\mu\in\Lambda\). Show:
   1. Any \(F\in P\) has the form \(F=\sum
      a_{(i_1,\dots,i_n)}(X_{\lambda_1}^{i_1}-x_{\lambda_1})\dots
      (X_{\lambda_n}-x_{\lambda_n})^{i_n}\) for unique \(a_{(i_1,\dots,i_n)}\in R\)
   2. \(\ker(\pi_{(x_\lambda)})=\{F\in P\mid F((x_\lambda))=0\}=\la\{X_\lambda-x_\lambda\}\ra\)
   3. \pi induces an isomorphism \(P/\la\{X_\lambda-x_\lambda\}\ra\simeq R\)
   4. Given \(F\in P\), its residue in \(P/\la\{X_\lambda-x_\lambda\}\ra\) is
      equal to \(F((x_\lambda))\)
   5. Let \(\caly\) be a second set of variables. Then
      \(P[\caly]/\la\{X_\lambda-x_\lambda\}\ra\simeq R[\caly]\)
   #+END_exercise

   #+BEGIN_proof
   1. Let \(\varphi_{(x_\lambda)}\) be the \(R\)-automorphism of \(P\). Say
      \(\varphi_{(x_\lambda)}F=\sum a_{(i_1,\dots,i_n)}X_{\lambda_1}^{i_1}\dots
      X_{\lambda_n}^{i_n}\) . And \(\varphi_{(x_\lambda)}^{-1}\varphi_{(x_\lambda)}F=F\)
   2. Note that \(\pi_{(x_\lambda)}F=F((x_\lambda))\). Hence
      \(F\in\ker(\pi_{(x_\lambda)})\) iff \(F((x_\lambda))=0\). If
      \(F((x_\lambda))=0\), then \(a_{(0,\dots,0)}=0\), and so \(F\in\la\{X_\lambda-x_\lambda\}\ra\)
   5. [@5] Set \(R':=R[\caly]\)
   #+END_proof

   #+BEGIN_exercise
   label:ex.1.18
   Let \(R\) be a ring, \(P:=R[X_1,\dots,X_n]\) the polynomial ring in variables
   \(X_i\). Given \(F=\sum a_{(i_1,\dots,i_n)}X_1^{i_1}\dots X_n^{i_n}\in P\),
   formally set
   \begin{equation*}
   \partial F/\partial X_j:=\sum i_ja_{(i_1,\dots,i_n)}
   X_1^{i_i}\dots X_n^{i_n}/X_j\in P
   \end{equation*}
   Given \((x_1,\dots,x_n)\in R^n\), set \(\bx:=(x_1,\dots,x_n)\), set
   \(a_j:=(\partial F/\partial X_j)(\bx)\), and set
   \(\fM:=\la X_1-x_1,\dots,X_n-x_n\ra\). Show \(F=F(\bx)+\sum a_j(X_j-x_j)+G\)
   with \(G\in\fM^2\). First show that if
   \(F=(X_1-x_1)^{i_1}\dots(X_n-x_n)^{i_n}\), then \(\partial F/\partial X_j=i_jF/(X_j-x_j)\)
   #+END_exercise

   #+BEGIN_proof
   \((\partial F/\partial X_j)(\bx)=b_{(\delta_{1j},\dots,\delta_{nj})}\) where
   \(\delta_{ij}\) is the Kronecker delta
   #+END_proof

   #+BEGIN_exercise
   label:ex1.19
   Let \(R\) be a ring, \(X\) a variable, \(F\in P:=R[x]\), and \(a\in R\). Set
   \(F':=\partial F/\partial X\). We call \(a\) a *root* of \(F\) if \(F(a)=0\), a
   *simple root* if also \(F'(a)\neq0\), and a *supersimple root* if also \(F'(a)\)
   is a unit.

   Show that \(a\) is a root of \(F\) iff \(F=(X-a)G\) for some \(G\in P\), and
   if so, then \(G\) is unique; that \(a\) is a simple root iff also
   \(G(a)\neq0\); and that \(a\) is a supersimple root iff also \(G(a)\) is a unit
   #+END_exercise

   #+BEGIN_exercise
   label:ex1.20
   Let \(R\) be a ring, \(P:=R[X_1,\dots,X_n]\), \(F\in P\) of degree \(d\) and
   \(F_i:=X_i^{d_i}+a_1X_i^{d_i-1}+\dots\) a monic polynomial in \(X_i\) aloen
   for all \(i\). Find \(G,G_i\in P\) s.t. \(F=\sum_{i=1}^nF_iG_i+G\) where
   \(G_i=0\) or \(\deg(G_i)\le d-d_i\) and where the highest power of \(X_i\) in
   \(G\) is less than \(d_i\)
   #+END_exercise

   #+BEGIN_proof
   By linearity, we may assume \(F:=X_1^{m_1}\dots X_n^{m_n}\). If \(m_i<d_i\)
   for all \(i\), set \(G_i:=0\) and \(G:=F\) and we're done. Else, fix \(i\)
   with \(m_i\ge d_i\), and set \(G_i:=F/X_i^{d_i}\) and \(G:=(-a_1X_i^{d_i-1}-\dots)G_i\)
   #+END_proof

   #+ATTR_LATEX: :options [Chinese Remainder Theorem]
   #+BEGIN_exercise
   label:ex1.21
   Let \(R\) be a ring
   1. Let \(\fa\) and \(\fb\) be *comaximal* ideals; that is, \(\fa+\fb=R\). Show
      1. \(\fa\fb=\fa\cap\fb\)
      2. \(R/\fa\fb=(R/\fa)\times(R/\fb)\)
   2. Let \(\fa\) be comaximal to both \(\fb\) and \(\fb'\). Show \(\fa\) is
      also comaximal to \(\fb\fb'\)
   3. Given \(m,n\ge1\), show \(\fa\) and \(\fb\) are comaximal iff \(\fa^m\)
      and \(\fb^n\) are.
   4. Let \(\fa_1,\dots,\fa_n\) be pairwise comaximal. Show
      1. \(\fa_1\) and \(\fa_2\dots\fa_n\) are comaximal
      2. \(\fa_1\cap\dots\cap\fa_n=\fa_1\dots\fa_n\)
      3. \(R/(\fa_1\dots\fa_n)\simeq\prod(R/\fa_i)\)
   5. Find an example where \(\fa\) and \(\fb\) satisfy 1.1 but aren't comaximal
   #+END_exercise

   #+BEGIN_proof
   1. \(\fa+\fb=R\) implies \(x+y=1\) with \(x\in\fa\) and \(y\in\fb\). So given
      \(z\in\fa\cap\fb\), we have \(z=xz+yz\in\fa\fb\)
   2. \(R=(\fa+\fb)(\fa+\fb')=(\fa^2+\fb\fa+\fa\fb')+\fb\fb'\subseteq\fa+\fb\fb'\subseteq
      R\)
   3. Build with \(\fa+\fb^2=R\). Conversely, note that \(\fa^n\subset\fa\)
   4. Induction
   5. Let \(k\) be a field. Take \(R:=k[X,Y]\) and \(\fa:=\la X\ra\) and
      \(\fb:=\la Y\ra\). Given \(f\in\la X\ra\cap\la Y\ra\), note that every
      monomial of \(f\) contains both \(X\) and \(Y\), and so \(f\in\la X\ra\la
      Y\ra\). But \(\la X\ra\) and \(\la Y\ra\) are not comaximal
   #+END_proof

   #+BEGIN_exercise
   label:ex1.22
   First given a prime number \(p\) and a \(k\ge1\), find the idempotents in
   \(\Z/\la p^k\ra\). Second, find the idempotents in \(\Z/\la12\ra\). Third,
   find the number of idempotents in \(\Z/\la n\ra\) where
   \(n=\prod_{i=1}^Np_i^{n_i}\) with \(p_i\) distinct prime numbers
   #+END_exercise

   #+BEGIN_proof
   \(x=0,1\)

   Since \(-3+4=1\), the Chinese Remainder Theorem yields
   \begin{equation*}
   \Z/\la 12\ra=\Z/\la3\ra\times\Z/\la4\ra
   \end{equation*}
   \(m\) is idempotent in \(\Z/\la12\ra\) iff it's idempotent in \(\Z/\la3\ra\)
   and \(\Z/\la4\ra\)

   \(p_i^{n_i}\) has a linear combination equal to 1. Hence \(2^N\)
   #+END_proof

   #+BEGIN_exercise
   label:ex1.23
   Let \(R:=R'\times R''\) be a product of rings, \(\fa\subset R\) an ideal.
   Show \(\fa=\fa'\times\fa''\) with \(\fa'\subset R\) and \(\fa''\subset R''\)
   ideals. Show \(R/\fa=(R'/\fa')\times(R''/\fa'')\)
   #+END_exercise

   #+BEGIN_exercise
   label:ex1.24
   Let \(R\) be a ring; \(e,e'\) idempotents. Show
   1. Set \(\fa:=\la e\ra\). Then \(\fa\) is idempotent; that is, \(\fa^2=\fa\)
   2. Let \(\fa\) be a principal idempotent ideal. Then \(\fa=\la f\ra\) with
      \(f\) idempotent
   3. Set \(e'':=e+e'-ee'\). Then \(\la e,e'\ra=\la e''\ra\) and \(e''\) is
      idempotent
   4. Let \(e_1,\dots,e_r\) be idempotents. Then \(\la e_1,\dots,e_r\ra=\la
      f\ra\) with \(f\) idempotent
   5. Assume \(R\) is Boolean. Then every finitely generated ideal is principal
   #+END_exercise

   #+BEGIN_proof
   3. [@3] \(ee''=e^2=e\)
   #+END_proof

   #+BEGIN_exercise
   label:ex1.25
   Let \(L\) be a *lattice*, that is, a partially ordered set in which every pair
   \(x,y\in L\) has a sup \(x\vee y\) and an inf \(x\wedge y\). Assume \(L\) is
   *Boolean*; that is:
   1. \(L\) has a least element 0 and a greatest element 1
   2. The operations \(\vee\) and \(\wedge\) *distribute* over each other
      \begin{equation*}
      x\wedge(y\vee z)=(x\wedge y)\vee(x\wedge z)
      \quad\text{ and }\quad
      x\vee(y\wedge z)=(x\vee y)\wedge(x\vee z)
      \end{equation*}
   3. Each \(x\in L\) has a unique *complement* \(x'\); that is, \(x\wedge x'=0\)
      and \(x\vee x'=1\) .

      
   Show that the following six laws obeyed
   #+ATTR_LATEX: :align rclr
   | \(x\wedge x=x\)                          | and | \(x\vee x=x\)                    | *(idempotent)*  |
   | \(x\wedge0=0,x\wedge1=x\)                | and | \(x\vee1=1,x\vee0=x\)            | *(unitary)*     |
   | \(x\wedge y=y\wedge x\)                  | and | \(x\vee y=y\vee x\)              | *(commutative)* |
   | \(x\wedge(y\wedge z)=(x \wedge y)\wedge z\) | and | \(x\vee(y\vee z)=(x\vee y)\vee z\) | *(associative)* |
   | \(x''=x\)                                | and | \(0'=1,1'=0\)                    | *(involutory)*  |
   | \((x\wedge y)'=x'\vee y'\)               | and | \((x\vee y)'=x'\wedge y'\)       | *(De Morgan's)* |

   Moreover, show that \(x\le y\) iff \(x=x\wedge y\)
   #+END_exercise

   #+BEGIN_exercise
   label:ex1.26
   Let \(L\) be a Boolean lattice. For all \(x,y\in L\), set
   \begin{equation*}
   x+y:=(x\wedge y')\vee(x'\wedge y)\quad\text{ and }\quad
   xy:=x\wedge y
   \end{equation*}
   Show
   1. \(x+y=(x\vee y)(x'\vee y')\)
   2. \((x+y)'=(x'y')\vee(xy)\)
   3. \(L\) is a Boolean ring
   #+END_exercise

   #+BEGIN_exercise
   label:ex1.27
   Given a Boolean ring \(R\), order \(R\) by \(x\le y\) if \(x=xy\). Show \(R\)
   is thus a Boolean lattice. Viewing this construction as a map \rho from the set
   of Boolean-ring structures on the set \(R\) to the set of Boolean-lattice
   structures on \(R\), show \rho is bijective with inverse the map \lambda associated to
   the construction in ref:ex1.26
   #+END_exercise

   #+BEGIN_proof
   First check \(R\) is partially ordered.

   Given \(x,y\in R\), set \(x\vee y:=x+y+xy\) and \(x\wedge y:=xy\). Then
   \(x\le x\vee y\) as \(x(x+y+xy)=x^2+xy+x^2y=x+2xy=x\). If \(z\le x\) and
   \(z\le y\), then \(z=zx\) and \(z=zy\), and so \(z(x\vee y)=z\); thus \(z\le
   x\vee y\)
   #+END_proof

   #+BEGIN_exercise
   label:ex1.28
   Let \(X\) be a set, and \(L\) the set of all subsets of \(X\), partially
   ordered by inclusion. Show that \(L\) is a Boolean lattice and that the ring
   structure on \(L\) constructed in ref:sec1.2 coincides with that constructed
   in ref:ex1.26

   Assume \(X\) is a topological space, and let \(M\) be the set of all its open
   and closed subsets. Show that \(M\) is a sublattice of \(L\), and that the
   subring structure on \(M\) of ref:sec1.2 coincides with the ring structure of
   ref:ex1.26 with \(M\) for \(L\)
   #+END_exercise

* Prime Ideals

** Zerodivisors
   Let \(R\) be a ring. An element \(x\) is called a *zerodivisor* if there is a
   nonzero \(y\) with \(xy=0\); otherwise \(x\) is called a *nonzerodivisor*.
   Denote the set of zerodivisors by \(\zdiv(R)\) and the set of nonzerodivisor
   by \(S_0\)

** Multiplicative subsets, prime ideals
   Let \(R\) be a ring. A subset \(S\) is called *multiplicative* if \(1\in S\)
   and if \(x,y\in S\) implies \(xy\in S\)

   An ideal \(\fp\) is called *prime* if its complement \(R-\fp\) is
   multiplicative, or equivalently, if \(1\not\in\fp\) and if \(xy\in\fp\)
   implies \(x\in\fp\) or \(y\in\fp\)

** Fields, domains
   A ring is called a *field* if \(1\neq0\) and if every nonzero element is a
   unit.

   A ring is called an *integral domain*, or simply a *domain*, if \(\la0\ra\) is
   prime, or equivalently, if \(R\) is nonzero and has no nonzero zerodivisors.

   Every domain \(R\) is a subring of its *fraction field* \(\Frac(R)\).
   Conversely, any subring \(R\) of a field \(K\), including \(K\) itself, is a
   domain. Further, \(\Frac(R)\) has this UMP: the inclusion of \(R\) into any
   field \(L\) extends uniquely to an inclusion of \(\Frac(R)\) into \(L\).


** Polynomials over a domain
   Let \(R\) be a domain, \(\calx:=\{X_\lambda\}_{\lambda\in\Lambda}\) a set of
   variables. Set \(P:=R[\calx]\). Then \(P\) is a domain too. In fact, given
   nonzero \(F,G\in P\), not only is their product \(FG\) nonzero, but also given
   a well ordering of the variables, the grlex leading term of \(FG\) is the
   product of the grlex leading terms of \(F\) and \(G\), and
   \begin{equation*}
   \deg(FG)=\deg(F)+\deg(G)\label{eq2.4.1}
   \end{equation*}
   Using the given ordering of the variables, well order all the monomials
   \(\bM\) of the same degree via the lexicographic order on exponents. Among
   the \(\bM\) in \(F\) with \(\deg(\bM)=\deg(F)\), the largest is called the
   *grlex leading monomial* (graded lexicographic) of \(F\). Its *grlex leading
   term* is the product \(a\bM\) whre \(a\in R\) is the coefficient of \(\bM\) in
   \(F\), and \(a\) is called the *grlex leading coefficient*

   /The grlex leading term of \(FG\) is the product of those \(a\bM\) and/
   /\(b\bN\) of \(F\) and \(G\)/. and ref:eq2.4.1 holds, for the following
   reasons. First, \(ab\neq0\) as \(R\) is domain. Second
   \begin{equation*}
   \deg(\bM\bN)=\deg(\bM)+\deg(\bN)=\deg(F)+\deg(G)
   \end{equation*}
   Third, \(\deg(\bM\bN)\ge\deg(\bM'\bN')\) for every pair of monomials \(\bM'\)
   and \(\bN'\) in \(F\) and \(G\).

   /The grlex hind term of \(FG\) is the product of the grlex hind terms of/
   /\(F\) and \(G\)./ Further, given a vector \((x_\lambda)\in R^\Lambda\), then
   \begin{equation*}
   \ord_{(x_\lambda)}FG=\ord_{(x_\lambda)}F+\ord_{(x_\lambda)}G
   \end{equation*}
   Among the monomials \(\bM\) in \(F\) with \(\ord(\bM)=\ord(F)\), the smallest
   is called the *grlex hind monomial* of \(F\). The *grlex hind term* of \(F\) os
   the product \(a\bM\) where \(a\in R\) is the coefficient of \(\bM\) in \(F\)

   The fraction field \(\Frac(P)\) is called the field of *rational functions*,
   and is also denoted by \(K(\calx)\) where \(K:=\Frac(R)\)

** Unique factorization
   Let \(R\) be a domain, \(p\) a nonzero nonunit. We call \(p\) *prime* if
   whenever \(p\mid xy\), either \(p\mid x\) or \(p\mid y\).
   /\(p\) is prime iff \(\la p\ra\) is prime/

   We call \(p\) *irreducible* if whenever \(p=yz\), either \(y\) or \(z\) is a
   unit. We call \(R\) a *Unique Factorization Domain* (UFD) if
   1. every nonzero nonunit factors into a product of irreducibles
   2. the factorization is unique up to order and units.


   If \(R\) is a UFD, then \(\gcd(x,y)\) always exists

   #+ATTR_LATEX: :options []
   #+BEGIN_lemma
   Let \(\varphi:R\to R'\) be a ring map, and \(T\subset R'\) a subset. If \(T\) is
   multiplicative, then \(\varphi^{-1}T\) is multiplicative; the converse holds if \varphi
   is surjective
   #+END_lemma

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   label:prop2.7
   Let \(\varphi:R\to R'\) be a ring map, and \(\fq\subset R'\) an ideal. Set
   \(\fp:=\varphi^{-1}\fq\). If \(\fq\) is prime, then \(\fp\) is prime; the
   converse holds if \varphi is surjective
   #+END_proposition

   #+ATTR_LATEX: :options []
   #+BEGIN_corollary
   Let \(R\) be a ring, \(\fp\) an ideal. Then \(\fp\) is prime iff \(R/\fp\) is
   a domain
   #+END_corollary

   #+BEGIN_proof
   By Proposition ref:prop2.7, \(\fp\) is prime iff \(\la0\ra\subset R/\fp\) is
   #+END_proof

   #+BEGIN_exercise
   label:ex2.9
   Let \(R\) be a ring, \(P:=R[\calx,\caly]\) the polynomial ring in two sets of
   variables \(\calx\) and \(\caly\). Set \(\fp:=\la\calx\ra\). Show \(\fp\) is
   prime iff \(R\) is a domain
   #+END_exercise

   #+BEGIN_proof
   \(\fp\) is prime iff \(R[\caly]\) is a domain
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   Let \(R\) be a ring. An ideal \(\fm\) is said to be *maximal* if \(\fm\) is
   proper and if there is no proper ideal \(\fa\) with \(\fm\subsetneq\fa\)
   #+END_definition

   #+ATTR_LATEX: :options []
   #+BEGIN_examplle
   Let \(R\) be a domain, \(R[X,Y]\) the polynomial ring. Then \(\la X\ra\) is
   prime. However, \(\la X\ra\) is not maximal since \(\la X\ra\subsetneq\la X,Y\ra\)
   #+END_examplle

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   label:2.12
   A ring \(R\) is a field iff \(\la0\ra\) is a maximal ideal
   #+END_proposition

   #+BEGIN_proof
   If \(\la0\ra\) is  maximal. Take \(x\neq0\), then \(\la x\ra\neq0\). So \(\la
   x\ra=R\) and \(x\) is a unit.
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_corollary
   label:2.13
   Let \(R\) be a ring, \(\fm\) an ideal. Then \(\fm\) is maximal iff \(R/\fm\)
   is a field.
   #+END_corollary

   #+BEGIN_proof
   \(\fm\) is maximal iff \(\la0\ra\) is maximal in \(R/\fm\) by Correspondence Theorem.
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_examplle
   Let \(R\) be a ring, \(P\) the polynomial ring in variable \(X_\lambda\), and
   \(x_\lambda\in R\) for all \lambda. Set \(\fm:=\la\{X_\lambda-x_\lambda\}\ra\).
   Then \(P/\fm=R\) by Exercise ref:ex1.17. Thus \(\fm\) is maximal iff \(R\) is a field
   #+END_examplle

   #+ATTR_LATEX: :options []
   #+BEGIN_corollary
   In a ring, every maximal ideal is prime
   #+END_corollary

** Coprime elements label:2.16
   Let \(R\) be a ring and \(x,y\in R\). We say \(x\) and \(y\) are *(strictly)
   coprime* if their ideals \(\la x\ra\) and \(\la y\ra\) are comaximal

   Plainly, \(x\) and \(y\) are coprime iff there are \(a,b\in R\) s.t.
   \(ax+by=1\)

   Plainly, \(x\) and \(y\) are coprime iff there is \(b\in R\) with
   \(by\equiv1\mod\la x\ra\) iff the residue of \(y\) is a unit in \(R/\la x\ra\)

   Fix \(m,n\ge1\). By Exercise ref:ex1.21, \(x\) and \(y\) are coprim eiff
   \(x^m\) and \(x^n\) are.

   If \(x\) and \(y\) are coprime, then their images in algebra \(R'\) too.

** PIDs
   A domain \(R\) is called a *Principal Ideal Domain* (PID) if every ideal is
   principal. A PID is a UFD

   Let \(R\) be a PID, \(\fp\) a nonzero prime ideal. Say \(\fp=\la p\ra\). Then
   \(p\) is prime, so irreducible. Now let \(q\in R\) be irreducible. Then \(\la
   q\ra\) is maximal for: if \(\la q\ra\subsetneq\la x\ra\), then \(q=xy\) for
   some nonunit \(y\); so \(x\) must be a unit as \(q\) is irreducible. So
   \(R/\la q\ra\) is a field. Also \(\la q\ra\) is prime; so \(q\) is prime
   Thus every irreducible element is prime, and every
   nonzero prime ideal is maximal

   #+BEGIN_exercise
   label:2.18
   Show that, in a PID, nonzero elements \(x\) and \(y\) are *relatively prime*
   (share no prime factor) iff they are coprime
   #+END_exercise

   #+BEGIN_proof
   Say \(\la x\ra+\la y\ra=\la d\ra\). Then \(d=\gcd(x,y)\)
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_examplle
   Let \(R\) be a PID, and \(p\in R\) a prime. Set \(k:=R/\la p\ra\). Let \(X\)
   be a variable, and set \(P:=R[X]\). Take \(G\in P\); let \(G'\) be its image
   in \(k[X]\); assume \(G'\) is irreducible. Set \(\fm:=\la p,G\ra\). Then
   \(P/\fm\simeq k[X]/\la G'\ra\) by ref:ex1.16 and ref:1.9 and \(k[X]/\la
   G'\ra\) is a field; hence
   \(\fm\) is maximal
   #+END_examplle

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   label:2.20
   Let \(R\) be a PID. Let \(P:=R[X]\) and \(\fp\) a nonzero prime ideal of
   \(P\)
   1. \(\fp=\la F\ra\) with \(F\) prime or \(\fp\) is maximal
   2. Assume \(\fp\) is maximal. Then either \(\fp=\la F\ra\) with \(F\) prime,
      or \(\fp=\la p,G\ra\) with \(p\in R\) prime, \(pR=\fp\cap R\) and \(G\in
      P\) prime with image \(G'\in(R/pR)[X]\) prime
   #+END_theorem

   #+BEGIN_proof
   \(P\) is a UFD.

   If \(\fp=\la F\ra\) for some \(F\in P\), then \(F\) is prime. Assume \(\fp\)
   isn't principal

   Take a nonzero \(F_1\in\fp\). Since \(\fp\) is prime, \(\fp\) contains a
   prime factor \(F_1'\) of \(F_1\). Replace \(F_1\) by \(F_1'\). As \(\fp\)
   isn't principal, \(\fp\neq\la F_1\ra\). So there is a prime \(F_2\in\fp-\la
   F_1\ra\).
   Set \(K:=\Frac(R)\), Gauss's lemma implies that \(F_1\) and \(F_2\) are also
   prime in \(K[X]\). So \(F_1\) and \(F_2\) are relatively prime in \(K[X]\).
   So ref:2.18 yield \(G_1,G_2\in P\) and \(c\in P\) with
   \((G_1/c)F_1+(G_2/c)F_2=1\). So \(c=G_1F_1+G_2F_2\in R\cap\fp\). Hence
   \(R\cap\fp\neq0\). But \(R\cap\fp\) is prime, and \(R\) is a PID; so
   \(R\cap\fp=pR\) where \(p\) is prime. Also \(pR\) is maximal.

   Set \(k:=R/pR\). Then \(k\) is a field. Set \(\fq:=\fp/pR\subset k[X]\). Then
   \(k[X]/\fq=P/\fp\) by ref:1.9. But \(\fp\) is prime, so \(P/\fp\) is a
   domain. So \(k[X]/\fq\) is a domain too. So \(\fq\) is prime. So \(\fq\) is
   maximal. So \(\fp\) is maximal.

   Since \(k[X]\) is a PID and \(\fq\) is prime, \(\fq=\la G'\ra\) where \(G'\)
   is prime in \(k[X]\). Take \(G\in\fp\)  with image \(G'\)
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   Every proper ideal \(\fa\) is contained in some maximal ideal
   #+END_theorem

   #+BEGIN_proof
   Set \(\cals:=\{\text{ideals }\fb\mid\fb\supset\fa\text{ and }\fb\not\ni1\}\).
   Then \(\fa\in\cals\) and \(\cals\) is partially ordered by inclusion. By
   Zorn's Lemma
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_corollary
   label:2.22
   Let \(R\) be a ring, \(x\in R\). Then \(x\) is a unit iff \(x\) belongs to no
   maximal ideal
   #+END_corollary


** Exercise
   #+BEGIN_exercise
   label:2.23
   Let \(\fa\) and \(\fb\) be ideals, and \(\fp\) a prime ideal. Prove that
   these conditions are equivalent
   1. \(\fa\subset\fp\) or \(\fb\subset\fp\)
   2. \(\fa\cap\fb\subset\fp\)
   3. \(\fa\fb\subset\fp\)
   #+END_exercise

   #+BEGIN_exercise
   label:2.24
   Let \(R\)  be a  ring, \(\fp\) a prime ideal, and \(\fm_1,\dots,\fm_n\)
   maximal ideals. Assume \(\fm_1\dots\fm_n=0\). Show \(\fp=\fm_i\) for some \(i\)
   #+END_exercise

   #+BEGIN_proof
   Note \(\fp\supset0=\fm_1\dots\fm_n\). So \(\fp\supset\fm_1\) or
   \(\fp\supset\fm_2\dots\fm_n\) by ref:2.23
   #+END_proof

   #+BEGIN_exercise
   label:2.25
   Let \(R\) be a ring, and \(\fp,\fa_1,\dots,\fa_n\) ideals with \(\fp\) prime
   1. Assume \(\fp\supset\bigcap_{i=1}^n\fa_i\). Show \(\fp\supset\fa_j\) for
      some \(j\)
   2. Assume \(\fp=\bigcap_{i=1}^n\fa_i\). Show \(\fp=\fa_j\) for some \(j\)
   #+END_exercise

   #+BEGIN_exercise
   label:2.26
   Let \(R\) be a ring, \(\cals\) the set of all ideals that consist entirely of
   zerodivisors. Show that \(\cals\) has maximal elements and they're prime.
   Conclude that \(\zdiv(R)\) is a union of primes.
   #+END_exercise

   #+BEGIN_proof
   Order \(\cals\) by inclusion. \(\cals\) is not empty. \(\cals\) consists of a
   maximal element \(\fp\).

   Given \(x,x'\in R\) with \(xx'\in\fp\), but \(x,x'\not\in\fp\). Hence \(\la
   x\ra+\fp,\la x'\ra+\fp\not\in\cals\). So there are \(a,a'\in R\) and
   \(p,p'\in\fp\)  s.t. \(y:=ax+p\) and \(y':=a'x'+p'\) are not zerodivisors. Then
   \(yy'\in\fp\). So \(yy'\in\zdiv(R)\), a contradiction. Thus \(\fp\) is prime.

   Given \(x\in\zdiv(R)\), note \(\la x\ra\in\cals\). So \(\la x\ra\) lies in a
   maximal element \(\fp\) of \(\cals\). Thus \(x\in\fp\) and \(\fp\) is prime
   #+END_proof

   #+BEGIN_exercise
   label:2.27
   Given a prime number \(p\) and an integer \(n\ge2\), prove that the residue
   ring \(\Z/\la p^n\ra\) does not contain a domain as a subring
   #+END_exercise

   #+BEGIN_proof
   Any subring of \(\Z/\la p^n\ra\) must contain 1, and \(1\) generates \(\Z/\la
   p^n\ra\) as an Abelian group. So \(\Z/\la p^n\ra\) contains no proper subrings.
   #+END_proof

   #+BEGIN_exercise
   label:2.28
   Let \(R:=R'\times R''\) be a product of two rings. Show that \(R\) is a
   domain if and only if either \(R'\) or \(R''\) is a domain and the other 0
   #+END_exercise

   #+BEGIN_proof
   Assume \(R\) is a domain. As \((1,0)\cdot(0,1)=(0,0)\), either \(R'\) or
   \(R''\) is 0.
   #+END_proof

   #+BEGIN_exercise
   label:2.29
   Let \(R:=R'\times R''\) be a product of rings, \(\fp\subset R\) an ideal.
   Show \(\fp\) is prime iff either \(\fp=\fp'\times R''\) with \(\fp'\subset
   R'\) prime or \(\fp=R'\times\fp''\) with \(\fp''\subset R''\) prime
   #+END_exercise

   #+BEGIN_proof
   \(1\in\fp\). \((1,0)(0,1)\in\fp\). Hence \((1,0)\in\fp\) or \((0,1)\in\fp\).
   #+END_proof

   #+BEGIN_exercise
   label:2.30
   Let \(R\) be a domain, and \(x,y\in R\). Assume \(\la x\ra=\la y\ra\). Show
   \(x=uy\) for some unit \(u\)
   #+END_exercise

   #+BEGIN_proof
   \((1-tu)y=0\) and domain
   #+END_proof

   #+BEGIN_exercise
   label:2.31
   Let \(k\) be a field, \(R\) a nonzero ring, \(\varphi:k\to R\) a ring map. Prove \varphi
   is injective
   #+END_exercise

   #+BEGIN_proof
   Since \(1\neq0\), \(\ker(\varphi)\neq k\). And by ref:2.12, \(\ker(\varphi)=0\) and hence
   \varphi is injective
   #+END_proof

   #+BEGIN_exercise
   label:2.32
   Let \(R\) be a ring, \(\fp\) a prime, \(\calx\) a set of variables. Let
   \(\fp[\calx]\) denote the set of polynomials with coefficients in \(\fp\).
   Prove
   1. \(\fp R[\calx]\) and \(\fp[\calx]\) and \(\fp R[\calx]+\la\calx\ra\) are
      primes of \(R[\calx]\), which contract to \(\fp\)
   2. Assume \(\fp\) is maximal. Then \(\fp R[\calx]+\la\calx\ra\) is maximal
   #+END_exercise

   #+BEGIN_proof
   1. \(R/\fp\) is a domain. \(\fp R[\calx]=\fp[\calx]\) by ref:1.15.

      \((\fp R[\calx]+\la\calx\ra/\fp R[\calx])\) is equal to
      \(\la\calx\ra\subset(R/\fp)[\calx]\). \((R/\fp)\la\calx\ra/\la\calx\ra\)
      is equal to \(R/\fp\). Hence
      \(R[X]/(\fp R[\calx]+\la\calx\ra)=(R[x]/\fp R[X])/((\fp
      R[\calx]+\la\calx\ra)/\fp R[X])=R/\fp\)

      Since the canonical map \(R/\fp\to R[\calx]/(\fp R[\calx]+\la\calx\ra)\)
      is bijective, it's injective.

   2. \(R/\fp\simeq R[\calx]/(\fp R[\calx]+\la\calx\ra)\)
   #+END_proof

   #+BEGIN_exercise
   label:2.33
   Let \(R\) be a ring, \(X\) a variable, \(H\in P:=R[X]\) and \(a\in R.\)Given
   \(n\ge1\), show \((X-a)^n\) and \(H\) are coprime iff \(H(a)\) is a unit.
   #+END_exercise

   #+BEGIN_proof
   \((X-a)^n\) and \(H\) are coprime iff \(X-a\) and \(H\) are coprime.
   \(R[x]/\la X-a\ra=\la H\ra/\la X-a\ra\), which implies the residue of \(H\)
   modulo \(X-a\) is a unit. Hence \(H(a)\) is a unit.
   #+END_proof

   #+BEGIN_exercise
   label:2.34
   Let \(R\) be a ring, \(X\) a variable, \(F\in P:=R[X]\), and \(a\in R\). Set
   \(F':=\partial F/\partial X\). Show the following statements are equivalent
   1. \(a\) is a supersimple root of \(F\)
   2. \(a\) is a root of \(F\), and \(X-a\) and \(F'\) are coprime
   3. \(F=(X-a)G\) for some \(G\) in \(P\) coprime to \(X-a\)


   Show that if (3) holds, then \(G\) is unique
   #+END_exercise

   #+BEGIN_exercise
   label:2.35
   Let \(R\) be a ring, \(\fp\) a prime; \(\calx\) a set of variables; \(F,G\in
   R[\calx]\). Let \(c(F)\), \(c(G)\), \(c(FG)\) be the ideals of \(R\)
   generated by the coefficients of \(F,G,FG\)
   1. Assume \(\fp\) doesn't contain either \(c(F)\) or \(c(G)\). Show \(\fp\)
      doesn't contain \(c(FG)\)
   2. Assume \(c(F)=R\) and \(c(G)=R\). Show \(c(FG)=R\)
   #+END_exercise

   #+BEGIN_proof
   1. Denote the residues of \(F,G,FG\)  in \((R/\fp)[\calx]\) by
      \(\overbar{F}\), \(\overbar{G}\) and \(\overbar{FG}\). Since
      \(\fp\not\supset c(F),c(G)\), \(\overbar{F},\overbar{G}\neq0\). Since
      \(R/\fp\) is a domain, so is \((R/\fp)[\calx]\) and we have
      \(\overbar{F}\overbar{G}\neq0\). Note that
      \(\overbar{F}\overbar{G}=\overbar{FG}\), we have \(\overbar{FG}\neq0\).
   2. Assume \(c(F)=c(G)=R\), since \(\fp\not\supset c(F),c(G)\) we have
      \(\fp\not\supset c(FG)\) for any prime ideals \(\fp\). Hence \(c(FG)=R\).

      If \(c(FG)=R\), \(c(FG)\subset c(F)\)
   #+END_proof

   #+BEGIN_exercise
   label:2.36
   Let \(B\) be a Boolean ring. Show that every prime \(\fp\) is maximal, and
   that \(B/\fp=\F_2\)
   #+END_exercise

   #+BEGIN_proof
   \(x(x-1)=0\) in \(B/\fp\). Since \(B/\fp\) is a domain, \(x=0\) or \(x=1\).
   #+END_proof

   #+BEGIN_exercise
   label:2.37
   Let \(R\) be a ring. Assume that, given any \(x\in R\), there is an
   \(n\ge2\) with \(x^n=x\). Show that every prime \(\fp\) is maximal
   #+END_exercise

   #+BEGIN_proof
   Same. Every element has an inverse
   #+END_proof

   #+BEGIN_exercise
   label:2.38
   Prove the following statements or give a counterexample
   1. The complement of a multiplicative subset is a prime ideal
   2. Given two prime ideals, their intersection is prime
   3. Given two prime ideals, their sum is prime
   4. Given a ring map \(\varphi:R\to R'\), the operation \(\varphi^{-1}\) carries maximal
      ideals of \(R'\) to maximal ideals of \(R\)
   5. An ideal \(\fm'\subset R/\fa\) is maximal iff \(\kappa^{-1}\fm'\subset R\) is
      maximal in ref:1.9

   #+END_exercise

   #+BEGIN_proof
   1. 0 can be belongs to the multiplicative subset
   2. False. In \(\Z\), \(\la2\ra\cap\la3\ra=\la6\ra\)
   3. False. In \(\Z\), \(\la2\ra+\la3\ra=\Z\)
   4. False. Consider \(\varphi:\Z\to\Q\). \(\varphi^{-1}(\la0\ra)=\la0\ra\)
   5. 
   #+END_proof

* Radicals
  #+ATTR_LATEX: :options []
  #+BEGIN_definition
  Let \(R\) be a ring. Its (Jacobson) *radical* \(\rad(R)\) is defined to be the
  intersection of all its maximal ideals
  #+END_definition

  #+ATTR_LATEX: :options []
  #+BEGIN_proposition
  label:3.2
  Let \(R\) be a ring, \(\fa\) an ideal, \(x\in R,u\in R^\times\). Then
  \(x\in\rad(R)\) iff \(u-xy\in R^\times\) for all \(x\in R\). In particular,
  the sum of an element of \(\rad(R)\) and a unit is a unit, and
  \(\fa\subset\rad(R)\) if \(1-\fa\in R^\times\)
  #+END_proposition

  #+BEGIN_proof
  Assume \(x\in\rad(R)\). Given a maximal ideal \(\fm\), suppose \(u-xy\in\fm\).
  Since \(x\in\fm\) too, also \(u\in\fm\), a contradiction. Thus \(u-xy\) is a
  unit by ref:2.22. In particular, tkaing \(y:=-1\) yields \(u+x\in R^\times\)

  Conversely, assume \(x\not\in\rad(R)\). Then there is a maximal ideal \(\fm\)
  with \(x\not\in\fm\). So \(\la x\ra+\fm=R\). Hence there exists \(y\in R\) and
  \(m\in\fm\) s.t. \(xy+m=u\). Then \(u-xy=m\in\fm\). A contradiction

  In particular, given \(y\in R\), set \(a:=u^{-1}xy\). Then \(u-xy=u(1-a)\in
  R^\times\) if \(1-a\in R^\times\)
  #+END_proof

  #+ATTR_LATEX: :options []
  #+BEGIN_corollary
  label:3.3
  Let \(R\) be a ring, \(\fa\) an ideal, \(\kappa:R\to R/\fa\) the quotient map.
  Assume \(\fa\subset\rad(R)\). Then \(\Idem(\kappa)\) is injective
  #+END_corollary

  #+BEGIN_proof
  Given \(e,e'\in\Idem(R)\) with \(\kappa(e)=\kappa(e')\), set \(x:=e-e'\). Then
  \begin{equation*}
  x^3=e-e'=x
  \end{equation*}
  Hence \(x(1-x^2)=0\). But \(\kappa(x)=0\); so \(x\in\fa\). But
  \(\fa\subset\rad(R)\). Hence \(1-x^2\) is a unit by ref:3.2. Thus \(x=0\).
  Thus \(\Idem(\kappa)\) is injective
  #+END_proof

  #+ATTR_LATEX: :options []
  #+BEGIN_definition
  A ring is called *local* if it has exactly one maximal ideal, and *semilocal* if
  it has at least one and at most finitely many

  By the *residue field* of a local ring \(A\), we mean the field \(A/\fm\) where
  \(\fm\) is the maximal ideal of \(A\)
  #+END_definition

  #+ATTR_LATEX: :options [Nonunit Criterion]
  #+BEGIN_lemma
  label:3.5
  Let \(A\) be a ring, \(\fn\) the set of nonunits. Then \(A\) is local iff
  \(\fn\) is an ideal; if so, then \(\fn\) is the maximal ideal
  #+END_lemma

  #+BEGIN_proof
  Assume \(A\) is local with maximal ideal \(\fm\). Then \(A-\fn=A-\fm\) by
  ref:2.22. Thus \(\fn\) is an ideal
  #+END_proof

  #+ATTR_LATEX: :options []
  #+BEGIN_examplle
  The product ring \(R'\times R''\) is not local by ref:3.5 if both \(R'\) and
  \(R''\) are nonzero. \((1,0)\) and \((0,1)\) are nonunits, but their sum is a unit.
  #+END_examplle

  #+ATTR_LATEX: :options []
  #+BEGIN_examplle
  Let \(R\) be a ring. A *formal power series* in the \(n\) variables
  \(X_1,\dots,X_n\) is a formal /infinite/ sum of the form \(\sum
  a_{(i)}X_1^{i_1}\dots X_n^{i_n}\) where \(a_{(i)}\in R\) and where
  \((i):=(i_1,\dots,i_n)\) with each \(i_j\ge0\). The term \(a_{(0)}\) where
  \((0):=(0,\dots,0)\) is called the *constant term*. Addition and multiplication
  are performed as for polynomials; with these operations, these series form a
  ring \(R[[X_1,\dots,X_n]]\)

  Set \(P:=R[[X_1,\dots,X_n]]\) and \(\fa:=\la X_1,\dots,X_n\ra\). Then \(\sum
  a_{(i)}X_1^{i_1}\dots X_n^{i_n}\mapsto a_{(0)}\) is a canonical surjective
  ring map \(P\to R\) with kernel \(\fa\); hence \(P/\fa=R\)

  Given an ideal \(\fm\subset R\), set \(\fn:=\fa+\fm P\). Then ref:1.9 yields
  \(P/\fn=R/\fm\)

  A power series \(F\) is a unit iff its constant term is a unit. If \(a_{(0)}\)
  is a unit, then \(F=a_{(0)}(1-G)\) with \(G\in\fa\). Set
  \(F':=a_{(0)}^{-1}(1+G+G^2+\dots)\);

  Suppose \(R\) is a local ring with maximal ideal \(\fm\). Given a power series
  \(F\not\in\fn\), its constant term lies outside \(\fm\), so is a unit. So
  \(F\) is itself a unit. Hence the nonunits constitutes \(\fn\). Thus \(P\) is
  local.
  #+END_examplle

  #+ATTR_LATEX: :options []
  #+BEGIN_examplle
  Let \(k\) be a ring, and \(A:=k[[X]]\) the formal power series ring in one
  variables. A *formal Laurent series* is a formal sum of the form
  \(\sum_{i=-m}^\infty a_iX^i\) with \(a_i\in k\) and \(m\in\Z\). Plainly, these
  seires form a ring \(k\{\{X\}\}\). Set \(K:=k\{\{X\}\}\)

  Set \(F:=\sum_{i=-m}^\infty a_iX^i\). If \(a_{-m}\in k^\times\), then \(F\in
  K^\times\); indeed, \(F=a_{-m}X^{-m}(1-G)\) where \(G\in A\) and

  Assume \(k\) is a field. If \(F\neq0\), then \(F=X^{-m}H\) with
  \(H:=a_{-m}(1-G)\in A^\times\). Let \(\fa\subset A\) be a nonzero ideal.
  Suppose \(F\in\fa\). Then \(X^{-m}\in\fa\). Let \(n\) be the smallest integer
  s.t. \(X^n\in\fa\). Then \(-m\ge n\). Set \(E:=X^{-m-n}H\). Then \(E\in A\)
  and \(F=X^nE\). Hence \(\fa=\la X^n\ra\). Thus \(A\) *is a* PID

  Further, \(K\) is a field. In fact, \(K=\Frac(A)\).

  Let \(A[Y]\) be the polynomial ring in one variable, and \(\iota:A\hookrightarrow
  K\) the inclusion.
  Define \(\varphi:A[Y]\to K\) by \(\varphi|A=\iota\) and \(\varphi(Y)=X^{-1}\). Then \varphi is
  surjective. Set \(\fm:=\ker(\varphi)\). Then \(\fm\) is maximal. So by ref:2.20
  \(\fm\) has the form \(\la F\ra\) with \(F\) irreducible, or the form \(\la
  p,G\ra\) with \(p\in A\) irreducible and \(G\in A[Y]\). But \(\fm\cap
  A=\la0\ra\) as \iota is injective. So \(\fm=\la F\ra\). But \(XY-1\) belongs to
  \(\fm\), and is clearly irreducible; hence \(XY-1=FH\) with \(H\) a unit. Thus
  \(\la XY-1\ra\) is maximal

  In addition, \(\la X,Y\ra\) is maximal. Indeed, \(A[Y]/\la X,Y\ra=A/\la
  X\ra=k\). Howevery ,\(\la X,Y\ra\) is not principal, as no nonunit of \(A[Y]\)
  divides both \(X\) and \(Y\). Thus \(A[Y]\) /has both principal and
  nonprincipal maximal ideals, two types allows by ref:2.20/
  #+END_examplle

  #+ATTR_LATEX: :options []
  #+BEGIN_proposition
  label:3.9
  Let \(R\) be a ring, \(S\) a multiplicative subset, and \(\fa\) an ideal with
  \(\fa\cap S=\emptyset\). Set \(\cals:=\{\text{ideals
  }\fb\mid\fb\supset\fa\text{ and }\fb\cap S=\emptyset\}\). Then \(\cals\) has a
  maximal element \(\fp\), and every such \(\fp\) is prime
  #+END_proposition

  #+BEGIN_proof
  Take \(x,y\in R-\fp\). Then \(\fp+\la x\ra\) and \(\fp+\la y\ra\) are strictly
  larger than \(\fp\). So there are \(p,q\in\fp\) and \(a,b\in R\) with
  \(p+ax,q+by\in S\). Hence \(pq+pby+qax+abxy\in S\). But \(pq+pby+qax\in\fp\),
  so \(xy\not\in\fp\). Thus \(\fp\) is prime
  #+END_proof

  #+BEGIN_exercise
  label:3.10
  Let \(\varphi:R\to R'\) be a ring map, \(\fp\) an ideal of \(R\). Show
  1. there is an ideal \(\fq\) of \(R'\) with \(\varphi^{-1}(\fq)=\fp\) iff
     \(\varphi^{-1}(\fp R')=\fp\)
  2. if \(\fp\) is prime with \(\varphi^{-1}(\fp R')=\fp\), then there is a prime
     \(\fq\) of \(R'\) with \(\varphi^{-1}(\fq)=\fp\)
  #+END_exercise

** Saturated multiplicative subsets
   Let \(R\) be a ring, and \(S\) a multiplicative subset. We say \(S\) is
   *saturated* if given \(x,y\in R\) with \(xy\in S\), necessarily \(x,y\in S\)

   #+ATTR_LATEX: :options [Prime Avoidance]
   #+BEGIN_lemma
   Let \(R\) be a ring, \(\fa\) a subset of \(R\) that is stable under addition
   and multiplication, and \(\fp_1,\dots,\fp_n\) ideals s.t.
   \(\fp_3,\dots,\fp_n\) are prime. If \(\fa\not\subset\fp_j\) for all \(j\),
   then there is an \(x\in\fa\) s.t. \(x\not\in\fp_j\) for all \(j\); or
   equivalently, if \(\fa\subset\bigcup_{i=1}^n\fp_i\), then \(\fa\subset\fp_i\)
   for some \(i\)
   #+END_lemma

   #+BEGIN_proof
  Assume there is an \(x_i\in\fa\) s.t. \(x_i\not\in\fp_j\) for all
   \(i\neq j\)and \(x_i\in\fp_i\) for every \(i\). If \(n=2\) then clearly
   \(x_1+x_2\not\in\fp_j\) for \(j=1,2\). If \(n\ge3\), then \((x_1\dots
   x_{n-1})+x_n\not\in\fp_j\) for all \(j\) as, if \(j=n\), then \(x_n\in\fp_n\)
   and \(\fp_n\) is prime.
   #+END_proof

** Other radicals
   Let \(R\) be a ring, \(\fa\) a subset. Its *radical* \(\sqrt{\fa}\) is the set
   \begin{equation*}
   \sqrt{\fa}:=\{x\in R\mid x^n\in\fa\text{ for some }n\ge1\}
   \end{equation*}
   If \(\fa\) is an ideal and \(\fa=\sqrt{\fa}\), then \(\fa\) is said to be
   *radical*. For example, suppose \(\fa=\bigcap\fp_\lambda\) with all
   \(\fp_\lambda\) prime. If \(x^n\in\fa\) for some \(n\ge1\), then
   \(x\in\fp_\lambda\). Thus \(\fa\) is radical. Hence two radicals coincide

   We call \(\sqrt{\la0\ra}\) the *nilradical*, and sometimes denote it by
   \(\nil(R)\). We call an element \(x\in R\) *nilpotent* if \(x\) belongs to
   \(\sqrt{\la0\ra}\). We call an ideal \(\fa\) *nilpotent* if \(\fa^n=0\) for
   some \(n\ge1\)

   \(\la0\ra\subset\rad(R)\). So \(\sqrt{\la0\ra}\subset\sqrt{\rad(R)}\). Thus
   \begin{equation*}
   \nil(R)\subset\rad(R)
   \end{equation*}
   We call \(R\) *reduced* if \(\nil(R)=\la0\ra\)

   #+ATTR_LATEX: :options [Scheinnullstellensatz]
   #+BEGIN_theorem
   label:3.14
   Let \(R\) be a ring, \(\fa\) an ideal. Then
   \begin{equation*}
   \sqrt{\fa}=\bigcap_{\fp\supset\fa}\fp
   \end{equation*}
   where \(\fp\) runs through all the prime ideals containing \(\fa\). (By
   convention, the empty intersection is equal to \(R\))
   #+END_theorem

   #+BEGIN_proof
   Take \(x\not\in\sqrt{\fa}\). Set \(S:=\{1,x,x^2,\dots\}\). Then \(S\) is
   multiplicative, and \(\fa\cap S=\emptyset\). By ref:3.9 there is a
   \(\fp\supset\fa\), but \(x\not\in\fp\), but \(x\not\in\fp\). So
   \(x\not\in\bigcap_{\fp\supset\fa}\fp\). Thus
   \(\sqrt{\fa}\supset\bigcap_{\fp\supset\fa}\fp\).
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   label:3.15
   Let \(R\) be a ring, \(\fa\) an ideal. Then \(\sqrt{\fa}\) is an ideal
   #+END_proposition

   #+BEGIN_proof
   Assume \(x^n,y^m\in\fa\). Then
   \begin{equation*}
   (x+y)^{m+n-1}=\sum_{i+j=m+n-1}\binom{n+m-1}{j}x^iy^j
   \end{equation*}
   Thus \(x+y\in\fa\)

   Alternatively by ref:3.14
   #+END_proof

   #+BEGIN_exercise
   label:3.16
   Use Zorn's lemma to prove that any prime ideal \(\fp\) contains a prime ideal
   \(\fq\) that is minimal containing any given subset \(\fs\subset\fp\)
   #+END_exercise

** Minimal primes label:3.17
   Let \(R\) be a ring, \(\fa\) an ideal, \(\fp\) a prime. We call \(\fp\) a
   *minimal prime* of \(\fa\), or over \(\fa\), if \(\fp\) is minimal in the set
   of primes containing \(\fa\). We call \(\fp\) a *minimal prime* of \(R\) if
   \(\fp\) is a minimal prime of \(\la0\ra\)

   Owing to ref:3.16, every prime of \(R\) containing \(\fa\) contains a minimal
   prime of \(\fa\). So owing to the Scheinnullstellensatz ref:3.14, the radical
   \(\sqrt{\fa}\) is the intersection of all the minimal primes of \(\fa\).

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   A ring \(R\) is reduced and has only one minimal prime if and only if \(R\)
   is a domain
   #+END_proposition

   #+BEGIN_proof
   ref:3.17 implies \(\la0\ra=\fq\)
   #+END_proof

   #+BEGIN_exercise
   label:3.19
   Let \(R\) be a ring, \(\fa\) an ideal, \(X\) a variable, \(R[[X]]\) the formal
   power series ring, \(\fM\subset R[[X]]\) an ideal, \(F:=\sum a_nX_n\in R[[X]]\). Set
   \(\fm:=\fM\cap R\) and \(\fA:=\{\sum b_nX^n\mid b_n\in\fa\}\). Prove the
   following statements:
   1. If \(F\) is a nilpotent, then \(a_n\) is nilpotent for all \(n\). The
      converse is false
   2. \(F\in\rad(R[[X]])\) iff \(a_0\in\rad(R)\)
   3. Assume \(X\in\fM\). Then \(X\) and \(\fm\) generate \(\fM\)
   4. Assume \(\fM\) is maximal. Then \(X\in\fM\) and \(\fm\) is maximal
   5. If \(\fa\) is finitely generated, then \(\fa R[[X]]=\fA\). However, there's an
      example of an \(R\) with a prime ideal \(\fa\) s.t. \(\fa R[[X]]\neq\fA\)
   #+END_exercise

   #+BEGIN_proof
   1. Assume \(F\) and \(a_i\) for \(i<n\) nilpotent. Set \(G:=\sum_{i\ge
      n}a_iX^i\). Then \(G=F-\sum_{i<n}a_iX^i\). So \(G\) is nilpotent by
      ref:3.15; say \(G^m=0\) for some \(m\ge1\). Then \(a^m_n=0\)

      Set \(P:=\Z[X_2,X_3,\dots]\). Set \(R:=P/\la X_2^2,X_3^3,\dots\ra\). Let
      \(a_n\) be the residue of \(X_n\). Then \(a^n_n=0\), but \(\sum a_nX^n\)
      is not nilpotent.

   2. By ref:3.2, suppose \(G=\sum b_iX^i\)
      \begin{equation*}
      F\in\rad(R[[X]])\Longleftrightarrow 1+FG\in R[[X]]^\times
      \Longleftrightarrow 1+a_0b_0\in R^\times\Longleftrightarrow
      a_0\in\rad(R)
      \end{equation*}

   5. [@5] Take \(R:=\Z[a_1,a_2,\dots]\) and \(\fa:=\la a_1,\dots\ra\). Then
      \(R/\fa=\Z\) and \(\fa\) is prime.

      Given \(G\in\fa R[[X]]\), say \(G=\sum_{i=1}^mb_iG_i\) with \(b_i\in\fa\) and
      \(G_i=\sum_{n\ge0}b_{in}X^n\) and \(F\neq G\) for any \(m\)
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_examplle
   Let \(R\) be a ring, \(R[[X]]\) the formal power series ring. Then every prime
   \(\fp\) of \(R\) is the contraction of a prime of \(R[[X]]\). Indeed \(\fp R[[X]]\cap
   R=\fp\). So by ref:3.10 there is a prime \(\fq\) of \(R[[X]]\) with \(\fq\cap
   R=\fp\). In fact ,a specific choice for \(\fq\) is the set of series \(\sum
   a_nX^n\) with \(a_n\in\fq\). Indeed, the canonical map \(R\to R/\fp\) induces
   a surjection \(R[[X]]\to(R/\fp)[[X]]\) with kernel \(\fq\); so \(R[[X]]/\fq=(R/\fp)[[X]]\).
   But ref:3.19 shows \(\fq\) may not be equal to \(\fp R[[X]]\)
   #+END_examplle

** Exercise
   #+BEGIN_exercise
   label:3.21
   Let \(R\) be a ring, \(\fa\subset\rad(R)\) an ideal, \(w\in R\) and \(w'\in
   R/\fa\) its residue. Prove that \(w\in R^\times\) iff
   \(w'\in(R/\fa)^\times\). What if \(\fa\not\subset\rad(R)\)?
   #+END_exercise

   #+BEGIN_proof
   Assume \(\fa\subset\rad(R)\). \(\fm\mapsto\fm/\fa\) is a bijection for
   maximal ideal \(\fm\). So \(w\) belongs to a maximal ideal of \(R\) iff \(w'\) belongs
   to one of \(R/\fa\)

   Assume \(\fa\not\subset\rad(R)\), then there is a maximal ideal \(\fm\) s.t.
   \(\fa\not\subset\fm\). So \(\fa+\fm=R\). So there are \(a\in\fa\) and
   \(v\in\fm\) s.t. \(a+v=w\). Then \(v\not\in R^\times\) but the residue of
   \(v\) is \(w'\), even if \(w'\in(R/\fa)^\times\). For example, take \(R:=\Z\)
   and \(\fa=\la2\ra\) and \(w:=3\). Then \(w\not\in R^\times\) but the residue
   of \(w\) is \(1\in(R/\fa)^\times\)
   #+END_proof

   #+BEGIN_exercise
   label:3.22
   Let \(A\) be a local ring, \(e\) an idempotent. Show \(e=1\) or \(e=0\)
   #+END_exercise

   #+BEGIN_proof
   \(1-e+e=1\). Since \(1\not\in\fm\), at least one of \(1-e\) and \(e\) doesn't
   belong to \(\fm\)
   #+END_proof

   #+BEGIN_exercise
   label:3.23
   Let \(A\) be a ring, \(\fm\) a maximal ideal s.t. \(1+m\) is a unit for every
   \(m\in\fm\). Prove \(A\) is local. Is this assertion still true if \(\fm\) is
   not maximal?
   #+END_exercise

   #+BEGIN_proof
   Let \(y\in A-\fm\). Then \(\la y\ra+\fm=A\) and there is a \(x\in A\) s.t.
   \(xy+m=1\). Hence \(xy\) is a unit and \(\la xy\ra=\la y\ra\). \(y\) is a unit.
   #+END_proof

   #+BEGIN_exercise
   label:3.24
   Let \(R\) be a ring, and \(S\) a subset. Show that \(S\) is saturated
   multiplicative iff \(R-S\) is a union of primes.
   #+END_exercise

   #+BEGIN_proof
   Assume \(S\) is saturated multiplicative. Take \(x\in R-S\). Then \(xy\not\in
   S\) for all \(y\in R\); in other words, \(\la x\ra\cap S=\emptyset\). Then
   ref:3.9 gives a prime \(\fp\supset\la x\ra\) with \(\fp\cap S=\emptyset\).
   Thus \(R-S\) is a union of primes.

   #+END_proof

   #+BEGIN_exercise
   label:3.25
   Let \(R\) be a ring, and \(S\) a multiplicative subset. Define its *saturation*
   to be the subset
   \begin{equation*}
   \overbar{S}:=\{x\in R\mid\text{there is }y\in R\text{ with }xy\in S\}
   \end{equation*}
   1. Show that \(\overbar{S}\supset S\) and that \(\overbar{S}\) is saturated
      multiplicative and that any saturated multiplicative subset \(T\)
      containing \(S\) also contains \(\overbar{S}\)
   2. Set \(U:=\bigcup_{\fp\cap S=\emptyset}\fp\). Show that \(R-\overbar{S}=U\)
   3. Let \(\fa\) an ideal; assume \(S=1+\fa\); set
      \(W:=\bigcup_{\fp\supset\fa}\fp\). Show \(R-\overbar{S}=W\)
   4. Given \(f,g\in R\), show that \(\overbar{S_f}\subset\overbar{S_g}\) iff
      \(\sqrt{\la f\ra}\supset\sqrt{\la g\ra}\), where \(S_f=\{f^n\mid n\ge0\}\)

   #+END_exercise

   #+BEGIN_proof
   3. [@3] First take a prime \(\fp\) with \(\fp\cap S=\emptyset\). Then
      \(1\not\in\fp+\fa\); else, \(1=p+a\) and \(p=1-a\in\fp\cap S\). So
      \(\fp+\fa\) lies in a maximal ideal \(\fm\). Then \(\fa\subset\fm\); so
      \(\fm\subset W\). But also \(\fp\subset W\). So \(U\subset W\)

      Conversely, take \(\fp\supset\fa\). Then \(1+\fp\supset 1+\fa=S\). But
      \(\fp\cap(1+\fp)=\emptyset\). So \(\fp\cap S=\emptyset\). Thus \(U\subset
      W\). Thus \(U=W\). Thus \(2\) implies (3)

   4. \(\overbar{S_f}\subset\overbar{S_g}\) iff \(f\in\overbar{S_g}\) iff
      \(hf=g^n\) iff \(g\in\sqrt{\la f\ra}\) iff \(\sqrt{\la
      g\ra}\subset\sqrt{\la f\ra}\)
   #+END_proof

   #+BEGIN_exercise
   label:3.26
   Let \(R\) be a nonzero ring, \(S\) a subset. Show \(S\) is maximal in the
   \(\fS\) of multiplicative subsets \(T\) of \(R\) with \(0\not\in T\) iff
   \(R-S\) is a minimal prime
   #+END_exercise

   #+BEGIN_proof
   First assume \(S\) is maximal. Then \(S=\overbar{S}\). So \(R-S\) is a union
   of primes \(\fp\). Fix a \(\fp\). Then ref:3.16 yields in \(\fp\) a minimal
   prime ideal \(\fq\). Then \(S\subset R-\fq\). But \(R-\fq\in\fS\).
   \(S=R-\fq\)

   If \(R-S\) is a minimal prime. Then \(S\in\fS\). Given \(T\in\fS\) with
   \(S\subset T\), note \(R-\overbar{T}=\bigcup\fp\) with \(\fp\) prime. Fix a
   \(\fp\), then \(S\subset T\subset\overbar{T}\). So \(\fq\supset\fp\). But
   \(\fq\) is minimal and hence \(\fq=\fp\). Hence \(\fq=R-\overbar{T}\). So \(S=\overbar{T}\)
   #+END_proof

   #+BEGIN_exercise
   label:3.27
   Let \(k\) be a field, \(X_\lambda\) for \(\lambda\in\Lambda\) variables, and
   \(\Lambda_\pi\) for \(\pi\in\Pi\) disjoint subsets of \Lambda. Set
   \(P:=k[\{X_\lambda\}_{\lambda\in\Lambda}]\) and
   \(\fp_\pi:=\la\{X_\lambda\}_{\lambda\in\Lambda_\pi}\ra\)for all
   \(\pi\in\Pi\). Let \(F,G\in P\) be nonzero, and \(\fa\subset P\) a nonzero
   ideal. Set \(U:=\bigcup_{\pi\in\Pi}\fp_\pi\). Show
   1. Assume \(F\in\fp_\pi\) for some \(\pi\in\Pi\), then every monomial of
      \(F\) is in \(\fp_\pi\)
   2. Assume there are \(\pi,\rho\in\Pi\) s.t. \(F+G\in\fp_\pi\) and
      \(G\in\fp_\rho\) but \(\fp_\rho\) contains no monomial of \(F\). Then
      \(\fp_\pi\) contains every monomial of \(F\) and of \(G\)
   3. Assume \(\fa\subset U\). Then \(\fa\subset\fp_\pi\) for some \(\pi\in\Pi\)
   #+END_exercise

* Modules

** Modules
   Let \(R\) be a ring. Recall that an *\(R\)-module* \(M\) is an abelian group,
   written additively, with a *scalar multiplication*, \(R\times M\to M\), written
   \((x,m)\mapsto xm\), which is
   1. *distributive*, \(x(m+n)=xm+xn\) and \((x+y)m=xm+xn\)
   2. *associative*, \(x(ym)=(xy)m\)
   3. *unitary*, \(1\cdot m=m\)


   For example, if \(R\) is a field, then an \(R\)-module is a vector space. A
   \(\Z\)-module is just an abelian group

   A *submodule* \(N\) of \(M\) is a subgroup that is closed under
   multiplication.; that is, \(xn\in N\) for all \(x\in R\) and \(n\in N\). For
   example, the ring \(R\) is itself an \(R\)-module, and the submodules are
   just the ideals. Given an ideal \(\fa\), let \(\fa N\) denote the smallest
   submodule containing all products \(an\) with \(a\in\fa\) and \(n\in N\).
   \(\fa N\) is equal to the set of finite sums \(\sum a_in_i\).

   Given \(m\in M\), we call the set of \(x\in R\) with \(xm=0\) the *annihilator*
   of \(m\), and denote it \(\Ann(m)\). We call the set of \(x\in R\) with
   \(xm=0\) for all \(m\in M\) the *annihilator* of \(M\), and denote it \(\Ann(M)\)

** Homomorphisms
   Let \(R\) be a ring, \(M\) and \(N\) modules. A *homomorphism*, or *module map*
   is a map \(\alpha:M\to N\) that is *\(R\)-linear*:
   \begin{equation*}
   \alpha(xm+yn)=x(\alpha m)+y(\alpha n)
   \end{equation*}

   Note that \(f\) is injective iff it has a left inverse. \(f\) is surjective
   iff it has a right inverse

   A homomorphism \alpha is an isomorphism iff there is a set map \(\beta:N\to M\) s.t.
   \(\beta\alpha=1_M\) and \(\alpha\beta=1_N\), and then \(\beta=\alpha^{-1}\).

   The set of homomorphisms \alpha is denoted by \(\Hom_R(M,N)\) or simply
   \(\Hom(M,N)\). It is an \(R\)-module with addition and scalar multiplication
   defined by
   \begin{equation*}
   (\alpha+\beta)m:=\alpha m+\beta m \quad\text{ and }\quad
   (x\alpha)m:=x(\alpha m)=\alpha(xm)
   \end{equation*}

   Homomorphisms \(\alpha:L\to M\) and \(\beta:N\to P\) induce, via composition, a map
   \begin{equation*}
   \Hom(\alpha,\beta):\Hom(M,N)\to\Hom(L,P)
   \end{equation*}

   When \alpha is the identity map \(1_M\), we write \(\Hom(M,\beta)\) for
   \(\Hom(1_M,\beta)\)

   #+BEGIN_exercise
   label:4.3
   Let \(R\) be a ring, \(M\) a module. Consider the map
   \begin{equation*}
   \theta:\Hom(R,M)\to M\quad\text{ defined by }\quad\theta(\rho):=\rho(1)
   \end{equation*}
   Show that \theta is an isomorphism, and describe its inverse
   #+END_exercise

   #+BEGIN_proof
   First, \theta is \(R\)-linear. Set \(H:=\Hom(R,M)\). Define \(\eta:M\to H\) by
   \(\eta(m)(x):=xm\). It is easy to check that \(\eta\theta=1_H\) and
   \(\theta\eta=1_M\). Thus \theta and \eta are inverse isomorphism
   #+END_proof

** Endomorphisms
   Let \(R\) be a ring, \(M\) a module. An *endomorphism* of \(M\) is a
   homomorphism \(\alpha:M\to M\). The module of endomorphism \(\Hom(M,M)\) is also
   denoted \(\End_R(M)\). _Further_, \(\End_R(M)\) _is a subring of_ \(\End_{\Z}(M)\)

   Given \(x\in R\), let \(\mu_x:M\to M\) denote the map of *multiplication* by
   \(x\), defined by \(\mu_x(m):=xm\). It is an endomorphism. Further,
   \(x\mapsto\mu_x\) is a ring map
   \begin{equation*}
   \mu_R:R\to\End_R(M)\subset\End_{\Z}(M)
   \end{equation*}
   (Thus we may view \(\mu_R\) as representing \(R\) as a ring of operators on
   the abelian gorup). Note that \(\ker(\mu_R)=\Ann(M)\)

   Conversely, given an abelian group \(N\) and a ring map
   \begin{equation*}
   \nu:R\to\End_{\Z}(N)
   \end{equation*}
   we obtain a module structure on \(N\) by setting \(xn:=(\nu x)(n)\). Then \(\mu_R=\nu\)

   We call \(M\) *faithful* if \(\mu_R:R\to\End_R(M)\) is injective, or
   \(\Ann(M)=0\). For example, \(R\) is a faithful \(R\)-module for \(x\cdot
   1=0\) implies


** Algebras
   Fix two rings \(R\) and \(R'\). Suppose \(R'\) is an \(R\)-algebra with
   structure map \(\varphi\). Let \(M'\) be an \(R'\)-module.  Then \(M'\) is
   also an \(R\)-module by *restriction on scalars*: \(xm:=\varphi(x)m\). In other
   words, the \(R\)-module structure on \(M'\) corresponds to the composition
   \begin{equation*}
   R\xrightarrow{\varphi}R'\xrightarrow{\mu_{R'}}\End_{\Z}(M')
   \end{equation*}

   In particular, \(R'\) is an \(R\)-module; further, for all \(x\in R\) and
   \(y,z\in R'\)
   \begin{equation*}
   (xy)z=x(yz)
   \end{equation*}
   by restriction on scalars

   Conversely, suppose \(R'\) is an \(R\)-module s.t. \((xy)z=x(yz)\). Then
   \(R'\) has an \(R\)-algebra structure that is compatible with the given
   \(R\)-module structure.. Indeed, define \(\varphi:R\to R'\) by \(\varphi(x):=x\cdot1\).
   Then \(\varphi(x)z=xz\) as \((x\cdot1)z=x(1\cdot z)\). So the composition
   \(\mu_{R'}\varphi:R\to R'\to\End_{\Z}(R')\) is equal to \(\mu_R\). Hence \(\varphi\)
   is a ring map. Thus \(R'\) is an \(R\)-algebra, and restriction of scalars
   recovers its given \(R\)-module structure

   Suppose that \(R'=R/\fa\) for some ideal \(\fa\). Then an \(R\)-module \(M\)
   has a compatible \(R'\)-module structure iff \(\fa M=0\); if so, then the
   \(R'\)-structure is unique. Indeed, the ring map \(\mu_R:R\to\End_{\Z}(M)\)
   factors through \(R'\) iff \(\mu_R(\fa)=0\), so iff \(\fa M=0\)

   Again suppose \(R'\) is an arbitrary \(R\)-algebra with structure map \varphi. A
   *subalgebra* \(R''\) of \(R'\) is a subring s.t. \varphi maps into \(R''\). The
   subalgebra *generated* by \(x_1,\dots,x_n\in R'\) is the smallest
   \(R\)-subalgebra that contains them. We denote it by \(R[x_1,\dots,x_n]\).

   We say \(R'\) is a *finitely generated \(R\)-subalgebra* or is *algrbra finite*
   *over \(R\)* if there exist \(x_1,\dots,x_n\in R'\) s.t. \(R'=R[x_1,\dots,x_n]\)

** Residue modules
   Let \(R\) be a ring, \(M\) a module, \(M'\subset M\) a submodule. Form the
   set of cosets
   \begin{equation*}
   M/M':=\{m+M'\mid m\in M\}
   \end{equation*}
   \(M/M'\) inherits a module structure, and is called the *residue module* or
  *quotient of \(M\) modulo \(M'\)*. Form the *quotient map*
  \begin{equation*}
  \kappa:M\to M/M'\quad\text{by}\quad
  \kappa(m):=m+M'
  \end{equation*}
  Clearly \kappa is surjective, \kappa is linear, and \kappa has kernel \(M'\)

  Let \(\alpha:M\to N\) be linear. Note that \(\ker(\alpha')\supset M'\) iff
  \(\alpha(M')=0\)

  If \(\ker(\alpha)\supset M'\), then there exists a homomorphism \(\beta:M/M'\to N\)
  s.t. \(\beta\kappa=\alpha\)
  #+BEGIN_center
  \begin{tikzcd}
  M\arrow[r,"\kappa"]\arrow[rd,"\alpha"]&M/M'\arrow[d,"\beta"]\\
  &N
  \end{tikzcd}
  #+END_center
  Always
  \begin{equation*}
  M/\ker(\alpha)\similarrightarrow\im(\alpha)
  \end{equation*}

  \(M/M'\) has the following UMP: \(\kappa(M')=0\), and given \(\alpha:M\to N\) s.t.
  \(\alpha(M')=0\), there is a unique homomorphism \(\beta:M/M'\to N\) s.t. \(\beta\kappa=\alpha\)

** Cyclic modules
   Let \(R\) be a ring. A module \(M\) is said to be *cyclic* if there exists
   \(m\in  M\) s.t. \(M=Rm\). If so, form \(\alpha:R\to M\) by \(x\mapsto xm\); then
   \alpha induces an isomorphism \(R/\Ann(m)\similarrightarrow M\). Note that
   \(\Ann(m)=\Ann(M)\). Conversely, given any ideal \(\fa\), the \(R\)-module
   \(R/\fa\) is cyclic, generated by the coset of 1, and \(\Ann(R/\fa)=\fa\)

** Noether Isomorphisms label:4.8
   Let \(R\) be a ring, \(N\) a module, and \(L\) and \(M\) submodules.

   First, assume \(L\subset M\subset N\). Form the following composition of
   quotient maps:
   \begin{equation*}
   \alpha:N\to N/L\to (N/L)/(M/L)
   \end{equation*}
   \alpha is surjective and \(\ker(\alpha)=M\). Hence
   #+BEGIN_center
   \begin{tikzcd}
   N\arrow[r]\arrow[d]&N/M\arrow[d,"\beta","\simeq"']\\
   N/L\arrow[r]&(N/L)/(M/L)
   \end{tikzcd}
   #+END_center

   Second, let \(L+M\) denote the set of all sums \(l+m\) with \(l\in L\) and
   \(m\in M\). Clearly \(L+M\) is a submodule of \(N\). It is called the *sum* of
   \(L\) and \(M\)

   Form the composition \(\alpha'\) of the inclusion map \(L\to L+M\) and the
   quotient map \(L+M\to(L+M)/M\). Clearly \(\alpha'\) is surjective and
   \(\ker(\alpha')=L\cap M\). Hence
   #+BEGIN_center
   \begin{tikzcd}
   L\arrow[r]\arrow[d]&L/(L\cap M)\arrow[d,"\beta'","\simeq"']\\
   L+M\arrow[r]&(L+M)/M
   \end{tikzcd}
   #+END_center

** Cokernels, coimages label:4.9
   Let \(R\) be a ring, \(\alpha:M\to N\) a linear map. Associated to \(\alpha\) are
   its *cokernel* and its *coimage*
   \begin{equation*}
   \coker(\alpha):=N/\im(\alpha)\quad\text{ and }\quad
   \coim(\alpha):=M/\ker(\alpha)
   \end{equation*}
   they are quotient modules, and their quotient maps are both denoted by \kappa.

   UMP of the cokernel: \(\kappa\alpha=0\) and given a map \(\beta:N\to P\) with
   \(\beta:N\to P\) with \(\beta\alpha=0\), there is a unique map \(\gamma:\coker(\alpha)\to
   P\) with \(\gamma\kappa=\beta\)
   #+BEGIN_center
   \begin{tikzcd}
   M\arrow[r,"\alpha"]\arrow[rd]&N\arrow[d,"\beta"]\arrow[r,"\kappa"]
   &\coker(\alpha)\arrow[ld,"\gamma"]\\
   &P&
   \end{tikzcd}
   #+END_center

   Further, \(\coim(\alpha)\similarrightarrow\im(\alpha)\)

** Free modules label:4.10
   Let \(R\) be a ring, \Lambda a set, \(M\) a module. Given elements \(m_\lambda\in
   M\) for \(\lambda\in\Lambda\), by the submodule they *generate*, we mean the
   smallest submodule that contains then all. Clearly, any submodule that
   contains them all contains any (finite) linear combination \(\sum x_\lambda
   m_\lambda\) with \(x_\lambda\in R\)

   \(m_\lambda\) are said to be *free* or *linearly independent* if whenever \(\sum
   x_\lambda m_\lambda=0\), also \(x_\lambda=0\) for all \lambda. Finally, the
   \(m_\lambda\) are said to form a *free basis* of \(M\) if they are free and
   generate \(M\); if so, then we say \(M\) is *free* on the \(m_\lambda\)

   We say \(M\) is *free* if it has a free basis. Any two free bases have the same
   number \(l\) of elements, and we say \(M\) is *free of rank* \(l\)

   For example, form the set of *restricted vectors*
   \begin{equation*}
   R^{\oplus\Lambda}:=\{(x_\lambda)\mid x_\lambda\in R\text{ with }x_\lambda=0
   \text{ for almost all }\lambda\}
   \end{equation*}
   It's a module under componentwise addition and scalar multiplication. It has
   a *standard basis*, which consists of the vectors \(e_\mu\) whose \(\lambda\)th
   component is the value of the *Kronecker delta function*

   If \Lambda has a finite number \(l\) of elements, then \(R^{\oplus\Lambda}\) is
   often written \(R^l\) and called the *direct sum of \(l\) copies* of \(R\)

   The free module \(R^{\oplus\Lambda}\) has the following UMP: given a module
   \(M\) and elements \(m_\lambda\in M\) for \(\lambda\in\Lambda\), there is a
   unique homomorphism
   \begin{equation*}
   \alpha:R^{\oplus\Lambda}\to M\text{ with }\alpha(e_\lambda)=m_\lambda
   \text{ for each }\lambda\in\Lambda
   \end{equation*}
   namely, \(\alpha((x_\lambda))=\alpha(\sum x_\lambda e_\lambda)=\sum x_\lambda
   m_\lambda\). Note the following obvious statements:
   1. \alpha is surjective iff \(m_\lambda\) generate \(M\)
   2. \alpha is injective iff \(m_\lambda\) are linearly independent
   3. \alpha is an isomorphism iff \(m_\lambda\) for a free basis


   Thus \(M\) is free of rank \(l\) iff \(M\simeq R^l\)

   #+BEGIN_exercise
   label:4.11
   Take \(R:=\Z\) and \(M:=\Q\). Then any two \(x,y\in M\) are not free. Aso \(M\)
   is not finitely generated. Indeed, given any \(m_1/n_1,\dots,m_r/n_r\in M\),
   let \(d\) be a common multiple of \(n_1,\dots,n_r\). Then \((1/d)\Z\)
   contains every linear combination but \((1/d)\Z\neq\Q\)
   #+END_exercise

   #+BEGIN_exercise
   label:4.12
   Let \(R\) be a domain, and \(x\in R\) nonzero. Let \(M\) be the submodule of
   \(\Frac(R)\) generated by \(1,x^{-1},x^{-2},\dots\). Suppose that \(M\) is
   finitely generated. Prove that \(x^{-1}\in R\) and conclude that \(M=R\)
   #+END_exercise

   #+BEGIN_proof
   Suppose \(M\) is generated by \(m_1,\dots,m_k\). Say
   \(m_i=\sum_{j=0}^{n_i}a_{ij}x^{-j}\) for some \(n_i\) and \(a_{ij}\in R\).
   Set \(n:=\max\{n_i\}\). Then \(1,x^{-1},\dots,x^{-n}\) generate \(M\). So
   \begin{equation*}
   x^{-n+1}=a_nx^{-n}+\dots+a_0
   \end{equation*}
   Thus
   \begin{equation*}
   x^{-1}=a_n+\dots+a_0x^n
   \end{equation*}
   #+END_proof

** Direct Products, Direct Sums label:4.13
   Let \(R\) be a ring, \Gamma a set, \(M_\lambda\) a module for
   \(\lambda\in\Lambda\). The *direct product* of the \(M_\lambda\) is the set of
   arbitrary vectors:
   \begin{equation*}
   \prod M_\lambda:=\{(m_\lambda)\mid m_\lambda\in M_\lambda\}
   \end{equation*}
   The *direct sum* of the \(M_\lambda\) is the subset of *restricted vectors*:
   \begin{equation*}
   \bigoplus M_\lambda:=\{(m_\lambda)\mid m_\lambda=0\text{ for almost all }\lambda\}
   \subset\prod M_\lambda
   \end{equation*}

   The direct product comes equipped with projections
   \begin{equation*}
   \pi_\kappa:\prod M_\lambda\to M_\kappa\quad\text{given by}\quad
   \pi_\kappa((m_\lambda)):=m_\kappa
   \end{equation*}
   \(\prod M_\lambda\) has UMP: given homomorphisms \(\alpha_\kappa:N\to
   M_\kappa\), there is a unique homomorphism \(\alpha:N\to\prod M_\lambda\)
   satisfying \(\pi_\kappa\alpha=\alpha_\kappa\) for all \(\kappa\in\Lambda\);
   namely \(\alpha(n)=(\alpha_\lambda(n))\). Often \alpha is denoted \((\alpha_\lambda)\).
   In other words, the \(\pi_\lambda\) induce a bijection of sets
   \begin{equation*}
   \Hom(N,\prod M_\lambda)\similarrightarrow\prod\Hom(N,M_\lambda)
   \end{equation*}

   Similarly, the direct sum comes equipped with injections
   \begin{equation*}
   \iota_\kappa:M_\kappa\to\bigoplus M_\lambda\quad\text{given by}\quad
   \iota_\kappa(m):=(m_\lambda)\text{ where }m_\lambda:=
   \begin{cases}
   m&\lambda=\kappa\\
   0
   \end{cases}
   \end{equation*}
   UMP: given homomorphisms \(\beta_\kappa:M_\kappa\to N\), there is a unique
   homomorphism
   \(\beta:\bigoplus M_\lambda\to N\) satisfying
   \(\beta\iota_\kappa=\beta_\kappa\) for all \(\kappa\in\Lambda\) for all
   \(\kappa\in\Lambda\); namely,
   \(\beta((m_\lambda))=\sum\beta_\lambda(m_\lambda)\). Often \beta is denoted
   \(\sum\beta_\lambda\); often \((\beta_\lambda)\). In other words, the
   \(\iota_\kappa\) induce this bijection of sets:
   \begin{equation}
   \Hom(\bigoplus M_\lambda,N)\similarrightarrow\prod\Hom(M_\lambda,N)
   \label{4.13.2}
   \end{equation}

   For example, if \(M_\lambda=R\) for all \lambda, then \(\bigoplus
   M_\lambda=R^{\oplus\Lambda}\). Further, if \(N_\lambda:=N\) for all \lambda, then
   \(\Hom(R^{\oplus\Lambda},N)=\prod N_\lambda\) by eqref:4.13.2 and ref:4.3

   #+BEGIN_exercise
   label:4.14
   Let \Lambda be an infinite set, \(R_\lambda\) a ring for \(\lambda\in\Lambda\).
   Endow \(\prod R_\lambda\) and \(\bigoplus R_\lambda\) with componentwise
   addition and multiplication. Show that \(\prod R_\lambda\) has a
   multiplicative identity (so is a ring), but \(\bigoplus R_\lambda\) does not
   (so is not a ring)
   #+END_exercise

   #+BEGIN_exercise
   label:4.15
   Let \(L,M,N\) be modules. Consider a diagram
   \begin{center}
   \begin{tikzcd}
   L\arrow[r,"\alpha",yshift=0.7ex]
   &M\arrow[r,"\beta",yshift=0.7ex]\arrow[l,"\rho",yshift=-0.7ex]
   &N\arrow[l,"\sigma",yshift=-0.7ex]
   \end{tikzcd}
   \end{center}
   where \alpha, \beta, \rho and \sigma are homomorphisms. Prove that
   \begin{equation*}
   M=L\oplus N \quad\text{ and }\quad\alpha=\iota_L,\beta=\pi_N,\sigma=\iota_N,\rho=\pi_L
   \end{equation*}
   iff the following relations holds
   \begin{equation*}
   \beta\alpha=0,\beta\sigma=1,\rho\sigma=0,\rho\alpha=1,\alpha\rho+\sigma\beta=1
   \end{equation*}
   #+END_exercise

   #+BEGIN_proof
   Consider the map \(\varphi:M\to L\oplus N\) and \(\theta:L\oplus N\to M\) given by
   \(\varphi m:=(\rho m,\rho m)\) and \(\theta(l,n):=\alpha l+\sigma n\). They are inverse
   isomorphism since
   \begin{equation*}
   \varphi\theta(l,n)=(\rho\alpha l+\rho\sigma n,\beta\alpha l+\beta\sigma n)=(l,n)
   \quad\text{ and }\quad
   \theta\varphi m=\alpha\rho m+\sigma\beta m=m
   \end{equation*}
   #+END_proof

   #+BEGIN_exercise
   label:4.16
   Let \(N\) be a module, \Lambda a nonempty set, \(M_\lambda\) a module for
   \(\lambda\in\Lambda\). Prove that the injections
   \(\iota_\kappa:M_\kappa\to\bigoplus M_\lambda\) induce an injection
   \begin{equation*}
   \bigoplus\Hom(N,M_\lambda)\hookrightarrow\Hom(N,\bigoplus M_\lambda)
   \end{equation*}
   and that it is an isomorphism if \(N\) is finitely generated
   #+END_exercise

   #+BEGIN_proof
   For \((\beta_\kappa)\in\bigoplus\Hom(N,M_\lambda)\)
   \begin{equation*}
   \beta(n)=
   \begin{cases}
   \iota_\kappa\beta_\kappa&\text{if }\beta_\kappa\neq0\\
   0&\beta_\kappa=0
   \end{cases}
   \in\Hom(N,\bigoplus M_\lambda)
   \end{equation*}
   If \(N\) is fintitely generated, suppose \(a_1,\dots,a_n\) generates \(N\)
   and \(\beta(a_i)=b_i\in\bigoplus M_\lambda\), which means \(\beta(N)\) is a finite
   direct subsum of \(\bigoplus M_\lambda\).
   then we have
   \(\beta_\kappa=\pi_\kappa\beta\) and almost
   #+END_proof

   #+BEGIN_exercise
   label:4.17
   Let \(\fa\) be an ideal, \Lambda a nonempty set, \(M_\lambda\) a module for
   \(\lambda\in\Lambda\). Prove \(\fa(\bigoplus M_\lambda)=\bigoplus\fa
   M_\lambda\). Prove \(\fa(\prod M_\lambda)=\prod\fa M_\lambda\) if \(\fa\) is
   finitely generated
   #+END_exercise


* Exact Sequence
   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   A (finite or infinite) sequence of module homomorphisms
   \begin{equation*}
   \cdots\to M_{i-1}\yrightarrow{\alpha_{i-1}}M_i\yrightarrow{\alpha_i}M_{i+1}\to\cdots
   \end{equation*}
   is said to be *exact at* \(M_i\) if \(\ker(\alpha_i)=\im(\alpha_{i-1})\).. The
   sequence is said to be *exact* if it is exact at every \(M_i\), except an
   initial source or final target
   #+END_definition

   #+ATTR_LATEX: :options []
   #+BEGIN_examplle
   label:5.2
   1. A sequence \(0\to L\yrightarrow{\alpha} M\) is exact iff \alpha is injective. If
      so, then we often identify \(L\) with its image \(\alpha(L)\)

      *Dually* - a sequence \(M\yrightarrow{\beta}N\to0\) is exact iff \beta is surjective

   2. A sequence \(0\to L\yrightarrow{\alpha}M\yrightarrow{\beta}N\) is exact iff
      \(L=\ker(\beta)\), where '\(\equal\)' means "canocially isomorphic". Dually, a sequence
      \(L\yrightarrow{\alpha}M\yrightarrow{\beta}N\to0\) is exact iff \(N=\coker(\alpha)\)
   #+END_examplle
** Short exact sequences
   A sequence \(0\to L\yrightarrow{\alpha}M\xrightarrow{\beta}N\to0\) is exact iff
   \alpha is injective and \(N=\coker(\alpha)\), or dually, iff \beta is surjective and
   \(L=\ker(\beta)\). If so, then the sequence is called *short exact*, and often we
   regard \(L\) as a submodule of \(M\), and \(N\) as the quotient \(M/L\)

   For example, the following sequence is shor t exact
   \begin{equation*}
   0\to L\yrightarrow{\iota_L}L\oplus N\yrightarrow{\pi_N}N\to0
   \end{equation*}

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   label:5.4
   For \(\lambda\in\Lambda\), let \(M'_\lambda\to M_\lambda\to M_\lambda''\) be a
   sequence  of module homomorphisms. If every sequence is exact, then so are
   the two induced sequences
   \begin{equation*}
   \bigoplus M'_\lambda\to\bigoplus M_\lambda\to\bigoplus M_\lambda''
   \quad\text{ and }\quad
   \prod M'_\lambda\to \prod M_\lambda\to\prod M_\lambda''
   \end{equation*}
   Conversely, if either induced sequence is exact then so is every original one
   #+END_proposition

   #+BEGIN_exercise
   label:5.5
   Let \(M'\) and \(M''\) be modules, \(N\subset M'\) a submodule. Set
   \(M:=M'\oplus M''\). Prove \(M/N=M'/N\oplus M''\)
   #+END_exercise

   #+BEGIN_proof
   \(N=N\oplus 0\)

   The two sequence \(0\to M''\to M''\to0\) and \(0\to N\to M'\to M'/N\to 0\)
   are exact. So by ref:5.4, the sequence
   \begin{equation*}
   0\to N\to M'\oplus M''\to(M'/N)\oplus M''\to 0
   \end{equation*}
   is exact
   #+END_proof

   #+BEGIN_exercise
   label:5.6
   Let \(0\to M'\to M\to M''\to 0\) be a short exact sequence. Prove the if
   \(M'\) and \(M''\) are finitely generated, then so is \(M\)
   #+END_exercise

   #+ATTR_LATEX: :options []
   #+BEGIN_lemma
   Let \(0\to M'\yrightarrow{\alpha}M\yrightarrow{\beta}M''\to0\) be a short exact
   sequence, and \(N\subset M\) a submodule. Set \(N':=\alpha^{-1}\) and
   \(N'':=\beta(N)\). Then the induced sequence \(0\to N'\to N\to N''\to 0\) is
   short exact
   #+END_lemma

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   We say that a short exact sequence
   \begin{equation*}
   0\to M'\yrightarrow{\alpha}M\yrightarrow{\beta}M''\to0
   \end{equation*}
   *splits* if there is an isomorphism \(\varphi:M\similarrightarrow M'\oplus M''\) with
    \(\varphi\alpha=\iota_{M'}\) and \(\beta=\pi_{M''}\varphi\)

    We call a homomorphism \(\rho:M\to M'\) a *retraction* of \alpha if
    \(\rho\alpha=1_{M'}\)

    Dually, we call a homomorphism \(\sigma:M''\to M\) a *section* of \beta if \(\beta\sigma=1_{M''}\)
   #+END_definition

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   label:5.9
   Let \(0\to M'\yrightarrow{\alpha}M\yrightarrow{\beta}M''\to0\) be a short exact
   sequence. Then the following conditions are equivalent
   1. The sequence splits
   2. There exists a retraction
   3. There exists a section
   #+END_proposition

   #+BEGIN_proof
   Assume (2). Set \(\sigma':=1_M-\alpha\rho\). Then \(\sigma'\alpha=0\). So
   there exists \(\sigma:M''\to M\) with \(\sigma\beta=\sigma'\) by ref:5.2 and UMP.
   So \(1_M=\alpha\rho+\sigma\beta\). Since \(\beta\sigma\beta=\beta\) and \beta is
   surjective, \(\beta\sigma=1_{M''}\). Hence \(\alpha\rho\sigma=0\). Since \alpha is
   injective, \(\rho\sigma=0\). Thus ref:4.15 yields (1) and also (3)
   #+END_proof

   #+BEGIN_exercise
   label:5.10
   Let \(M',M''\) be modules, and set \(M:=M'\oplus M''\). Let \(N\) be a
   submodule of \(M\) containing \(M'\), and set \(N'':=N\cap M''\). Prove
   \(N=M'\oplus N''\)
   #+END_exercise

   #+BEGIN_proof
   Form the sequence \(0\to M'\to N\to\pi_{M''}N\to0\). It splits by ref:5.9  as
   \((\pi_{M'}|N)\circ\iota_{M'}=1_{M'}\). Finally if \((m',m'')\in N\), then
   \((0,m'')\in N\) as \(M'\subset N\); hence \(\pi_{M''}N=N''\)
   #+END_proof

   #+BEGIN_exercise
   label:5.11 Criticize the following misstatement of ref:5.9: given a short
   exactg sequence \(0\to M'\xrightarrow{\alpha}M\xrightarrow{\beta}M''\to0\), there is
   an isomorphism \(M\simeq M'\oplus M''\) iff there is a section \(\sigma:M''\to M\)
   of \beta
   #+END_exercise

   #+BEGIN_proof
   We have \(\alpha:M'\to M\) and \(\iota_{M'}:M'\oplus M''\), but ref:5.9 requires
   that they be compatible with the isomorphism \(M\simeq M'\oplus M''\).

   Let's construct a counterexample. For each integer \(n\ge2\), let \(M_n\) be
   the direct sum of countably many copies of \(\Z/\la n\ra\). Set
   \(M:=\bigoplus M_n\)

   First let us check these two statements:
   1. For any finite abelian group \(G\), we have \(G\oplus M\simeq M\)
   2. For any finite abelian subgroup \(G\subset M\), we have \(M/G\simeq M\)


   Statement (1) holds since \(G\) is isomorphic to a direct sum of copies of
   \(\Z/\la n\ra\)

   To prove (2), write \(M=B\oplus M'\), where \(B\) contains \(G\) and involes
   only finitely many components of \(M\). Then \(M'\simeq M\). Therefore,
   ref:5.10 yields
   \begin{equation*}
   M/G\simeq(B/G)\oplus M'\simeq M
   \end{equation*}

   To construct the counterexample, let \(p\) be a prime number. Take one of the
   \(\Z/\la p^2\ra\) components of \(M\), and let \(M'\subset\Z/\la p^2\ra\) be
   the cyclic subgroup of order \(p\). There is no retraction \(\Z/\la p^2\ra\to
   M'\), so there is no traction \(M\to M'\) either, since the latter would
   induce the former. Finally take \(M'':=M/M'\). Then (1) and (2) yield
   \(M\simeq M'\oplus M''\)
   #+END_proof

   #+ATTR_LATEX: :options [Snake]
   #+BEGIN_lemma
   Consider this commutative diagram with exact rows:
   \begin{center}
   \begin{tikzcd}
   &M'\arrow[r,"\alpha"]\arrow[d,"\gamma'"]&M\arrow[r,"\beta"]
   \arrow[d,"\gamma"]&M''\arrow[r]\arrow[d,"\gamma''"]&0\\
   0\arrow[r]&N'\arrow[r,"\alpha'"]&N\arrow[r,"\beta'"]&N''
   \end{tikzcd}
   \end{center}
   It yields the following exact sequence
   \begin{equation*}
   \ker(\gamma')\xrightarrow{\varphi}\ker(\gamma)\xrightarrow{\psi}\ker(\gamma'')
   \xrightarrow{\partial}\coker(\gamma')\xrightarrow{\varphi'}\coker(\gamma)
   \xrightarrow{\psi'}\coker(\gamma'')
   \end{equation*}
   Moreover, if \alpha is injective, then so is \varphi; dually, if \(\beta'\) is
   surjective, then so is \(\psi'\)
   #+END_lemma

   #+BEGIN_proof
   Clearly, \alpha yields a unique compatible homomorphism
   \(\ker(\gamma')\to\ker(\gamma)\) since \(\gamma\alpha(\ker(\gamma'))=0\). By the
   UMP in ref:4.9, \(\alpha'\) yields a unique compatible homomorphism \(\varphi'\) because
   \(M'\) goes to 0 in \(\coker(\gamma)\).
   \begin{center}
   \begin{tikzcd}
   M'\arrow[r,"\gamma'"]&N'\arrow[r]\arrow[ld,"\alpha'"]\arrow[d]&
   \coker(\gamma')\arrow[ld,"\varphi''"]\\
   N\arrow[r]&\coker(\gamma)
   \end{tikzcd}
   \end{center}
   Similarly, \beta and \(\beta'\) induce corresponding homomorphisms \psi and
   \(\psi'\)

   To define \(\partial\), *chase* an \(m''\in\ker(\gamma'')\) through the
   diagram. Since  \beta is surjective, there is \(m\in M\) s.t. \(\beta(m)=m''\). By
   commutativity, \(\gamma''\beta(m)=\beta'\gamma(m)\). So
   \(\beta'\gamma(m)=0\). By exactness of the bottom row, there is a unique
   \(n'\in N'\) s.t. \(\alpha'(n')=\gamma(m)\). Define \(\partial(m'')\) to be the
   image of \(n'\) in \(\coker(\gamma')\)

   To see \(\partial\) is well defined, choose another \(m_1\in M\) with
   \(\beta(m_1)=m''\).  Let \(n_1'\in N'\) be the unique element with
   \(\alpha'(n_1')=\gamma(m_1)\). Since \(\beta(m-m_1)=0\), there is an \(m'\in M'\)
   with \(\alpha(m')=m-m_1\). But \(\alpha'\gamma'=\gamma\alpha\). So
   \(\alpha'\gamma'(m')=\alpha'(n'-n_1')\). Hence \(\gamma'(m')=n'-n_1'\) since
   \(\alpha'\) is injective. So \(n'\) and \(n_1'\) have the same image in
   \(\coker(\gamma')\). Thus \(\partial\) is well defined

   Exact at \(\ker(\gamma'')\). Take \(m''\in\ker(\gamma'')\). As in the
   construction of \(\partial\), take \(m\in M\) s.t. \(\beta(m)=m''\) and take
   \(n'\in N'\) s.t. \(\alpha'(n')=\gamma(m)\). Suppose \(m''\in\ker(\partial)\). Then
   the image of \(n'\) in \(\coker(\gamma')\) is equal to 0; so there is \(m'\in
   M'\) s.t. \(\gamma'(m')=n'\). Clearly
   \(\gamma\alpha(m')=\alpha'\gamma'(m')\). So
   \(\gamma\alpha(m')=\alpha'(n')=\gamma(m)\). Hence \(m-\alpha(m')\in\ker(\gamma)\).
   Since \(\beta(m-\alpha(m'))=m''\), clearly \(m''=\psi(m-\alpha(m'))\); so
   \(m''\in\im(\psi)\). Hence \(\ker(\partial)\subset\im(\psi)\)

   Conversely, suppose \(m''\in\im(\psi)\). We may assume \(m\in\ker(\gamma)\). So
   \(\gamma(m)=0\) and \(\alpha'(n')=0\). Since \(\alpha'\) is injective, \(n'=0\).
   Thus \(\partial(m'')=0\) and so \(\im(\psi)\subset\ker(\partial)\).Thus \(\ker(\partial)=\im(\psi)\)
   #+END_proof

   #+BEGIN_exercise
   label:5.13
   Referring to ref:4.8, give an alternative proof that \beta is an isomorphism by
   applying the Snake Lemma to the diagram
   \begin{center}
   \begin{tikzcd}
   0\arrow[r]&M\arrow[r]\arrow[d]&N\arrow[r]\arrow[d,"\kappa"]&
   N/M\arrow[r]\arrow[d,"\beta"]&0\\
   0\arrow[r]&M/L\arrow[r]&N/L\arrow[r,"\lambda"]&
   (N/L)/(M/L)\arrow[r]&0
   \end{tikzcd}
   \end{center}
   #+END_exercise

   #+BEGIN_proof
   The Snake Lemma yields an exact sequence
   \begin{center}
   \begin{tikzcd}
   L\arrow[r,"1"]&L\arrow[r]&\ker(\beta)\arrow[r]&0
   \end{tikzcd}
   \end{center}
   hence \(\ker(\beta)=0\) and \beta is injective. Moreover, \beta is surjective because
   \kappa and \lambda are
   #+END_proof

   #+ATTR_LATEX: :options [Five Lemma]
   #+BEGIN_exercise
   Consider this commutative diagram
   \begin{center}
   \begin{tikzcd}
   M_4\arrow[r,"\alpha_4"]\arrow[d,"\gamma_4"]&
   M_3\arrow[r,"\alpha_3"]\arrow[d,"\gamma_3"]&
   M_2\arrow[r,"\alpha_2"]\arrow[d,"\gamma_2"]&
   M_1\arrow[r,"\alpha_1"]\arrow[d,"\gamma_1"]&
   M_0\arrow[d,"\gamma_0"]\\
   N_4\arrow[r,"\beta_4"]&
   N_3\arrow[r,"\beta_3"]&
   N_2\arrow[r,"\beta_2"]&
   N_1\arrow[r,"\beta_1"]&
   N_0
   \end{tikzcd}
   \end{center}
   Assume it has exact rows. Via a chase, prove these two statements
   1. If \(\gamma_3\) and \(\gamma_1\) are surjective and if \(\gamma_0\) is
      injective, then \(\gamma_2\) is surjective
   2. If \(\gamma_3\) and \(\gamma_1\) are injective and if \(\gamma_4\) is
      surjective, then \(\gamma_2\) is injective
   #+END_exercise


   #+BEGIN_proof
   Take \(n_2\in N_2\). Since \(\gamma_1\) is surjective, there is \(m_1\in
   M_1\) s.t. \(\gamma_1(m_1)=\beta_2(n_2)\). Then
   \(\gamma_0\alpha_1(m_1)=\beta_1\gamma_1(m_1)=\beta_1\beta_2(n_1)=0\). Since
   \(\gamma_0\) is injective, \(\alpha_1(m_1)=0\). Hence exactness yields
   \(m_2\in M_2\) with \(\alpha_2(m_2)=m_1\). So
   \(\beta_2(\gamma_2(m_2)-n_2)=\gamma_1\alpha_2(m_2)-\beta_2(n_2)=0\).

   Hence exactness yields \(n_3\in N_3\) with
   \(\beta_3(n_3)=\gamma_2(m_2)-n_2\). Since \(\gamma_3\) is surjective, there
   is \(m_3\in M_3\) with \(\gamma_3(m_3)=n_3\). Then
   \(\gamma_2\alpha_3(m_3)=\beta_3\gamma_3(m_3)=\gamma_2(m_2)-n_2\). Hence
   \(\gamma_2(m_2-\alpha_3(m_3))=n_2\). Thus \(\gamma_2\) is surjective
   #+END_proof

   #+ATTR_LATEX: :options [Nine Lemma]
   #+BEGIN_exercise
   label:5.15
   Consider the commutative diagram
   \begin{center}
   \begin{tikzcd}
   &0\arrow[d]&0\arrow[d]&0\arrow[d]&\\
   0\arrow[r]&L'\arrow[d]\arrow[r]&L\arrow[d]\arrow[r]&L''\arrow[d]\arrow[r]&0\\
   0\arrow[r]&M'\arrow[d]\arrow[r]&M\arrow[d]\arrow[r]&M''\arrow[d]\arrow[r]&0\\
   0\arrow[r]&N'\arrow[d]\arrow[r]&N\arrow[d]\arrow[r]&N''\arrow[d]\arrow[r]&0\\
   &0&0&0&
   \end{tikzcd}
   \end{center}
   Assume all the columns are exact and the middle row is exact. Apply the Snake
   Lemma, prove that the first row is exact iff the third is
   #+END_exercise

   #+BEGIN_exercise
   label:5.16
   Consider this commutative diagram with exact rows
   \begin{center}
   \begin{tikzcd}
   M'\arrow[r,"\beta"]\arrow[d,"\alpha'"]&M\arrow[r,"\gamma"]\arrow[d,"\alpha"]&
   M''\arrow[d,"\alpha''"]\\
   N'\arrow[r,"\beta'"]&N\arrow[r,"\gamma'"]&N''
   \end{tikzcd}
   \end{center}
   Assume \(\alpha'\) and \gamma are surjective. Given \(n\in N\) and \(m''\in M''\)
   with \(\alpha''(m'')=\gamma'(n)\), show that there is \(m\in M\) s.t.
   \(\alpha(m)=n\) and \(\gamma(m)=m''\)
   #+END_exercise

   #+ATTR_LATEX: :options [Left exactness of Hom]
   #+BEGIN_theorem
   1. Let \(M'\to M\to M''\to0\) be a sequence of module homomorphisms. Then it
      is exact iff for all modules \(N\), the following induced sequence is
      exact
      \begin{equation}
      0\to\Hom(M'',N)\to\Hom(M,N)\to\Hom(M',N)
      \label{eq5.17.1}
      \end{equation}
   2. Let \(0\to N'\to N\to N''\) be a sequence of module homomorphisms. Then it
      is exact iff for all modules \(M\), the following induced sequence is
      exact:
      \begin{equation*}
      0\to\Hom(M,N')\to\Hom(M,N)\to\Hom(M,N'')
      \end{equation*}
   #+END_theorem

   #+BEGIN_proof
   The exactness of \(M'\xrightarrow{\alpha}M\xrightarrow{\beta}M''\to 0\) means simply
   that \(M''=\coker(\alpha)\). On the other hand, the exactness of eqref:eq5.17.1
   means that a \(\varphi\in\Hom(M,N)\) maps to 0, or equivalently,
   \(\varphi\alpha=0\) iff there is a unique \(\gamma:M''\to N\) s.t.
   \(\gamma\beta=\varphi\). So eqref:eq5.17.1 is exact iff \(M''\) has the UMP
   of \(\coker(\alpha)\), discussed in ref:4.9
   \begin{center}
   \begin{tikzcd}
   M'\arrow[r,"\alpha"]&M\arrow[r]\arrow[d]&\coker(\alpha)
   \arrow[ld,dashed]\\
   &N
   \end{tikzcd}
   \end{center}
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   A (free) *presentation* of a module \(M\) is an exact sequence
   \begin{equation*}
   G\to F\to M\to 0
   \end{equation*}
   with \(G\) and \(F\) free. If \(G\) and \(F\) are free of finite rank, then
   the presentation is called *finite*. If \(M\) has a finite presentation, then
   \(M\) is said to be *finitely presented*
   #+END_definition

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   label:5.19
   Given a module \(M\)and a set of generators
   \(\{m_\lambda\}_{\lambda\in\Lambda}\), there is an exact sequence
   \(0\to K\to R^{\oplus\Lambda}\xrightarrow{\alpha}M\to0\) with
   \(\alpha(e_\lambda)=m_\lambda\), where \(\{e_\lambda\}\) is the standard basis;
   further, there is a presentation \(R^{\oplus\Sigma}\to R^{\oplus\Lambda}\xrightarrow{\alpha}M\to0\)
   #+END_proposition

   #+BEGIN_proof
   By ref:4.10, there is a surjection \(\alpha:R^{\oplus\Lambda}\twoheadrightarrow
   M\) with \(\alpha(e_\lambda)=m_\lambda\). Set \(K:=\ker(\alpha)\). Then
   \(0\to K\to R^{\oplus\Lambda}\to M\to0\) is exact. Take a generators
   \(\{k_\sigma\}_{\sigma\in\Sigma}\) of \(K\), and repeat the process to obtain
   a surjection \(R^{\oplus\Sigma}\twoheadrightarrow K\). Then
   \(R^{\oplus\Sigma}\to R^{\oplus\Lambda}\to M\to0\) is a presentation
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_definition
   A module \(P\) is called *projective* if, given any surjective homomorphism
   \(\beta:M\twoheadrightarrow N\), every homomorphism \(\alpha:P\to N\) *lifts* to a
   homomorphism \(\gamma:P\to M\); that is, \(\alpha=\beta\gamma\)
   #+END_definition

   #+BEGIN_exercise
   label:5.21
   Show that a free module \(R^{\oplus\Lambda}\) is projective
   #+END_exercise

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   The following conditions on a module \(P\) are equivalent:
   1. The module \(P\) is projective
   2. Every short exact sequence \(0\to K\to M\to P\to 0\) splits
   3. There is a module \(K\) s.t. \(K\oplus P\)
       is free
   4. Every exact sequence \(N'\to N\to N''\) induces an exact sequence
      \begin{equation*}
      \Hom(P,N')\to\Hom(P,N)\to\Hom(P,N'')
      \end{equation*}
   5. Every surjective homomorphism \(\beta:M\twoheadrightarrow N\) induces a
      surjection
      \begin{equation*}
      \Hom(P,\beta):\Hom(P,M)\to\Hom(P,N)
      \end{equation*}
   #+END_theorem

   #+BEGIN_proof
   Assume (1). The surjection \(M\twoheadrightarrow P\) and the identity \(P\to
   P\) yield a section \(P\to M\). So the sequence splits by ref:5.9

   Assume (2). By ref:5.19 there is an exact sequence \(0\to K\to
   R^{\oplus\Lambda}\to P\to0\). Then \(K\oplus P\simeq R^{\oplus\Lambda}\).

   Assume (3); say \(K\oplus P\simeq R^{\oplus\Lambda}\). For each
   \(\lambda\in\Lambda\), take a copy \(N_\lambda'\to N_\lambda\to N''_\lambda\)
   of the exact sequence \(N'\to N\to N''\). Then the induced sequence
   \begin{equation*}
   \prod N_\lambda'\to\prod N_\lambda\to \prod N_\lambda''
   \end{equation*}
   is exact by ref:5.4. But at the end of ref:4.13, that sequence is equal to
   this one
   \begin{equation*}
   \Hom(R^{\oplus\Lambda},N')\to\Hom(R^{\oplus\Lambda},N)\to\Hom(R^{\oplus\Lambda},N'')
   \end{equation*}
   But \(K\oplus P\simeq R^{\oplus\Lambda}\). So owing to eqref:4.13.2, the
   latter sequence is also equal to
   \begin{equation*}
   \Hom(K,N')\oplus\Hom(P,N')\to\Hom(K,N)\oplus\Hom(P,N)\to\Hom(K,N'')\oplus\Hom(P,N'')
   \end{equation*}
   hence by ref:5.4, it holds

   Assume (4). Then every exact sequence \(M\xrightarrow{\beta}N\to0\) induces an
   exact sequence
   \begin{equation*}
   \Hom(P,M)\to\Hom(P,N)\to0
   \end{equation*}

   Assume (5). By definition, \(\Hom(P,\beta)(\gamma)=\beta\gamma\)
   #+END_proof

   #+ATTR_LATEX: :options [Schanuel]
   #+BEGIN_lemma
   Given two short exact sequences
   \begin{equation*}
   0\to L\xrightarrow{i}P\xrightarrow{\alpha}M\to0 \quad\text{ and }\quad
   0\to L'\xrightarrow{i'}P'\xrightarrow{\alpha'}M\to0
   \end{equation*}
   with \(P\) and \(P'\) projective, there is an isomorphism of exact sequences
   \begin{center}
   \begin{tikzcd}
   0\arrow[r]&L\oplus P'\arrow[r,"i\oplus1_{P'}"]\arrow[d,"\cong","\beta"']&
   P\oplus P'\arrow[r,"(\alpha\;0)"]\arrow[d,"\cong","\gamma"']&
   M\arrow[r]\arrow[d,"=","1_M"']&0\\
   0\arrow[r]&P\oplus L'\arrow[r,"1_P\oplus i'"]&P\oplus P'
   \arrow[r,"(0\;\alpha')"]&M\arrow[r]&0
   \end{tikzcd}
   \end{center}
   #+END_lemma

   #+BEGIN_proof
   First, let's construct an intermediate isomorphism of exact sequences
   \begin{center}
   \begin{tikzcd}
   0\arrow[r]&L\oplus P'\arrow[r,"i\oplus 1_{P'}"]&P\oplus P'
   \arrow[r,"(\alpha\;0)"]&M\arrow[r]&0\\
   0\arrow[r]&K\arrow[r]\arrow[u,"\cong","\lambda"']&
   P\oplus P'\arrow[r,"(\alpha\;\alpha')"]\arrow[u,"\cong","\theta"']&
   M\arrow[r]\arrow[u,"=","1_M"']&0
   \end{tikzcd}
   \end{center}
   Take \(K:=\ker(\alpha\;\alpha')\). To form \theta, recall that \(P'\) is
   projective and \alpha is surjective. So there is a map \(\pi:P'\to P\) s.t.
   \(\alpha'=\alpha\pi\). Take \(\theta:=\begin{psm}1&\pi\\0&1\end{psm}\)

   Then \theta has $\begin{psm}1&-\pi\\0&1\end{psm}$ as inverse. Further, the
   right-hand square is commutative
   \begin{equation*}
   (\alpha\;0)\theta=(\alpha\;0)\begin{psm}1&\pi\\0&1\end{psm}
   =(\alpha\;\alpha\pi)=(\alpha\;\alpha')
   \end{equation*}
   So \theta induces the desired isomorphism \(\lambda:K\similarrightarrow L\oplus P'\)
   since they are both kernels.
   \(\alpha(\theta(\ker(\alpha\;\alpha')))=1_M(\alpha\;\alpha')(\ker(\alpha\;\alpha'))=0\)

   Symmetrically, form an automorphism \(\theta'\) of \(P\oplus P'\), which
   induces an isomorphism \(\lambda':K\similarrightarrow P\oplus L'\). Finally,
   take \(\gamma:=\theta'\theta^{-1}\) and \(\beta:=\lambda'\lambda^{-1}\)
   #+END_proof

   #+BEGIN_exercise
   label:5.24
   Let \(R\) be a ring, and \(0\to L\to R^n\to M\to 0\) an exact sequence. Prove
   \(M\) is finitely presented iff \(L\) is finitely generated
   #+END_exercise

   #+BEGIN_proof
   Assume \(M\) is finitely presented; say \(R^l\to R^m\to M\to0\) is a finite
   sequence. Let \(L'\) be the image of \(R^l\).  Then \(L'\oplus R^n\simeq
   L\oplus R^m\) by Schanuel's Lemma since we can replace \(R^l\) by \(L'\).
   Hence \(L\) is a quotient of \(L'\oplus R^n\). Thus \(L\) is finitely
   generated

   Conversely, suppose \(L\) is finitely generated by \(l\) elements. They yield
   a surjection \(R^l\twoheadrightarrow L\) and a sequence \(R^l\to R^n\to M\to0\).
   #+END_proof

   #+BEGIN_exercise
   label:5.25
   Let \(R\) be a ring, \(X_1,X_2,\dots\) infinitely many variables. Set
   \(P:=R[X_1,X_2,\dots]\) and \(M:=P/\la X_1,X_2,\dots\ra\). Is \(M\) finitely presented?
   #+END_exercise

   #+BEGIN_proof
   No. By ref:5.24
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   Let \(0\to L\xrightarrow{\alpha}M\xrightarrow{\beta}N\to0\) be a short exact sequence
   with \(L\) finitely generated and \(M\) finitely generated. Then \(N\) is
   finitely generated
   #+END_proposition

   #+BEGIN_proof
   Let \(R\) be the ground ring, \(\mu:R^m\to M\) any surjection. Set
   \(\nu:=\beta\mu\), set \(K:=\ker(\nu)\) and set \(\lambda:=\mu|K\). Then the following
   diagram is commutative
   \begin{center}
   \begin{tikzcd}
   0\arrow[r]&K\arrow[r]\arrow[d,"\lambda"]&R^m\arrow[r,"\nu"]
   \arrow[d,"\mu"]&N\arrow[r]\arrow[d,"1_N"]&0\\
   0\arrow[r]&L\arrow[r,"\alpha"]&M\arrow[r,"\beta"]&N\arrow[r]&0
   \end{tikzcd}
   \end{center}
   The Snake Lemma yields an isomorphism \(\ker(\lambda)\similarrightarrow\ker(\mu)\).
   But \(\ker(\mu)\) is finitely generated by ref:5.24. So \(\ker(\lambda)\) is finitely
   generated. Also the Snake Lemma implies \(\coker(\lambda)=0\) as \(\coker(\mu)=0\);
   so \(0\to\ker(\lambda)\to K\xrightarrow{\lambda}L\to0\) is exact. Hence \(K\) is finitely
   generated by ref:5.6. Thus \(N\) is finitely generated by ref:5.24
   #+END_proof

   #+BEGIN_exercise
   label:5.27
   Let \(0\to L\xrightarrow{\alpha}M\xrightarrow{\beta}N\to0\) be a short exact sequence
   with \(M\) finitely generated and \(N\) finitely presented. Prove \(L\) is
   finitely generated
   #+END_exercise

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   label:5.28
   Let \(0\to L\xrightarrow{\alpha}M\xrightarrow{\beta}N\to0\) be a short exact sequence
   with \(L\) and \(N\) finitely generated. Prove \(M\) is finitely presented too.
   #+END_proposition

   #+BEGIN_proof
   Let \(R\) be the ground ring, \(\lambda:R^l\to L\) and \(\nu:R^n\twoheadrightarrow
   N\) any surjections. Define \(\gamma:R^l\to M\) by \(\gamma:=\alpha\lambda\). Note
   \(R^n\) is projective and define \(\delta:R^n\to M\) by lifting \nu along \beta. Define
   \(\mu:R^l\oplus R^n\to M\) by \(\mu:=\gamma+\delta\). Then the following diagram
   is commutative, where \(\iota:=\iota_{R^l}\) and \(\pi:=\pi_{R^n}\)
   \begin{center}
   \begin{tikzcd}
   0\arrow[r]&R^l\arrow[r,"\iota"]\arrow[d,"\lambda"]&
   R^l\oplus R^n\arrow[d,"\mu"]\arrow[r,"\pi"]&R^n\arrow[r]\arrow[d,"\nu"]&0\\
   0\arrow[r]&L\arrow[r,"\alpha"]&M\arrow[r,"\beta"]&N\arrow[r]&0
   \end{tikzcd}
   \end{center}
   Since \lambda and \nu are surjective, the Snake Lemma yields an exact sequence
   \begin{equation*}
   0\to\ker(\lambda)\to\ker(\mu)\to\ker(\nu)\to0\to\coker(\mu)\to0
   \end{equation*}
   and implies \(\coker(\mu)=0\). Also \(\ker(\lambda)\) and \(\ker(\nu)\) are finitely
   generated. So \(\ker(\mu)\) is finitely generated by ref:5.6. Thus \(M\) is
   finitely generated
   #+END_proof
* Direct Limits
** Categories
   A *category* \(\calc\) is a collection of elements, called *objects*. Each pair
   of objects \(A,B\) is equipped with a set \(\Hom_{\calc}(A,B)\) of elements,
   called *maps* or *morphisms*. We write \(\alpha:A\to B\) or \(A\xrightarrow{\alpha}B\) to
   mean \(\alpha\in\Hom_{\calc}(A,B)\)

   Given objects \(A,B,C\), there is a *composition law*
   \begin{equation*}
   \Hom_{\calc}(A,B)\times\Hom_{\calc}(B,C)\to\Hom_{\calc}(A,C),\quad
   \text{written}\quad(\alpha,\beta)\mapsto\beta\alpha
   \end{equation*}
   and there is a distinguished map \(1_B\in\Hom_{\calc}(B,B)\), called the
   *identity* s.t.
   1. composition is *associative*
   2. \(1_B\) is *unitary*, or \(1_B\alpha=\beta1_B=\beta\)


   We say \alpha is an *isomorphism* with *inverse* \(\beta:B\to A\) if \(\alpha\beta=1_B\)
   and \(\beta\alpha=1_A\)
** Functors label:6.2
   A map of categories is known as a functor. Namely, given categories \(\calc\)
   and \(\calc'\), a *(covariant) functor* \(F:\calc\to\calc'\) is a rule that
   assigns to each object \(A\) of \(\calc\) an object \(F(A)\) of \(\calc'\)
   and to each map \(\alpha:A\to B\) of \(\calc\) a map \(F(\alpha):F(A)\to F(B)\) of
   \(\calc'\) preserving composition and identiy; that is
   1. \(F(\beta\alpha)=F(\beta)F(\alpha)\) for maps \(\alpha:A\to B\) and \(\beta:B\to C\) of
      \(\calc\) and
   2. \(F(1_A)=1_{F(A)}\)


   We also denote a functor \(F\) by \(F(\bullet)\), by \(A\mapsto F(A)\), or by
   \(A\mapsto F_A\)

   Note that a functor preserves isomorphisms

   For example, let \(R\) be a ring, \(M\) a module. Then clearly
   \(\Hom_R(M,\bullet)\) is a functor from \(\RMod\) to \(\RMod\). A
   second example is the *forgetful functor* from \(\RMod\) to \(\Sets\); it sends
   a module to its underlying set and a homomorphism to its underlying set map

   A map of functors is known as a natural transformation. Namely, given two
   functor \(F,F':\calc\rightrightarrows\calc'\), a *natural transformation*
   \(\theta:F\to F'\) is a collection of maps \(\theta(A):F(A)\to F'(A)\) one for each
   object \(A\) of \(\calc\), s.t. \(\theta(B)(F(\alpha)=F'(\alpha)\theta(A)\) for the map \(\alpha:A\to B\)
   #+BEGIN_center
   \begin{tikzcd}
   F(A)\arrow[r,"F(\alpha)"]\arrow[d,"\theta(A)"]&F(B)\arrow[d,"\theta(B)"]\\
   F'(A)\arrow[r,"F'(\alpha)"]&F'(B)
   \end{tikzcd}
   #+END_center

   We call \(F\) and \(F'\) *isomorphic* if there are natural transformations
   \(\theta:F\to F'\) and \(\theta':F'\to F\) with \(\theta'\theta=1_F\) and \(\theta\theta'=1_{F'}\)

   A *contravariant* functor \(G\) from \(\calc\) to \(\calc'\) is a rule similar
   to \(F\), but \(G\) reverses the direction of maps. For example, fix a module
   \(N\); then \(\Hom(\bullet,N)\) is a contravariant functor

   #+BEGIN_exercise
   label:6.3
   1. Show that the condition ref:6.2 (1) is equivalent to the commutativity of
      the corresponding diagram
      \begin{center}
      \begin{tikzcd}
      \Hom_{\calc}(B,C)\arrow[r]\arrow[d]&\Hom_{\calc'}(F(B),F(C))
      \arrow[d]\\
      \Hom_{\calc}(A,C)\arrow[r]&\Hom_{\calc'}(F(A),F(C))
      \end{tikzcd}
      \end{center}
   2. Given \(\gamma:C\to D\), show ref:5.2 (1) yields the commutativity of this
      diagram
      \begin{center}
      \begin{tikzcd}
      \Hom_{\calc}(B,C)\arrow[r]\arrow[d]&\Hom_{\calc'}(F(B),F(C))\arrow[d]\\
      \Hom_{\calc}(A,D)\arrow[r]&\Hom_{\calc'}(F(A),F(D))
      \end{tikzcd}
      \end{center}

   #+END_exercise
** Adjoints label:6.4
   Let \(\calc\) and \(\calc'\) be categories, \(F:\calc\to\calc'\) and
   \(F':\calc'\to\calc\) functors. We call \((F,F')\) an *adjoint pair*, \(F\) the
   *left adjoint* of \(F'\), and \(F'\) the *right adjoint* of \(F\) if for each
   object \(A\in\calc\) and object \(A'\in\calc'\), there is a natural bijection
   \begin{equation*}
   \Hom_{\calc'}(F(A),A')\simeq\Hom_{\calc}(A,F'(A'))
   \end{equation*}
   Here *natural* means that maps \(B\to A\) and \(A'\to B'\) induce a commutative
   diagram
   #+BEGIN_center
   \begin{tikzcd}
   \Hom_{\calc'}(F(A),A')\arrow[r,"\simeq"]\arrow[d]&
   \Hom_{\calc}(A,F'(A'))\arrow[d]\\
   \Hom_{\calc'}(F(B),B')\arrow[r,"\simeq"]&\Hom_{\calc}(B,F'(B'))
   \end{tikzcd}
   #+END_center

   /Naturality serves to determine an adjoint up to canonical isomorphism/.
   Indeed, let \(F\) and \(G\) be two left adjoints of \(F'\). Given
   \(A\in\calc\), define \(\theta(A):G(A)\to F(A)\) to be the image of \(1_{F(A)}\)
   under the adjoint bijections
   \begin{equation*}
   \Hom_{\calc'}(F(A),F(A))\simeq\Hom_{\calc}(A,F'F(A))\simeq\Hom_{\calc'}(G(A),F(A))
   \end{equation*}
   To see that \(\theta(A)\) is natural in \(A\), take a map \(\alpha:A\to B\). It induces
   the following diagram, which is commutative owing to the naturality of the
   adjoint bijections:
   #+BEGIN_center
   \begin{tikzcd}
   \Hom_{\calc'}(F(A),F(A))\arrow[r,"\simeq"]\arrow[d]&
   \Hom_{\calc}(A,F'F(A))\arrow[r,"\simeq"]\arrow[d]&
   \Hom_{\calc'}(G(A),F(A))\arrow[d]\\
   \Hom_{\calc'}(F(A),F(B))\arrow[r,"\simeq"]&
   \Hom_{\calc'}(F(A),F'F(B))\arrow[r,"\simeq"]&
   \Hom_{\calc'}(G(A),F(B))\\
   \Hom_{\calc'}(F(B),F(B))\arrow[r,"\simeq"]\arrow[u]&
   \Hom_{\calc}(B,F'F(B))\arrow[r,"\simeq"]\arrow[u]&
   \Hom_{\calc'}(G(B),F(B))\arrow[u]\\
   \end{tikzcd}
   #+END_center

   Chase after \(1_{F(A)}\) and \(1_{F(B)}\). Both map to
   \(F(\alpha)\in\Hom_{\calc'}(F(A),F(B))\). So both map to the same image in
   \(\Hom_{\calc'}(G(A),F(B))\). But clockwise, \(1_{F(A)}\) maps to
   \(F(\alpha)\theta(A)\); counterclockwise, \(1_{F(B)}\) maps to \(\theta(B)G(\alpha)\). So
   \(\theta(B)G(\alpha)=F(\alpha)\theta(A)\). Thus the \(\theta(A)\) form a natural transformation
   \(\theta:G\to F\)

   Similearly, there is a natural transformation \(\theta':F\to G\). It remains
   to show \(\theta'\theta=1_G\) and \(\theta\theta'=1_F\). However, by
   naturality, this diagram is commutative
   #+BEGIN_center
   \begin{tikzcd}
   \Hom_{\calc'}(F(A),F(A))\arrow[r,"\simeq"]\arrow[d]&
   \Hom_{\calc'}(A,F'F(A))\arrow[r,"\simeq"]\arrow[d]&
   \Hom_{\calc'}(G(A),F(A))\arrow[d]\\
   \Hom_{\calc'}(F(A),G(A))\arrow[r,"\simeq"]&
   \Hom_{\calc}(A,F'G(A))\arrow[r,"\simeq"]&
   \Hom_{\calc'}(G(A),G(A))
   \end{tikzcd}
   #+END_center
   Chase after \(1_{F(A)}\). Clockwise, its image is \(\theta'(A)\theta(A)\).
   Counterclockwise, its image is \(1_{G(A)}\). Thus \(\theta'\theta=1_G\). And
   similarly, \(\theta\theta'=1_F\)

   For example, the "free module" functor is the left adjoint of the forgetful
   functor from \(\RMod\) to \(\Sets\), since by ref:4.10
   \begin{equation*}
   \Hom_{\RMod}(R^{\oplus\Lambda},M)=\Hom_{\Sets}(\Lambda,M)
   \end{equation*}
   Similarly, the "polynomial ring" functor is the left adjoint of the forgetful
   functor from \(\RAlg\) to \(\Sets\) since by ref:1.3
   \begin{equation*}
   \Hom_{\RAlg}(R[X_1,\dots,X_n],R')=\Hom_{\Sets}(\{X_1,\dots,X_n\},R')
   \end{equation*}


   #+BEGIN_exercise
   label:6.5
   Let \(\calc\) and \(\calc'\) be categories, \(F:\calc\to\calc'\) and
   \(F':\calc'\to\calc\) an adjoint pair. Let
   \(\varphi_{A,A'}:\Hom_{\calc'}(FA,A')\similarrightarrow\Hom_{\calc}(A,F'A')\)
   denote the *natural* bijection, and set \(\eta_A:=\varphi_{A,FA}(1_{FA})\). Do
   the following
   1. Prove \(\eta_A\) is natural in \(A\); that is, given \(g:A\to B\), the
      induced square
      \begin{center}
      \begin{tikzcd}
      A\arrow[r,"\eta_A"]\arrow[d,"g"]&F'FA\arrow[d,"F'Fg"]\\
      B\arrow[r,"\eta_B"]&F'FB
      \end{tikzcd}
      \end{center}
      is commutative. We call the natural transformation \(A\mapsto\eta_A\) the
      *unit* of \((F,F')\)
   2. Given \(f':FA\to A'\), prove \(\varphi_{A,A'}(f')=F'f'\circ\eta_A\)
   3. Prove the natural map \(\eta_A:A\to F'FA\) is *universal* from \(A\) to
      \(F'\); that is, given \(f:A\to F'A'\), there is a unique map \(f':FA\to
      A'\) with \(F'f'\circ\eta_A=f\)
   4. Conversely, instead of assuming \((F,F')\) is an adjoint pair, assume
      given a natural transformation \(\eta:1_{\calc}\to F'F\) satisfying (1) and
      (3). Prove the equation in (2) defines a natural bijection making
      \((F,F')\) an adjoint pair, whose unit is \eta
   5. Identify the units in the two examples in ref:6.4.


   (Dually, we can define a *counit* \(\epsilon:FF'\to 1_{\calc'}\))
   #+END_exercise

   #+BEGIN_proof
   1.
        \begin{center}
        \begin{tikzcd}
        \Hom_{\calc'}(FA,FA)\arrow[r,"(Fg)_*"]\arrow[d,"\varphi_{A,FA}"]&
        \Hom_{\calc'}(FA,FB)\arrow[d,"\varphi_{A,FB}"]&
        \Hom_{\calc'}(FB,FB)\arrow[l,"(Fg)^*"']\arrow[d,"\varphi_{B,FB}"]\\
        \Hom_{\calc}(A,F'FA)\arrow[r,"(F'Fg)_*"]&
        \Hom_{\calc}(A,F'FB)&
        \Hom_{\calc}(B,F'FB)\arrow[l,"g^*"']
        \end{tikzcd}
        \end{center}
        Follow \(1_{FA}\) out of the upper left corner to find
        \(F'Fg\circ\eta_A=\varphi_{A,FB}(Fg)\) in \(\Hom_{\calc}(A,F'FB)\). Follow
        \(1_{FB}\) out of the upper right corner to find
        \(\varphi_{A,FB}(Fg)=\eta_B\circ g\). Thus \(F'Fg\circ\eta_A=\eta_B\circ g\).
   2. [@2]
      \begin{center}
      \begin{tikzcd}
      \Hom_{\calc'}(FA,FA)\arrow[r,"f'_*"]\arrow[d,"\varphi_{A,FA}"]
      &\Hom_{\calc'}(FA,A')\arrow[d,"\varphi_{A,A'}"]\\
      \Hom_{\calc}(A,F'FA)\arrow[r,"(F'f')_*"]&
      \Hom_{\calc}(A,F'A')
      \end{tikzcd}
      \end{center}
   4. [@4] Set \(\psi_{A,A'}(f'):=F'f'\circ\eta_A\). As \(\eta_A\) is universal,
      given \(f:A\to F'A'\), there is a unique \(f':FA\to A'\) with
      \(F'f'\circ\eta_A=f\). Thus \(\psi_{A,A'}\) is a bijection
      \begin{equation*}
      \psi_{A,A'}:\Hom_{\calc'}(FA,A')\similarrightarrow\Hom_{\calc}(A,F'A')
      \end{equation*}
      Also \(\psi_{A,A'}\) is natural in \(A\), as \(\eta_A\) is natural in
      \(A\) and \(F'\) is a functor. And \(\psi_{A,A'}\) is natural in \(A'\),
      as \(F'\) is a functor. Clearly \(\psi_{A,FA}(1_{FA})=\eta_A\)
   5. \(\eta_\Lambda:\Lambda\to R^{\oplus\Lambda}\) carries an element of \Lambda to
      the corresponding standard basis vector.

      If \(F\) is the polynomial ring functor and if \(A\) is the set of
      variables \(X_1,\dots,X_n\), then \(\eta_A(X_i)\) is just \(X_i\) viewed
      in \(R[X_1,\dots,X_n]\)
   #+END_proof
** Direct limits label:6.6
   Let \(\Lambda,\calc\) be categories. Assume \Lambda is *small*; that is, its objects form a
   set. Given a functor \(\lambda\mapsto M_{\lambda}\) from \Lambda to \(\calc\), its
   *direct limit*, or *colimit*, denoted by \(\varinjlim M_\lambda\) or
   \(\varinjlim_{\lambda\in\Lambda}M_\lambda\), is defined as the universal
   example of an object \(P\) of \(\calc\) equipped with maps
   \(\beta_\mu:M_\mu\to P\), called *insertions*, that are compatible with the
   *transition maps* \(\alpha^\kappa_\mu:M_\kappa\to M_\mu\), which are the images of
   the maps of \Lambda.  In other words, there is a unique map \beta s.t. all these
   diagrams commute
   #+BEGIN_center
   \begin{tikzcd}
   M_\kappa\arrow[r,"\alpha_\mu^\kappa"]\arrow[d,"\beta_\kappa"]&
   M_\mu\arrow[r,"\alpha_\mu"]\arrow[d,"\beta_\mu"]&
   \varinjlim M_\lambda\arrow[d,"\beta"]\\
   P\arrow[r,"1_P"]&P\arrow[r,"1_P"]&P
   \end{tikzcd}
   #+END_center
   To indicate this context, the functor \(\lambda\mapsto M_\lambda\) is often
   called a *direct system*

   As usual, universaility implies that, once equipped with its insertions
   \(\alpha_\mu\), the limit \(\varinjlim M_\lambda\) is determined up to unique
   isomorphism, assuming it exists. In practice, there is usually a canonical
   choice for \(\varinjlim M_\lambda\), given by a construction.
   #+BEGIN_center
   \begin{tikzcd}
   P\arrow[r,"\alpha"]\arrow[d,"\beta_P"]&
   \varinjlim M_\lambda\arrow[r,"\beta"]\arrow[d,"\beta_M"]&
   P\arrow[r,"\alpha"]\arrow[d,"\beta_P"]&
   \varinjlim M_\lambda\arrow[d,"\beta_M"]\\
   P\arrow[r,"1_P"]&P\arrow[r,"1_P"]&P\arrow[r,"1_P"]&
   P
   \end{tikzcd}
   #+END_center
   Hence \(\beta_P\beta\alpha=\beta_P\) and \(\beta_M\alpha\beta=\beta_M\).
   Since the identity is unique, \(\beta\alpha=1_P\) and
   \(\alpha\beta=1_{\varinjlim M_\lambda}\). This induce an isomorphism

   We say that \(\calc\) *has direct limits indexed by* \Lambda if, for every
   functor \(\lambda\mapsto M_\lambda\) from \Lambda to \(\calc\), the direct limit
   \(\varinjlim M_\lambda\) exists. We say that \(\calc\) *has direct limits* if
   it has direct limits indexed by every small category \Lambda. We say that a functor
   \(F:\calc\to\calc'\) *preserves direct limits* if, given any direct limit
   \(\varinjlim M_\lambda\) in \(\calc\), the direct limit \(\varinjlim
   F(M_\lambda)\) exists, and is equal to \(F(\varinjlim M_\lambda)\); more
   precisely, the maps \(F(\alpha_\mu):F(M_\mu)\to F(\varinjlim M_\lambda)\)
   induce a canonical map
   \begin{equation*}
   \phi:\varinjlim F(M_\lambda)\to F(\varinjlim M_\lambda)
   \end{equation*}
   and \phi is an isomorphism. Sometimes, we construct \(\varinjlim F(M_\lambda)\)
   by showing that \(F(\varinjlim M_\lambda)\) has the requisite UMP

   Assuming \(\calc\) has direct limits by \Lambda. Then, given a natural
   transformation from \(\lambda\mapsto M_\lambda\) to \(\lambda\mapsto
   N_\lambda\), universaility yields unique commutative diagram
   #+BEGIN_center
   \begin{tikzcd}
   M_\mu\arrow[r]\arrow[d]&
   \varinjlim M_\lambda\arrow[d]\\
   N_\mu\arrow[r]&\varinjlim N_\lambda
   \end{tikzcd}
   #+END_center

   To put it in another way, form the *functor category* \(\calc^\Lambda\): its
   objects are the functors \(\lambda\mapsto M_\lambda\) from \(\Lambda\) to
   \(\calc\); its maps are the natural transformations. Then taking direct
   limits yields a functor \(\varinjlim\) from \(\calc^\Lambda\) to \(\calc\)

   In fact, it is just a restatement of the definitions that the "direct limit"
   functor \(\varinjlim\) is the left adjoint of the *diagonal functor*
    
   \begin{equation*}
   \Delta:\calc\to\calc^\Lambda
   \end{equation*}
   By definition, \(\Delta\) sends each object \(M\) to the *constant functor*
   \(\Delta M\), which has the same value \(M\) for every \(\lambda\in\Lambda\) and
   has the same value \(1_M\) at every map of \Lambda; further, \Delta carries a map
   \(\gamma:M\to N\) to the natural transformation \(\Delta\gamma:\Delta M\to \Delta N\), which
   has the same value \gamma at every \(\lambda\in\Lambda\)

   We have
   \begin{equation*}
   \frac{\varinjlim M_\lambda\to M}{(\lambda\mapsto M_\lambda)\to(\lambda\mapsto M)}
   \end{equation*}
** Coproducts label:6.7
   Let \(\calc\) be a category, \Lambda a set, and \(M_\lambda\) an object of
   \(\calc\) for each \(\lambda\in\Lambda\). The *coproduct*
   \(\coprod_{\lambda\in\Lambda}M_\lambda\), or simply \(\coprod M_\lambda\), is
   defined as the universal example of an object \(P\) equipped with a map
   \(\beta_\mu:M_\mu\to P\) for each \(\mu\in\Lambda\). The maps
   \(\iota_\mu:M_\mu\to\coprod M_\lambda\) are called the *inclusions*. Thus,
   given an example \(P\), there exists a unique map \(\beta:\coprod M_\lambda\to
   P\) with \(\beta\iota_\mu=\beta_\mu\) for all \(\mu\in\Lambda\)

   If \(\Lambda=\emptyset\), then the coproduct is an object \(B\) with a unique
   map \beta to every other object \(P\). There are no \mu in \Lambda, so no inclusions
   \(\iota_\mu:M_\mu\to B\), so no equations \(\beta\iota_\mu=\beta_\mu\) to
   restrict \beta. Such a \(B\) is called an *initial object*

   For instance, suppose \(\calc=\RMod\). Then the zero module is an initial
   object. For any \Lambda, the coproducts \(\coprod M_\lambda\) is just the direct
   sum \(\oplus M_\lambda\). Further, suppose \(\calc=\Sets\). Then the empty
   set is an initial object. For any \Lambda, the coproduct \(\coprod M_\lambda\) is
   the disjoint union \(\bigcupdot M_\lambda\)

   Note that the coproduct is a special case of the direct limit. Indeed, regard
   \Lambda as a *discrete* category: its objects are the \(\lambda\in\Lambda\) and it
   has just the required maps, namely, the \(1_\lambda\). Then \(\varinjlim
   M_\lambda=\coprod M_\lambda\) with the insertions equal to the inclusions
** Coequalizers label:6.8
   Let \(\alpha,\alpha':M\to N\) be a two maps in a category \(\calc\). Their
   *coequalizer* is defined as the universal example of an object \(P\) with a map
   \(\eta:N\to P\) s.t. \(\eta\alpha=\eta\alpha'\)
   #+BEGIN_center
   \begin{tikzcd}
   M\arrow[r,yshift=0.7ex,"\alpha"]\arrow[r,yshift=-0.7ex,"\alpha'"']
   &N\arrow[r,"\eta"]\arrow[rd,"\xi"']&P\arrow[d,dashed,"u"]\\
   &&Z
   \end{tikzcd}
   #+END_center
   If \(\calc=\RMod\), then the coequalizer is \(\coker(\alpha-\alpha')\). In
   particular, the coequalizer of \alpha and 0 is just \(\coker(\alpha)\)

    TODO label:todo1   Suppose \(\calc=\Sets\). Take the smallest equivalence relation \(\sim\) on
   \(N\) with \(\alpha(m)\sim\alpha'(m)\) for all \(m\in M\); explicitly, \(n\sim
   n'\) if there are elements \(m_1,\dots,m_r\) with \(\alpha(m_1)=n\) and
   \(\alpha'(m_r)=n'\) and with \(\alpha(m_i)=\alpha'(m_{i+1})\) for \(1\le i<r\).
   Clearly, the coequalizer is the quotient \(N/\sim\) equipped with the
   quotient group

   Note that the coequalizer is a special case of the direct limit. Indeed, let
   \Lambda be the category consisting of two objects \(\kappa,\mu\) and two nontrivial maps
   \(\varphi,\varphi':\kappa\to\mu\). 

   #+BEGIN_exercise
   label:6.9
   Let \(\alpha:L\to M\) and \(\beta:L\to N\) be two maps. Their *pushout* is defined as
   the universal example of an object \(P\) equipped with a pair of maps
   \(\gamma:M\to P\) and \(\delta:N\to P\) s.t. \(\gamma\alpha=\delta\beta\). Express the
   pushout as a direct limit. Show that, in \(\Sets\), the pushout is the
   disjoint union \(M\cupdot N\) modulo the smallest equivalence relation
   \(\sim\) with \(m\sim n\) if there is \(\l\in L\) with \(\alpha(l)=m\) and
   \(\beta(l)=n\). Show that, in \(\RMod\), the pushout is equal to the direct sum
   \(M\oplus N\) modulo the image of \(L\) under the map \(\alpha,-\beta\)
   #+END_exercise

   #+BEGIN_proof
   \begin{center}
   \begin{tikzcd}
   Q&&\\
   &P\arrow[ul,"u",dashed]&M\arrow[l,"\gamma"]\arrow[ull,bend right,"\gamma'"]\\
   &N\arrow[u,"\delta"]\arrow[uul,bend left,"\delta'"]&L\arrow[u,"\alpha"]\arrow[l,"\beta"]
   \end{tikzcd}
   \end{center}
   Let \Lambda be the category with three objects \lambda, \mu and \nu and two nonidentity maps
   \(\lambda\to\mu\) and \(\lambda\to\nu\). Define a functor \(\lambda\mapsto
   M_\lambda\) by \(M_\lambda:=L,M_\mu=M\), \(M_\nu:=N\),
   \(\alpha_\mu^\lambda:=\alpha\), \(\alpha_\nu^\lambda:=\beta\). Set \(Q:=\varinjlim
   M_\lambda\). Then writing
   \begin{center}
   \begin{tikzcd}
   N\arrow[d,"\eta_\nu"]&L\arrow[r,"\alpha"]\arrow[l,"\beta"']\arrow[d,"\eta_\lambda"]&
   M\arrow[d,"\eta_\mu"]\\
   Q&Q\arrow[l,"1_R"']\arrow[r,"1_R"]&Q
   \end{tikzcd}
   \hspace{1cm}as\hspace{1cm}
   \begin{tikzcd}
   L\arrow[r,"\alpha"]\arrow[d,"\beta"']&M\arrow[d,"\eta_\mu"]\\
   N\arrow[r,"\eta_\nu"]&Q
   \end{tikzcd}
   \end{center}

   In \(\Sets\), take \gamma and \delta to be the inclusions followed by the quotient map.
   Clearly \(\gamma\alpha=\delta\beta\). Further, given \(P\) and maps
   \(\gamma':M\to P\) and \(\delta':N\to P\), they define a unique map
   \(M\coprod N\to P\), and it factors through the quotient iff
   \(\gamma'\alpha=\delta'\beta\). Thus \((M\coprod N)/\sim\) is the pushout

   In \(\RMod\), take \gamma and \delta to be the inclusions followed by the quotient map.
   Then for all \(l\in L\), clearly
   \(\iota_M\alpha(l)-\iota_N(\beta(l))=(\alpha(l),-\beta(l))\). So
   \(\iota_M\alpha(l)-\iota_N\beta(l)\) is in \(\im(L)\); hence
   \(\iota_M\alpha(l)\) and \(\iota_N\beta(l)\) has the same image in the quotient
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_lemma
   A category \(\calc\) has direct limits iff \(\calc\) has coproducts and
   coequalizers. If a category \(\calc\) has direct limits, then a functor
   \(F:\calc\to\calc'\) preserves then iff \(F\) preserves coproducts and coequalizers
   #+END_lemma

   #+BEGIN_proof
   Assume \(\calc\) has coproducts and coequalizers. Let \Lambda be a small category,
   and \(\lambda\mapsto M_\lambda\) a functor from \Lambda to \(\calc\). Let
   \Sigma be the set of transition maps \(\alpha_\mu^\lambda:M_\lambda\to M_\mu\). For each
   \(\sigma:=\alpha_\mu^\lambda\in\Sigma\), set \(M_\sigma:=M_\lambda\). Set
   \(M:=\coprod_{\sigma\in\Sigma}M_\sigma\) and \(N:=\coprod_{\lambda\in\Lambda}
   M_\lambda\). For each \sigma, there are two maps \(M_\sigma:=M_\lambda\to N\): the
   inclusion \(\iota_\lambda\) and the composition
   \(\iota_\mu\alpha_\mu^\lambda\). Correspondingly, there are two maps
   \(\alpha,\alpha':M\to N\). Let \(C\) be their coequalizer, and \(\eta:N\to C\)

   Given maps \(\beta_\lambda:M_\lambda\to P\) with
   \(\beta_\mu\alpha_\mu^\lambda=\beta_\lambda\), there is a unique map \(\beta:N\to
   P\) with \(\beta\iota_\lambda=\beta_\lambda\) by the UMP of the coproduct.
   Clearly, \(\beta\alpha=\beta\alpha'\) (note the choice of \beta, just choose all
   \(M\)). so \beta factors uniquely through \(C\) by the UMP of the coequalizer.
   Thus \(C=\varinjlim M_\lambda\)

   Further, if \(F:\calc'\to\calc'\) preserves coproduct and coequalizers, then
   \(F\) preserves arbitrary direct limits as \(F\) preserves the above construction
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   label:6.11 The categories \(\RMod\) and \(\Sets\) have direct limits
   #+END_theorem

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   label:6.12
   Every left adjoint \(F:\calc\to\calc'\) preserves direct limits
   #+END_theorem

   #+BEGIN_proof
   Let \Lambda be a small category, \(\lambda\mapsto M_\lambda\) a functor from \Lambda to
   \(\calc\) s.t. \(\varinjlim M_\lambda\) exists. Given an object \(P'\) of
   \(\calc'\), consider all possible commutative diagrams
   \begin{center}
   \begin{tikzcd}
   F(M_\kappa)\arrow[d,"\beta_\kappa'"]\arrow[r,"F(\alpha_\mu^\kappa)"]&
   F(M_\mu)\arrow[d,"\beta'_\mu"]\arrow[r,"F(\alpha_\mu)"]&
   F(\varinjlim M_\lambda)\arrow[d,"\beta'"]\\
   P'\arrow[r,"1"]&P\arrow[r,"1"]&P
   \end{tikzcd}
   \end{center}
   given the \(\beta_\kappa'\), we must show there is a unique \(\beta'\)

   Say \(F\) is the left adjoint of \(F':\calc'\to\calc\). Then the above
   diagram is equivalent to
   \begin{center}
   \begin{tikzcd}
   M_\kappa\arrow[r,"\alpha_\mu^\kappa"]\arrow[d,"\beta_\kappa"]&
   M_\mu\arrow[r,"\alpha_\mu"]\arrow[d,"\beta_\mu"]&
   \varinjlim M_\lambda\arrow[d,"\beta"]\\
   F'(P')\arrow[r,"1"]&F'(P')\arrow[r,"1"]&F'(P')
   \end{tikzcd}
   \end{center}
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   label:6.13
   Let \(\calc\) be a category, \Lambda and \Sigma small categories. Assume \(\calc\) has
   direct limits indexed by \Sigma. Then the functor category \(\calc^\Lambda\) does too.
   #+END_proposition

   #+BEGIN_proof
   Let \(\sigma\mapsto(\lambda\mapsto M_{\sigma\lambda})\) be a functor from
   \(\Sigma\) to \(\calc^\Lambda\). Then a map \(\sigma\to\tau\) in \Sigma yields a
   natural transformation from \(\lambda\mapsto M_{\sigma\lambda}\) to
   \(\lambda\mapsto M_{\tau\lambda}\). So a map \(\lambda\mapsto\mu\) in \Lambda
   yields a commutative square
   \begin{center}
   \begin{tikzcd}
   M_{\sigma\lambda}\arrow[r]\arrow[d]&M_{\sigma\mu}\arrow[d]\\
   M_{\tau\lambda}\arrow[r]&M_{\tau\mu}
   \end{tikzcd}
   \end{center}
   With \lambda fixed, the rule \(\sigma\mapsto M_{\sigma\lambda}\) is a functor from
   \Sigma to \(\calc\)

   By hypothesis, \(\varinjlim_{\sigma\in\Sigma}M_{\sigma\lambda}\) exists. So
   \(\lambda\mapsto\varinjlim_{\sigma\in\Sigma}M_{\sigma\lambda}\) is a functor
   from \Lambda to \(\calc\). Further, as \(\tau\in\Sigma\) varies, there are
   compatible natural transformation from the \(\lambda\mapsto
   M_{\tau\lambda}\) to
   \(\lambda\mapsto\varinjlim_{\sigma\in\Sigma}M_{\sigma\lambda}\) (definition
   of direct limit) Finally, the latter is the direct limit of the functor
   \(\tau\mapsto(\lambda\mapsto M_{\tau\lambda})\) from \Sigma to \(\calc^\Lambda\),
   because given any functor \(\lambda\mapsto P_\lambda\) from \Lambda to  \(\calc\)
   equipped with, for \(\tau\in\Sigma\), compatible natural transformations from
   the \(\lambda\mapsto M_{\tau\lambda}\) to \(\lambda\mapsto P_\lambda\), there
   are, for \(\lambda\in\Lambda\), compatible unique maps
   \(\varinjlim_{\sigma\in\Sigma}M_{\sigma\lambda}\to P_\lambda\)
   #+END_proof

   #+ATTR_LATEX: :options [Direct limits commute]
   #+BEGIN_theorem
   label:6.14
   Let \(\calc\) be a category with direct limits indexed by small categories \Sigma
   and \Lambda. Let \(\sigma\mapsto(\lambda\mapsto M_{\sigma\lambda})\) be a functor
   from \Sigma to \(\calc^\Lambda\). Then
   \begin{equation*}
   \varinjlim_{\sigma\in\Sigma}\varinjlim_{\lambda\in\Lambda}M_{\sigma,\lambda}=
   \varinjlim_{\lambda\in\Lambda}\varinjlim_{\sigma\in\Sigma}M_{\sigma,\lambda}
   \end{equation*}
   #+END_theorem

   #+BEGIN_proof
   By ref:6.6, the functor
   \(\varinjlim_{\lambda\in\Lambda}:\calc^\Lambda\to\calc\) is a left adjoint.
   By ref:6.13, the category \(\calc^\Lambda\) has direct limits indexed by \Sigma.
   So ref:6.12 yields the assertion
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_corollary
   label:6.15
   Let \Lambda be a small category, \(R\) a ring, and \(\calc\) either \(\Sets\) or
   \(\RMod\). Then the functor \(\varinjlim:calc^\Lambda\to\calc\) preserves
   coproducts and coequalizers
   #+END_corollary

   #+BEGIN_proof
   They all have direct limits
   #+END_proof

   #+BEGIN_exercise
   label:6.16
   label:todo2
   Let \(\calc\) be a category, \Sigma and \Lambda small categories
   1. Prove \(\calc^{\Sigma\times\Lambda}=(\calc^\Lambda)^\Sigma\) with \((\sigma,\lambda)\mapsto
      M_{\sigma,\lambda}\) corresponding to \(\sigma\mapsto(\lambda\mapsto M_{\sigma,\lambda})\)
   2. Assume \(\calc\) has direct limits indexed by \Sigma and by \Lambda. Prove that
      \(\calc\) has direct limits indexed by \(\Sigma\times\Lambda\) and \(\varinjlim_{\lambda\in\Lambda}\varinjlim_{\sigma\in\Sigma}=\varinjlim_{(\sigma,\lambda)\in\Sigma\times\Lambda}\)
   #+END_exercise

   #+BEGIN_proof
   1. In \(\Sigma\times\Lambda\), a map \((\sigma,\lambda)\to(\tau,\mu)\) factors in two ways
      \begin{equation*}
      (\sigma,\lambda)\to(\tau,\lambda)\to(\tau,\mu)\quad\text{ and }\quad
      (\sigma,\lambda)\to(\sigma,\mu)\to(\tau,\mu)
      \end{equation*}
      So given a functor \((\sigma,\lambda)\mapsto M_{\sigma,\lambda}\), there is a diagram
      \begin{center}
      \begin{tikzcd}
      M_{\sigma,\lambda}\arrow[r]\arrow[d]&M_{\sigma,\mu}\arrow[d]\\
      M_{\tau,\lambda}\arrow[r]&M_{\tau,\mu}
      \end{tikzcd}
      \end{center}
      It shows that the map \(\sigma\to\tau\) in \Sigma induces a natural
      transformation from \(\lambda\mapsto M_{\sigma,\lambda}\) to \(\lambda\mapsto
      M_{\tau,\lambda}\). Thus the rule \(\sigma\mapsto(\lambda\mapsto M_{\sigma,\lambda})\) is a
      functor from \Sigma to \(\calc^\Lambda\)

      A map from \((\sigma,\lambda)\mapsto M_{\sigma,\lambda}\) to a second functor \((\sigma,\lambda)\mapsto
      N_{\sigma,\lambda}\) is a collection of maps \(\theta_{\sigma,\lambda}:M_{\sigma,\lambda}\to N_{\sigma,\lambda}\)
      s.t., for every map \((\sigma,\lambda)\to(\tau,\mu)\), the square
      \begin{center}
      \begin{tikzcd}
      M_{\sigma,\lambda}\arrow[r]\arrow[d,"\theta_{\sigma,\lambda}"]&M_{\tau,\mu}\arrow[d,"\theta_{\tau,\mu}"]\\
      N_{\sigma,\lambda}\arrow[r]&N_{\tau,\mu}
      \end{tikzcd}
      \end{center}
      is commutative. Factoring \((\sigma,\lambda)\to(\tau,\mu)\) in two ways as above, we get a
      commutative cube. It shows that the \(\theta_{\sigma,\lambda}\) define a map in \((\calc^\Lambda)^\Sigma\)

   2. \(\calc^\Lambda\) has direct limits indexed by \Sigma. So the functors
      \(\varinjlim_{\lambda\in\Lambda}:\calc^\Lambda\to\calc\) and
      \(\lim_{\sigma\in\Sigma}:(\calc^\Lambda)^\Sigma\to \calc^\Lambda\) exists, and
      they are the left adjoints of the diagonal functors
      \(\calc\to\calc^\Lambda\) and \(\calc^\Lambda\to(\calc^\Lambda)^\Sigma\). Hence
      the composition
      \(\varinjlim_{\lambda\in\Lambda}\varinjlim_{\sigma\in\Sigma}\) is the left
      adjoint of the composition of the two diagonal functors. But the latter is
      just the diagonal \(\calc\to\calc^{\Sigma\times\Lambda}\) owing to (1). So
      this diagonal has a left adjoint, which is necessarily
      \(\varinjlim_{(\sigma,\lambda)\in\Sigma\times\Lambda}\) owing to the uniqueness of adjoints
   #+END_proof

   #+BEGIN_exercise
   label:6.17
   Let \(\lambda\mapsto M_\lambda\) and \(\lambda\mapsto N_\lambda\) be two
   functors from a small category \Lambda to \(\RMod\), and
   \(\{\theta_\lambda:M_\lambda\to N_\lambda\}\) a natural transformation. Show
   \begin{equation*}
   \varinjlim\coker(\theta_\lambda)=\coker(\varinjlim M_\lambda\mapsto\varinjlim N_\lambda)
   \end{equation*}

   Show that the analogous statement for kernel can be false by constructing a
   counterexample using the following commutative diagram with exact rows
   \begin{center}
   \begin{tikzcd}
   \Z\arrow[r,"\mu_2"]\arrow[d,"\mu_2"]&\Z\arrow[r]\arrow[d,"\mu_2"]
   &\Z/\la2\ra\arrow[d,"\mu_2"]\arrow[r]&0\\
   \Z\arrow[r,"\mu_2"]&\Z\arrow[r]&\Z/\la2\ra\arrow[r]&0
   \end{tikzcd}
   \end{center}
   #+END_exercise
   #+BEGIN_proof
   By ref:6.8, the cokernel is a direct limit, and by ref:6.14,  direct limits
   commute;

   To construct the desired counterexample. View its rows as expressing the
   cokernel \(\Z/\la2\ra\) as a direct limit over the category \Lambda of ref:6.8.
   View the left two columns as expressing a natural transformation
   \(\{\theta_\lambda\}\) and view the third column as expressing the induced
   map between the two limits. The latter map is 0, so its kernel is
   \(\Z/\la2\ra\). However, \(\ker(\theta_\lambda)=0\) for
   \(\lambda\in\Lambda\); so \(\varinjlim\ker(\theta_\lambda)=0\)
   #+END_proof
* Filtered Direct Limits
** Filtered categories
   We call a small category \Lambda *filtered* if
   1. given objects \kappa and \lambda, for some \mu there are maps \(\kappa\to\mu\) and \(\lambda\to\mu\)
   2. given two maps \(\sigma,\tau:\eta\rightrightarrows  \kappa\) with the same source and
      the same target, for some \mu there is a map \(\varphi:\kappa\to\mu\) s.t. \(\varphi\sigma=\varphi\tau\)


   Given a category \(\calc\), we say a functor \(\lambda\mapsto M_\lambda\)
   from \Lambda to \(\calc\) is *filtered* if \Lambda is filtered. It so, then we say that the
   direct limit \(\varinjlim M_\lambda\) is *filtered* if it exists

   For example, let \Lambda be a partially ordered set. Suppose \Lambda is *directed*; that
   is, given \(\kappa,\lambda\in\Lambda\) there is a \mu with \(\kappa\le\mu\) and
   \(\lambda\le\mu\). Regard \Lambda as a category whose objects are its elements and
   whose sets \(\Hom(\kappa,\lambda)\) consist of a single element if \(\kappa\le\lambda\)
   and are empty if not; morphisms can be composed as the ordering is transitive

   #+BEGIN_exercise
   label:7.2
   Let \(R\) be a ring, \(M\) a module, \Lambda a set, \(M_\lambda\) a submodule for
   each \(\lambda\in\Lambda\). Assume \(\bigcup M_\lambda=M\). Assume given
   \(\lambda,\mu\in\Lambda\), there is \(\nu\in\Lambda\) s.t. \(M_\lambda,M_\mu\subset
   M_\nu\). Order \Lambda by inclusion: \(\lambda\le\mu\) if \(M_\lambda\subset
   M_\mu\). Prove \(M=\varinjlim M_\lambda\)
   #+END_exercise

   #+BEGIN_proof
   Let prove that \(M\) has the desired UMP.
   If \(M_\lambda\not\subset M_\mu\) and
   \(M_\mu\not\subset M_\lambda\).
   \begin{center}
   \begin{tikzcd}
   M_\mu\arrow[r,"i_\mu"]\arrow[d,"\beta_\mu"]&
   M\arrow[d,"\beta"]&M_\lambda\arrow[l,"i_\lambda"]\arrow[d,"\beta_\lambda"]\\
   P\arrow[r,"1_P"]&P&P\arrow[l,"1_P"]
   \end{tikzcd}
   \end{center}
   If there is \(x\in M_\mu\cap M_\lambda\), since the diagram should be
   commutative, we have \(\beta_\mu(x)=\beta_\lambda(x)\). Hence
   \(\beta=\bigcup\beta_\lambda\) satisfies the condition. And \beta is unique by
   the choice of \(\beta_\lambda\). \beta is well-defined since for any
   \(\beta_\lambda,\beta_\mu\), there is a \(\beta_\nu\) s.t.
   \(\beta_\nu(m)=\beta_\lambda(
   m)=\beta_\nu(m)\)
   #+END_proof

   #+BEGIN_exercise
   label:7.3
   Show that every module \(M\) is the filtered direct limit of its finitely
   generated submodules
   #+END_exercise

   #+BEGIN_proof
   \(M\) is the union of all its finitely generated submodules. Any two finitely
   generated submodules are contained in a third. So by ref:7.2 with  \Lambda the set of
   all finite subsets of \(M\)
   #+END_proof

   #+BEGIN_exercise
   label:7.4
   Show that every direct sum of modules is the filtered direct limit of its
   finite direct subsums
   #+END_exercise

   #+ATTR_LATEX: :options []
   #+BEGIN_examplle
   label:7.5
   Let \Lambda be the set of all positive integers, and for each \(n\in\Lambda\), set
   \(M_n:=\{r/n\mid r\in\Z\}\subset\Q\). Then \(\bigcup M_n=\Q\) and
   \(M_m,M_n\subset M_{mn}\). Then ref:7.2 yields \(\Q=\varinjlim M_n\) where \Lambda
   is ordered by inclusion of the \(M_n\)

   We view \Lambda as ordered by divisibility

   For each \(n\in\Lambda\), set \(R_n:=\Z\), and define \(\beta_n:R_n\to M_n\)
   by \(\beta_n(r):=r/n\). Clearly \(\beta_n\) is a \(\Z\)-module isomorphism.
   And if \(n=ms\), then this diagram is commutative
   \begin{center}
   \begin{tikzcd}
   R_m\arrow[r,"\mu_s"]\arrow[d,"\beta_m","\simeq"']&
   R_n\arrow[d,"\beta_n","\simeq"']\\
   M_m\arrow[r,hookrightarrow,"\iota_n^m"]&M_n
   \end{tikzcd}
   \end{center}
   where \(\iota_n^m\) is the inclusion. Hence \(\Q=\varinjlim R_n\), where the
   transition maps are the multiplication maps \(\mu_s\)
   #+END_examplle

   #+BEGIN_exercise
   label:7.6
   Keep the setup of ref:7.5. For each \(n\in\Lambda\), set \(N_n:=\Z/\la
   n\ra\); if \(n=ms\), define \(\alpha_n^m: N_m\to N_n\) by \(\alpha^m_n(x):=xs\mod
   n\). Show \(\varinjlim N_n=\Q/\Z\)
   #+END_exercise

   #+BEGIN_proof
   For each \(n\in\Lambda\), set \(Q_n:=M_n/\Z\subset\Q/\Z\), if \(n=ms\), then
   \begin{center}
   \begin{tikzcd}
   N_m\arrow[r,"\alpha^m_n"]\arrow[d,"\gamma_m","\simeq"']
   &N_n\arrow[d,"\gamma_n","\simeq"']\\
   Q_m\arrow[r,"\eta_n^m",hookrightarrow]&Q_n
   \end{tikzcd}
   \end{center}
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   label:7.7
   Let \Lambda be a filtered category, \(R\) a ring, and \(\calc\) either \(\Sets\) or
   \(\RMod\) or \(\RAlg\). Let \(\lambda\mapsto M_\lambda\) be a functor from \Lambda
   to \(\calc\). Define a relation \(\sim\) on the disjoint union
   \(\bigsqcup M_\lambda\) as follows: \(m_1\sim m_2\) for \(m_i\in M_{\lambda_i}\) if there are
   transitive maps \(\alpha_\mu^{\lambda_i}:M_{\lambda_i}\to M_\mu\) s.t.
   \(\alpha_\mu^{\lambda_1}m_1=\alpha_\mu^{\lambda_2}m_2\). Then \(\sim\) is an
   equivalence relation. Set \(M:=(\bigsqcup M_\lambda)/\sim\) . Then
   \(M=\varinjlim M_\lambda\) and for each \mu, the canonical map
   \(\alpha_\mu:M_\mu\to M\) is equal to the insertion map \(M_\mu\to\varinjlim M_\lambda\)
   #+END_proposition

   #+BEGIN_proof
   \(\sim\) is transitive. Suppose
   \(\alpha_\mu^{\lambda_1}m_1=\alpha_\mu^{\lambda_2}m_2\) and
   \(\alpha_\nu^{\lambda_2}m_2=\alpha_\nu^{\lambda_3}m_3\). Then since \Lambda is
   filtered. There is \(M_\rho\) with \(\alpha^\mu_\rho\) and \(\alpha^\nu_\rho\). Hence
   there is \(\alpha_\sigma^\rho\) with
   \(\alpha_\sigma^\rho(\alpha_\rho^\mu\alpha_\mu^{\lambda_2})=\alpha_\sigma^\rho(\alpha^\nu_\rho\alpha^{\lambda_2}_\nu)\).
   Hence
   \((\alpha_\sigma^\rho\alpha_\rho^\mu)\alpha_\mu^{\lambda_1}m_1=(\alpha_\sigma^\rho\alpha_\rho^\nu)\alpha_\nu^{\lambda_3}m_3\).
   Thus \(m_1\sim m_3\)

   If \(\calc=\RMod\), define addition in \(M\) as follows. Given \(m_i\in
   M_{\lambda_i}\) for \(i=1,2\),  there are \(\alpha_\mu^{\lambda_i}\). Set
   \begin{equation*}
   \alpha_{\lambda_1}m_1+\alpha_{\lambda_2}m_2:=\alpha_\mu(\alpha_\mu^{\lambda_1}m_1+\alpha_\mu^{\lambda_2}m_2)
   \end{equation*}
   We must check that this addition is well defined

   First consider \mu. Suppose there are \(\alpha_\nu^{\lambda_i}\) too. Then
   there are \(\alpha_\rho^\mu\) and \(\alpha_\rho^\nu\). Furthermore, there is
   \(\alpha_\sigma^\rho\) with
   \(\alpha_\sigma^\rho(\alpha_\rho^\mu\alpha_\mu^{\lambda_1})=\alpha_\sigma^\rho(\alpha_\rho^\nu\alpha_\nu^{\lambda_1})\)
   and then \(\alpha_\tau^\sigma\) with
   \(\alpha_\tau^\sigma(\alpha_\sigma^\rho\alpha_\rho^\mu\alpha_\mu^{\lambda_2})=\alpha_\tau^\sigma(\alpha_\sigma^\rho\alpha_\rho^\nu\alpha_\nu^{\lambda_2})\).
   Therefore
   \begin{equation*}
    (\alpha_\tau^\sigma\alpha_\sigma^\rho\alpha_\rho^\mu)(\alpha_\mu^{\lambda_1}m_1+\alpha_\mu^{\lambda_2}m_2)=(\alpha_\tau^\sigma\alpha_\sigma^\rho\alpha_\rho^\nu)(\alpha_\nu^{\lambda_1}m_1+\alpha_\nu^{\lambda_2}m_2)
   \end{equation*}
   Thus both \mu and \nu yields the same value for
   \(\alpha_{\lambda_1}m_1+\alpha_{\lambda_2}m_2\)

   Second, suppose \(m_1\sim m_1'\in M_{\lambda_1'}\). Then
   \(\alpha_{\lambda_1}m_1+\alpha_{\lambda_2}m_2=\alpha_{\lambda_1'}m_1'+\alpha_{\lambda_2}m_2\).
   Thus addition is well defined on \(M\)

   Define scalar multiplication on \(M\) similarly

   Finally, let \(\beta_\lambda:M_\lambda\to N\) be maps with
   \(\beta_\lambda\alpha^\kappa_\lambda=\beta_\kappa\) for all
   \(\alpha_\lambda^\kappa\). The \(\beta_\lambda\) induce a map \(\bigsqcup
   M_\lambda\to N\). Suppose \(m_1\sim m_2\) for \(m_1\in M_{\lambda_i}\); that
   is, \(\alpha_\mu^{\lambda_1}m_1=\alpha_\mu^{\lambda_2}m_2\) for some
   \(\alpha_\mu^{\lambda_i}\). Then
   \(\beta_{\lambda_1}m_1=\beta_{\lambda_2}m_2\) as
   \(\beta_\mu\alpha_\mu^{\lambda_i}=\beta_{\lambda_i}\). So there is a unique
   map \(\beta:M\to N\) with \(\beta\alpha_\lambda=\beta_\lambda\)
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_corollary
   Preserve the conditions of ref:7.7
   1. Given \(m\in\varinjlim M_\lambda\) for some \lambda, there is \(m_\lambda\in
      M_\lambda\) s.t. \(m=a_\lambda m_\lambda\)
   2. Given \(m_i\in M_{\lambda_i}\) for \(i=1,2\) s.t.
      \(\alpha_{\lambda_1}m_1=\alpha_{\lambda_2}m_2\), there are
      \(\alpha_\mu^{\lambda_i}\) s.t. \(\alpha_\mu^{\lambda_1}m_1=\alpha_\mu^{\lambda_2}m_2\)
   3. Suppose \(\calc=\RMod\) or \(\calc=\RAlg\). Then given \(m_\lambda\in
      M_\lambda\) s.t. \(\alpha_\lambda m_\lambda=0\), there is
      \(\alpha_\mu^\lambda\) s.t. \(\alpha_\mu^\lambda m_\lambda=0\)
   #+END_corollary

   #+BEGIN_exercise
   Let \(R\)
   #+END_exercise

   #+ATTR_LATEX: :options [Exactness of filtered direct limits]
   #+BEGIN_theorem
   Let \(R\) be a ring, \Lambda a filtered category. Let \(\calc\) be the category of
   3-term exact sequences of \(R\)-modules: its objects are the 3-term exact
   sequences and its maps are the commutative diagrams
   \begin{center}
   \begin{tikzcd}
   L\arrow[r]\arrow[d]&M\arrow[r]\arrow[d]&N\arrow[d]\\
   L'\arrow[r]&M'\arrow[r]&N'
   \end{tikzcd}
   \end{center}
   Then for any functor \(\lambda\mapsto(L_\lambda
   \xrightarrow{\beta_\lambda}M_\lambda\xrightarrow{\gamma_\lambda}
   N_\lambda)\) from \Lambda to \(\calc\), the induced sequence
   \(\varinjlim L_\lambda\xrightarrow{\beta}\varinjlim
   M_\lambda\xrightarrow{\gamma}\varinjlim N_\lambda\) is exact
   #+END_theorem

* Tensor Products
** Bilinear maps
   Let \(R\) be a ring, and \(M,N,P\) modules. We call a map
   \begin{equation*}
   \alpha:M\times N\to P
   \end{equation*}
   *bilinear* if it is linear in each variable; that is, given \(m\in M\) and
   \(n\in N\), the maps
   \begin{equation*}
   m'\mapsto\alpha(m',n)\quad\text{ and }\quad
   n'\mapsto \alpha(m,n')
   \end{equation*}
   are \(R\)-linear. Denote the set of all these maps by \(\Bil_R(M,N;P)\).
** Tensor product
   Let \(R\) be a ring, and \(M,N\) modules. Their *tensor product*, denoted by
   \(M\otimes_R N\), or simply \(M\otimes N\), is constructed as the quotient of
   the free module \(R^{\oplus(M\times N)}\) modulo the submodule generated by
   the following elements, where \((m,n)\) stands for the standard basis element
   \(e_{(m,n)}\):
   \begin{align}
   (m+m',n)-(m,n)-(m',n)\quad&\text{ and }\quad
   (m,n+n')-(m,n)-(m,n')   \label{8.2.1}\\
   (xm,n)-x(m,n)\quad&\text{ and }\quad
   (m,xn)-x(m,n)\nonumber
   \end{align}
   for all \(m,m'\in M\) and \(n,n'\in N\) and \(x\in R\). Hence we have
   distributivity and scalar multiplication

   Note that \(M\otimes N\) is the target of the canonical map with source
   \(M\times N\)
   \begin{equation*}
   \beta:M\times N\to M\otimes N
   \end{equation*}
   which sends each \((m,n)\) to its residue class \(m\otimes n\). By
   construction, \beta is bilinear

   #+ATTR_LATEX: :options [UMP of tensor product]
   #+BEGIN_theorem
   Let \(R\) be a ring, \(M,N\) modules. Then \(\beta:M\times N\to M\otimes N\) is
   the universal example of a bilinear map with source \(M\times N\); in fact, \beta
   induces a module isomorphism
   \begin{equation*}
   \theta:\Hom_R(M\otimes_R N,P)\similarrightarrow\Bil_R(M,N;P)
   \end{equation*}

   #+END_theorem

   #+BEGIN_proof

   There is a obvious linear map \(\psi:M\otimes N\to P\) with
   \begin{equation*}
   \psi(r_1(m_1,n_1)+\dots+(r_s(m_s,n_s)))=r_1\psi(m_1,n_1)+\dots+r_s\psi(m_s,n_s)
   \end{equation*}

   \begin{center}\begin{tikzcd}
   M\times N\arrow[r,"\beta"]\arrow[rd,"\text{bilinear}"']&
   M\otimes N\arrow[d,dashed,"\text{linear}"]\\
   &P
   \end{tikzcd}\end{center}
   Note that, if we follow any bilinear map with any linear map, then the
   composition is bilinear; hence \theta is well-defined. Clearly, \theta is a module
   homomorphism. Further, \theta is injective since \(M\otimes_R N\) is generated by
   the image of \beta (Suppose for \(\alpha\in\Hom(M\otimes N,P)\), then
   \(\theta:\alpha\mapsto \alpha\beta\). If \(\alpha\beta=\alpha'\beta\), then
   \(\alpha(x)=\alpha'(x)\) for all \(x\in\im(\beta)\). But \(M\otimes N\) is generated
   by \(\im(\beta)\), hence \(\alpha(x)=\alpha'(x)\) for all \(x\in M\otimes N\)).
   Finally, given any bilinear map \(\alpha:M\times N\to P\), by
   ref:4.10, it extends to a map \(\alpha':R^{\oplus(M\times N)}\to P\), and
   \(\alpha'\) carries all the elements in eqref:8.2.1 to 0; hence \(\alpha'\)
   factors through \beta. Thus \beta is also surjective
   #+END_proof

** Bifunctoriality
   Let \(R\) be a ring, \(\alpha:M\to M'\) and \(\alpha':N\to N'\) module
   homomorphisms. Then there is a canonical commutative diagram:
   \begin{center}\begin{tikzcd}
   M\times N\arrow[r,"\alpha\times\alpha'"]\arrow[d,"\beta"]&
   M'\times N'\arrow[d,"\beta'"]\\
   M\otimes N\arrow[r,"\alpha\otimes\alpha'"]&M'\otimes N'
   \end{tikzcd}\end{center}
   Indeed, \(\beta\circ(\alpha\times\alpha')\) is bilinear; so the UMP yields
   \(\alpha\otimes\alpha'\). Thus \(\bullet\otimes N\) and \(M\otimes\bullet\)
   are commuting *linear* functors, that is, linear on maps

   #+ATTR_LATEX: :options []
   #+BEGIN_proposition
   label:8.5
   Let \(R\) be a ring, \(M\) and \(N\) modules
   1. Then the switch map \(M\times N\to N\times M\) induces an isomorphism
      \begin{equation*}
      M\otimes_R N=N\otimes_R M\tag*{(\textbf{commutative law})}
      \end{equation*}
   2. Then multiplication of \(R\) on \(M\) induces an isomorphism
      \begin{equation*}
      R\otimes_R M=M\tag*{(\textbf{unitary law})}
      \end{equation*}
   #+END_proposition

   #+BEGIN_proof
   The switch map induces an isomorphism \(R^{\oplus(M\times
   N)}\similarrightarrow R^{\oplus(N\times M)}\)

   Define \(\beta:R\times M\to M\) by \(\beta(x,m):=xm\). Clearly \beta is bilinear. Let's
   check \beta has the required UMP. Given a bilinear map \(\alpha: R\times M\to P\),
   define \(\gamma:M\to P\) by \(\gamma(m):=\alpha(1,m)\). Then \gamma is linear as \alpha is
   bilinear. Also \(\alpha=\gamma\beta\) as
   \begin{equation*}
   \alpha(x,m)=x\alpha(1,m)=\alpha(1,xm)=\gamma(xm)=\gamma\beta(x,m)
   \end{equation*}
   Further, \gamma is unique as \beta is surjective
   #+END_proof

   #+BEGIN_exercise
   label:8.6
   Let \(R\) be a domain, \(\fa\) a nonzero ideal. Set \(K:=\Frac(R)\). Show
   that \(\fa\otimes_R K=K\)
   #+END_exercise

   #+BEGIN_proof
   Note that \(1\not\in\fa\).
   #+END_proof
** Bimodules
   Let \(R\) and \(R'\) be rings. An abelian group \(N\) is an
   *\((R,R')\)-bimodule* if it is both an \(R\)-module and an \(R'\)-module and if
   \(x(x'n)=x'(xn)\) for all \(x\in R\), all \(x'\in R'\) and all \(n\in N\). We
   can think of \(N\) as a left \(R\)-module with multiplication \(xn\), and as
   a right \(R'\)-module, with multiplication \(nx'\). Then the compatibility
   condition becomes the associative law: \(x(nx')=(xn)x'\).
   A *\((R,R')\)-homomorphism* of bimodule is a map that is both \(R\)-linear and
   \(R'\)-linear.

   Let \(M\) be an \(R\)-module, and let \(N\) be an \((R,R')\)-bimodule. Then
   \(M\otimes_R N\) is an \((R,R')\)-bimodule with \(R\)-structure as usual and
   with \(R'\)-structure defined by \(x'(m\otimes n):=m\otimes (x'n)\)

   For instance, suppose \(R'\) is an \(R\)-algebra. Then \(R'\) is an
   \((R,R')\)-bimodule. So \(M\otimes_R R'\) is an \(R'\)-module. It is said to
   be obtained by *extension of scalars*

   #+BEGIN_exercise
   label:8.8
   Let \(R\) be a ring, \(R'\) an \(R\)-algebra, \(M,N\) two \(R'\)-modules.
   Show there is a canonical \(R\)-linear map \(\tau:M\otimes_R N\to
   M\otimes_{R'} N\)

   Let \(K\subset M\otimes_R N\) denote the \(R\)-submodule generated by all the
   differences \((x'm)\otimes n-m\otimes (x'n)\) for \(x'\in R'\)
   and \(m\in
   M\) and \(n\in N\). Show \(K=\ker(\tau)\). Show \tau is surjective and is an
   isomorphism if \(R'\) is a quotient of \(R\)
   #+END_exercise

   \(1+1=2\)

   #+BEGIN_proof
   The canonical map \(\beta':M\times N\to M\otimes_{R'}N\) is \(R'\)-bilinear,
   so \(R\)-bilinear

   Set \(Q:=(M\otimes_R N)/K\). Then \tau factors through a map \(\tau':Q\to
   M\otimes_{R'}N\) since \(K\subset\ker(\tau)\)

   There is an \(R'\)-structure on \(M\otimes_R N\) with \(y'(m\otimes
   n)=m\otimes(y'n)\) and so by ref:8.5, another one with \(y'(m\otimes
   n)=(y'm)\otimes n\). Clearly \(K\) is a submodule for each structure, so
   \(Q\) is too. But on \(Q\) the two structure coincide.

   Further, the canonical
   map \(M\times N\to Q\) is \(R'\)-bilinear. Hence the latter factors through
   \(M\otimes_{R'}N\), furnishing an inverse to \(\tau'\). So
   \(\tau':Q\similarrightarrow M\otimes_{R'}N\). Hence \(\ker(\tau)=K\) and \tau is
   surjective

   Finally, suppose \(R'\) is a quotient of \(R\). Then every \(x'\in R'\) is
   the residue of some \(x\in R\). So each \((x'm)\otimes n-m\otimes(x'n)\) is
   equal to 0 in \(M\otimes_R N\) as \(x'm=xm\) and \(x'n=xn\). Hence
   \(\ker(\tau)\) vanishes.
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_theorem
   Let \(R\) and \(R'\) be rings, \(M\) an \(R\)-module, \(P\) an \(R'\)-module,
   \(N\) an \((R,R')\)-bimodule. Then there is two canonical
   \((R,R')\)-isomorphisms
   \begin{align*}
   M\otimes_R(N\otimes_{R'}P)&=(M\otimes_RN)\otimes_{R'}P\tag*{(\textbf{associative law})}\\
   \Hom_{R'}(M\otimes_RN,P)&=\Hom_R(M,\Hom_{R'}(N,P))\tag*{(\textbf{adjoint associativity})}
   \end{align*}
   #+END_theorem

   #+BEGIN_proof
   Note that \(M\otimes_R(N\otimes_{R'}P)\) and \((M\otimes_RN)\otimes_{R'}P\)
   are \((R,R')\)-bimodules. For each \((R,R')\)-bimodule \(Q\), call a map
   \(\tau:M\times N\times P\to Q\) *trilinear* if it is \(R\)-bilinear in \(M\times
   N\) and \(R'\)-bilinear in \(N\times P\). Denote the set of all these \tau by
   \(\Tril(M,N,P;Q)\). It is an \((R,R')\)-bimodule

   A trilinear map \tau yields an \(R\)-bilinear map \(M\times(N\otimes_{R'}P)\to
   Q\), whence a map \(M\otimes_R(N\otimes_{R'}P)\to Q\) which is both
   \(R\)-linear and \(R'\)-linear, and vice versa. Thus
   \begin{equation*}
   \Tril_{(R,R')}(M,N,P;Q)=\Hom(M\otimes_R(N\otimes_{R'}P),Q)
   \end{equation*}
   Similarly, there is a canonical isomorphism of \((R,R')\)-bimodules
   \begin{equation*}
   \Tril_{(R,R')}(M,N,P;Q)=\Hom((M\otimes_RN)\otimes_{R'}P,Q)
   \end{equation*}
   Hence both \(M\otimes_R(N\otimes_{R'}P)\) and \((M\otimes_RN)\otimes_{R'}P\)
   are universal examples of a target of a trilinear map with source \(M\times
   N\times P\)

   To establish the isomorphism of adjoint associativity, define a map
   \begin{align*}
   \alpha:\Hom_{R'}(M\otimes_RN,P)&\to\Hom_R(M,\Hom_{R'}(N,P))\\
   (\alpha(\gamma)(m))(n)&:=\gamma(m\otimes n)
   \end{align*}
   Let's check that \alpha is well defined. First, \(\alpha(\gamma)(m)\) is \(R'\)-linear,
   because given \(x'\in R'\)
   \begin{equation*}
   \gamma(m\otimes(x'n))=\gamma(x'(m\otimes n))=x'\gamma(m\otimes n)
   \end{equation*}
   since \gamma is \(R'\)-linear. Hence \(\alpha(\gamma)(m)\in\Hom_{R'}(N,P)\).
   Further, \(\alpha(\gamma)\) is \(R\)-linear, because given
   \(x\in R\),
   \begin{equation*}
   (xm)\otimes n=m\otimes(xn)\quad\text{ and so }\quad
   (\alpha(\gamma)(xm))(n)=(\alpha(\gamma)(m))(xn)
   \end{equation*}
   Thus \(\alpha(\gamma)\in\Hom_R(M,\Hom_{R'}(N,P))\). Clearly \alpha is an
   \((R,R')\)-homomorphism

   To obtain an inverse to \alpha, given \(\eta\in\Hom_R(M,\Hom_{R'}(N,P))\), define
   a map \(\zeta:M\times N\to P\) by \(\zeta(m,n):=(\eta(m))(n)\). Clearly, \zeta is
   \(\Z\)-bilinear, so \zeta induces a \(\Z\)-linear map \(\delta:M\otimes_{\Z}N\to P\).
   Given \(x\in R\),
   #+END_proof

   #+ATTR_LATEX: :options []
   #+BEGIN_corollary
   Let \(R\) and \(R'\) be rings, \(M\) an \(R\)-module, \(P\) an \(R'\)-module.
   If \(R'\) is an \(R\)-algebra, then there are two canonical
   \((R,R')\)-isomorphisms
   \begin{align*}
   (M\otimes_RR')\otimes_{R'}P&=M\otimes_RP\tag*{(\textbf{cancellation law})}\\
   \Hom_{R'}(M\otimes_RR',P)&=\Hom_R(M,P)\tag*{(\textbf{left adjoint})}
   \end{align*}
   Instead, if \(R\) is an \(R'\)-algebra, then there is another canonical
   \((R,R')\)-isomorphism:
   \begin{equation*}
   \Hom_{R'}(M,P)=\Hom_{R}(M,\Hom_{R'}(R,P))\tag*{(\textbf{right adjoint})}
   \end{equation*}
   In other words, \(\bullet\otimes_RR'\) is the left adjoint of restriction of
   scalars from \(R'\) to \(R\), and \(\Hom_{R'}(R,\bullet)\) is the right
   adjoint of restriction of scalars from \(R\) to \(R'\)
   #+END_corollary

   #+ATTR_LATEX: :options []
   #+BEGIN_corollary
   label:8.11
   Let \(R,R'\) be rings, \(N\) a bimodule. Then the functor \(\bullet\otimes_R
   N\)
   preserves direct limits, or equivalently, direct sums and cokernels
   #+END_corollary

   #+ATTR_LATEX: :options []
   #+BEGIN_examplle
   Tensor product does not preserve kernels, not even injections. Indeed, consider
   the injection \(\mu_2:\Z\to\Z\). Tensor it with \(N:=\Z/\la2\ra\), containing
   \(\mu_2:N\to N\). This map is zero, but not injective as \(N\neq0\)

   \(\mu_2:x\mapsto 2x\)
   #+END_examplle

   #+BEGIN_exercise
   label:8.13
   Let \(R\) be a ring, \(\fa\) and \(\fb\) ideals, and \(M\) a module
   1. Use ref:8.11 to show that \((R/\fa)\otimes M=M/\fa M\)
   2. Use (1) to show that \((R/\fa)\otimes(R/\fb)=R/(\fa+\fb)\)
   #+END_exercise

   #+BEGIN_proof
   1. View \(R/\fa\) as the cokernel of the inclusion \(\fa\to R\). Then
      ref:8.11 implies that \((R/\fa)\otimes M\) is the cokernel of \(\fa\otimes
      M\to R\otimes M\).
      Now \(R\otimes M=M\)
      and \(x\otimes m=xm\) by ref:8.5. Correspondingly, \(\fa\otimes M\to M\)
      has \(\fa M\) as image.

      (Caution. \(\fa\otimes M\to M\)) needn't be injective; if it's not, then
      \(\fa\otimes M\neq\fa M\). For example, take \(R:=\Z\), take
      \(\fa:=\la2\ra\), \(M:=\Z/\la2\ra\), then \(\fa M=0\))

   2. Note that \(\fa(R/\fb)=\fa/\fb=(\fa+\fb)/\fb\). Hence
      \begin{equation*}
      R/\fa\otimes R/\fb=(R/\fb)/((\fa+\fb)/\fb)
      \end{equation*}
   #+END_proof

   #+BEGIN_exercise
   label:8.14
   Let \(k\) be a field, \(M\) and \(N\) nonzero vector spaces. Prove that
   \(M\otimes N\neq0\)
   #+END_exercise

   #+BEGIN_proof
   Since \(k\) is a filed, \(M\) and \(N\) are free; say \(M=k^{\oplus\phi}\)
   and \(N=k^{\oplus\psi}\). Then ref:8.11 yields \(M\otimes
   N=k^{\oplus(\phi\times\psi)}\) as \(k\otimes k=k\)
   #+END_proof

   #+ATTR_LATEX: :options [Watts]
   #+BEGIN_theorem
   Let \(F:\RMod\to\RMod\) be a linear functor. Then there is a natural
   transformation \(\theta(\bullet):\bullet\otimes F(R)\to F(\bullet)\) with
   \(\theta(R)=1\) and \(\theta(\bullet)\) is an isomorphism iff \(F\) preserves direct
   sums and cokernels
   #+END_theorem

   #+BEGIN_proof
   As \(F\) is linear, there is a natural \(R\)-linear map
   \(\theta(M):\Hom(R,M)\to\Hom(F(R),F(M))\). But \(\Hom(R,M)=M\) by ref:4.3. Set
   \(N:=F(R)\). Then with \(P:=F(M)\) adjoint associativity yields the desired
   map
   \begin{equation*}
   \theta(M)\in\Hom(M,\Hom(N,F(M)))=\Hom(M\otimes N,F(M))
   \end{equation*}
   Explicitly, \(\theta(M)(m\otimes n)=F(\rho)(n)\) where \(\rho:R\to M\) is defined by
   \(\rho(1)=m\). Alternatively, this formula can be used to construct \(\theta(M)\), as
   \((m,n)\mapsto F(\rho)(n)\) is clearly bilinear.
   #+END_proof








* TODO Problems
   ref:todo1
   ref:todo2
** COMMENT completion
   definition

   proposition

   lemma

   corollary

   exercise
